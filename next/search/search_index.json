{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Frequenz channels \u00a4 This repository contains channel implementations for python. Contributing \u00a4 If you want to know how to build this project and contribute to it, please check out the Contributing Guide .","title":"Home"},{"location":"#frequenz-channels","text":"This repository contains channel implementations for python.","title":"Frequenz channels"},{"location":"#contributing","text":"If you want to know how to build this project and contribute to it, please check out the Contributing Guide .","title":"Contributing"},{"location":"CONTRIBUTING/","text":"Contributing to frequenz-channels \u00a4 Build \u00a4 You can use build to simply build the source and binary distribution: python -m pip install build python -m build Local development \u00a4 You can use editable installs to develop the project locally (it will install all the dependencies too): python -m pip install -e . You can also use nox to run the tests and other checks: python -m pip install nox nox To build the documentation, first install the dependencies: python -m pip install -e . [ docs ] Then you can build the documentation (it will be written in the site/ directory): mkdocs build Or you can just serve the documentation without building it using: mkdocs serve Your site will be updated live when you change your files (provided that you used pip install -e . , beware of a common pitfall of using pip install without -e , in that case the API reference won't change unless you do a new pip install ). To build multi-version documentation, we use mike . If you want to see how the multi-version sites looks like locally, you can use: mike deploy my-version mike set-default my-version mike serve mike works in mysterious ways. Some basic information: mike deploy will do a mike build and write the results to your local gh-pages branch. my-version is an arbitrary name for the local version you want to preview. mike set-default is needed so when you serve the documentation, it goes to your newly produced documentation by default. mike serve will serve the contents of your local gh-pages branch. Be aware that, unlike mkdocs serve , changes to the sources won't be shown live, as the mike deploy step is needed to refresh them. Be careful not to use --push with mike deploy , otherwise it will push your local gh-pages branch to the origin remote. That said, if you want to test the actual website in your fork , you can always use mike deploy --push --remote your-fork-remote , and then access the GitHub pages produced for your fork. Releasing \u00a4 These are the steps to create a new release: Get the latest head you want to create a release from. Update the RELEASE_NOTES.md file if it is not complete, up to date, and clean from template comments ( <!-- ... -> ) and empty sections. Submit a pull request if an update is needed, wait until it is merged, and update the latest head you want to create a release from to get the new merged pull request. Create a new signed tag using the release notes and a semver compatible version number with a v prefix, for example: git tag -s -F RELEASE_NOTES.md v0.0.1 Push the new tag. A GitHub action will test the tag and if all goes well it will create a GitHub Release , create a new announcement about the release, and upload a new package to PyPI automatically. Once this is done, reset the RELEASE_NOTES.md with the template: cp .github/RELEASE_NOTES.template.md RELEASE_NOTES.md Commit the new release notes and create a PR (this step should be automated eventually too). Celebrate!","title":"Development"},{"location":"CONTRIBUTING/#contributing-to-frequenz-channels","text":"","title":"Contributing to frequenz-channels"},{"location":"CONTRIBUTING/#build","text":"You can use build to simply build the source and binary distribution: python -m pip install build python -m build","title":"Build"},{"location":"CONTRIBUTING/#local-development","text":"You can use editable installs to develop the project locally (it will install all the dependencies too): python -m pip install -e . You can also use nox to run the tests and other checks: python -m pip install nox nox To build the documentation, first install the dependencies: python -m pip install -e . [ docs ] Then you can build the documentation (it will be written in the site/ directory): mkdocs build Or you can just serve the documentation without building it using: mkdocs serve Your site will be updated live when you change your files (provided that you used pip install -e . , beware of a common pitfall of using pip install without -e , in that case the API reference won't change unless you do a new pip install ). To build multi-version documentation, we use mike . If you want to see how the multi-version sites looks like locally, you can use: mike deploy my-version mike set-default my-version mike serve mike works in mysterious ways. Some basic information: mike deploy will do a mike build and write the results to your local gh-pages branch. my-version is an arbitrary name for the local version you want to preview. mike set-default is needed so when you serve the documentation, it goes to your newly produced documentation by default. mike serve will serve the contents of your local gh-pages branch. Be aware that, unlike mkdocs serve , changes to the sources won't be shown live, as the mike deploy step is needed to refresh them. Be careful not to use --push with mike deploy , otherwise it will push your local gh-pages branch to the origin remote. That said, if you want to test the actual website in your fork , you can always use mike deploy --push --remote your-fork-remote , and then access the GitHub pages produced for your fork.","title":"Local development"},{"location":"CONTRIBUTING/#releasing","text":"These are the steps to create a new release: Get the latest head you want to create a release from. Update the RELEASE_NOTES.md file if it is not complete, up to date, and clean from template comments ( <!-- ... -> ) and empty sections. Submit a pull request if an update is needed, wait until it is merged, and update the latest head you want to create a release from to get the new merged pull request. Create a new signed tag using the release notes and a semver compatible version number with a v prefix, for example: git tag -s -F RELEASE_NOTES.md v0.0.1 Push the new tag. A GitHub action will test the tag and if all goes well it will create a GitHub Release , create a new announcement about the release, and upload a new package to PyPI automatically. Once this is done, reset the RELEASE_NOTES.md with the template: cp .github/RELEASE_NOTES.template.md RELEASE_NOTES.md Commit the new release notes and create a PR (this step should be automated eventually too). Celebrate!","title":"Releasing"},{"location":"SUMMARY/","text":"Home API Reference Development","title":"SUMMARY"},{"location":"reference/SUMMARY/","text":"frequenz channels util","title":"SUMMARY"},{"location":"reference/frequenz/channels/","text":"frequenz.channels \u00a4 Frequenz Channels. This package contains channel implementations. Channels: Anycast : A channel that supports multiple senders and multiple receivers. A message sent through a sender will be received by exactly one receiver. Bidirectional : A channel providing a client and a service handle to send and receive bidirectionally. Broadcast : A channel to broadcast messages from multiple senders to multiple receivers. Each message sent through any of the senders is received by all of the receivers. Other base classes: Peekable : An object to allow users to get a peek at the latest value in the channel, without consuming anything. Receiver : An object that can wait for and consume messages from a channel. Sender : An object that can send messages to a channel. Utilities: util : A module with utilities, like special receivers that implement timers, file watchers, merge receivers, or wait for messages in multiple channels. Exception classes: Error : Base class for all errors in this library. ChannelError : Base class for all errors related to channels. ChannelClosedError : Error raised when trying to operate (send, receive, etc.) through a closed channel. SenderError : Base class for all errors related to senders. ReceiverError : Base class for all errors related to receivers. ReceiverStoppedError : A receiver stopped producing messages. ReceiverInvalidatedError : A receiver is not longer valid (for example if it was converted into a peekable. Classes \u00a4 frequenz.channels.Anycast \u00a4 Bases: Generic [ T ] A channel for sending data across async tasks. Anycast channels support multiple senders and multiple receivers. A message sent through a sender will be received by exactly one receiver. In cases where each message need to be received by every receiver, a Broadcast channel may be used. Uses an deque internally, so Anycast channels are not thread-safe. When there are multiple channel receivers, they can be awaited simultaneously using Select , Merge or MergeNamed . Example async def send ( sender : channel . Sender ) -> None : while True : next = random . randint ( 3 , 17 ) print ( f \"sending: { next } \" ) await sender . send ( next ) async def recv ( id : int , receiver : channel . Receiver ) -> None : while True : next = await receiver . receive () print ( f \"receiver_ { id } received { next } \" ) await asyncio . sleep ( 0.1 ) # sleep (or work) with the data acast = channel . Anycast () sender = acast . new_sender () receiver_1 = acast . new_receiver () asyncio . create_task ( send ( sender )) await recv ( 1 , receiver_1 ) Check the tests and benchmarks directories for more examples. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_anycast.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 class Anycast ( Generic [ T ]): \"\"\"A channel for sending data across async tasks. Anycast channels support multiple senders and multiple receivers. A message sent through a sender will be received by exactly one receiver. In cases where each message need to be received by every receiver, a [Broadcast][frequenz.channels.Broadcast] channel may be used. Uses an [deque][collections.deque] internally, so Anycast channels are not thread-safe. When there are multiple channel receivers, they can be awaited simultaneously using [Select][frequenz.channels.util.Select], [Merge][frequenz.channels.util.Merge] or [MergeNamed][frequenz.channels.util.MergeNamed]. Example: ``` python async def send(sender: channel.Sender) -> None: while True: next = random.randint(3, 17) print(f\"sending: {next}\") await sender.send(next) async def recv(id: int, receiver: channel.Receiver) -> None: while True: next = await receiver.receive() print(f\"receiver_{id} received {next}\") await asyncio.sleep(0.1) # sleep (or work) with the data acast = channel.Anycast() sender = acast.new_sender() receiver_1 = acast.new_receiver() asyncio.create_task(send(sender)) await recv(1, receiver_1) ``` Check the `tests` and `benchmarks` directories for more examples. \"\"\" def __init__ ( self , maxsize : int = 10 ) -> None : \"\"\"Create an Anycast channel. Args: maxsize: Size of the channel's buffer. \"\"\" self . limit : int = maxsize self . deque : Deque [ T ] = deque ( maxlen = maxsize ) self . send_cv : Condition = Condition () self . recv_cv : Condition = Condition () self . closed : bool = False async def close ( self ) -> None : \"\"\"Close the channel. Any further attempts to [send()][frequenz.channels.Sender.send] data will return `False`. Receivers will still be able to drain the pending items on the channel, but after that, subsequent [receive()][frequenz.channels.Receiver.receive] calls will return `None` immediately. \"\"\" self . closed = True async with self . send_cv : self . send_cv . notify_all () async with self . recv_cv : self . recv_cv . notify_all () def new_sender ( self ) -> Sender [ T ]: \"\"\"Create a new sender. Returns: A Sender instance attached to the Anycast channel. \"\"\" return Sender ( self ) def new_receiver ( self ) -> Receiver [ T ]: \"\"\"Create a new receiver. Returns: A Receiver instance attached to the Anycast channel. \"\"\" return Receiver ( self ) Functions \u00a4 __init__ ( maxsize = 10 ) \u00a4 Create an Anycast channel. PARAMETER DESCRIPTION maxsize Size of the channel's buffer. TYPE: int DEFAULT: 10 Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_anycast.py 64 65 66 67 68 69 70 71 72 73 74 def __init__ ( self , maxsize : int = 10 ) -> None : \"\"\"Create an Anycast channel. Args: maxsize: Size of the channel's buffer. \"\"\" self . limit : int = maxsize self . deque : Deque [ T ] = deque ( maxlen = maxsize ) self . send_cv : Condition = Condition () self . recv_cv : Condition = Condition () self . closed : bool = False close () async \u00a4 Close the channel. Any further attempts to send() data will return False . Receivers will still be able to drain the pending items on the channel, but after that, subsequent receive() calls will return None immediately. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_anycast.py 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 async def close ( self ) -> None : \"\"\"Close the channel. Any further attempts to [send()][frequenz.channels.Sender.send] data will return `False`. Receivers will still be able to drain the pending items on the channel, but after that, subsequent [receive()][frequenz.channels.Receiver.receive] calls will return `None` immediately. \"\"\" self . closed = True async with self . send_cv : self . send_cv . notify_all () async with self . recv_cv : self . recv_cv . notify_all () new_receiver () \u00a4 Create a new receiver. RETURNS DESCRIPTION Receiver [ T ] A Receiver instance attached to the Anycast channel. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_anycast.py 102 103 104 105 106 107 108 def new_receiver ( self ) -> Receiver [ T ]: \"\"\"Create a new receiver. Returns: A Receiver instance attached to the Anycast channel. \"\"\" return Receiver ( self ) new_sender () \u00a4 Create a new sender. RETURNS DESCRIPTION Sender [ T ] A Sender instance attached to the Anycast channel. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_anycast.py 94 95 96 97 98 99 100 def new_sender ( self ) -> Sender [ T ]: \"\"\"Create a new sender. Returns: A Sender instance attached to the Anycast channel. \"\"\" return Sender ( self ) frequenz.channels.Bidirectional \u00a4 Bases: Generic [ T , U ] A wrapper class for simulating bidirectional channels. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_bidirectional.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 class Bidirectional ( Generic [ T , U ]): \"\"\"A wrapper class for simulating bidirectional channels.\"\"\" class Handle ( Sender [ V ], Receiver [ W ]): \"\"\"A handle to a [Bidirectional][frequenz.channels.Bidirectional] instance. It can be used to send/receive values between the client and service. \"\"\" def __init__ ( self , channel : Bidirectional [ V , W ] | Bidirectional [ W , V ], sender : Sender [ V ], receiver : Receiver [ W ], ) -> None : \"\"\"Create a `Bidirectional.Handle` instance. Args: channel: The underlying channel. sender: A sender to send values with. receiver: A receiver to receive values from. \"\"\" self . _chan = channel self . _sender = sender self . _receiver = receiver async def send ( self , msg : V ) -> None : \"\"\"Send a value to the other side. Args: msg: The value to send. Raises: SenderError: if the underlying channel was closed. A [ChannelClosedError][frequenz.channels.ChannelClosedError] is set as the cause. \"\"\" try : await self . _sender . send ( msg ) except SenderError as err : # If this comes from a channel error, then we inject another # ChannelError having the information about the Bidirectional # channel to hide (at least partially) the underlaying # Broadcast channels we use. if isinstance ( err . __cause__ , ChannelError ): this_chan_error = ChannelError ( f \"Error in the underlying channel { err . __cause__ . channel } : { err . __cause__ } \" , self . _chan , # pylint: disable=protected-access ) this_chan_error . __cause__ = err . __cause__ err . __cause__ = this_chan_error raise err async def ready ( self ) -> bool : \"\"\"Wait until the receiver is ready with a value or an error. Once a call to `ready()` has finished, the value should be read with a call to `consume()` (`receive()` or iterated over). The receiver will remain ready (this method will return immediately) until it is consumed. Returns: Whether the receiver is still active. \"\"\" return await self . _receiver . ready () # pylint: disable=protected-access def consume ( self ) -> W : \"\"\"Return the latest value once `_ready` is complete. Returns: The next value that was received. Raises: ReceiverStoppedError: if there is some problem with the receiver. ReceiverError: if there is some problem with the receiver. # noqa: DAR401 err (https://github.com/terrencepreilly/darglint/issues/181) \"\"\" try : return self . _receiver . consume () # pylint: disable=protected-access except ReceiverError as err : # If this comes from a channel error, then we inject another # ChannelError having the information about the Bidirectional # channel to hide (at least partially) the underlaying # Broadcast channels we use. if isinstance ( err . __cause__ , ChannelError ): this_chan_error = ChannelError ( f \"Error in the underlying channel { err . __cause__ . channel } : { err . __cause__ } \" , self . _chan , # pylint: disable=protected-access ) this_chan_error . __cause__ = err . __cause__ err . __cause__ = this_chan_error raise err def __init__ ( self , client_id : str , service_id : str ) -> None : \"\"\"Create a `Bidirectional` instance. Args: client_id: A name for the client, used to name the channels. service_id: A name for the service end of the channels. \"\"\" self . _client_id = client_id self . _request_channel : Broadcast [ T ] = Broadcast ( f \"req_ { service_id } _ { client_id } \" ) self . _response_channel : Broadcast [ U ] = Broadcast ( f \"resp_ { service_id } _ { client_id } \" ) self . _client_handle = Bidirectional . Handle ( self , self . _request_channel . new_sender (), self . _response_channel . new_receiver (), ) self . _service_handle = Bidirectional . Handle ( self , self . _response_channel . new_sender (), self . _request_channel . new_receiver (), ) @property def client_handle ( self ) -> Bidirectional . Handle [ T , U ]: \"\"\"Get a `Handle` for the client side to use. Returns: Object to send/receive messages with. \"\"\" return self . _client_handle @property def service_handle ( self ) -> Bidirectional . Handle [ U , T ]: \"\"\"Get a `Handle` for the service side to use. Returns: Object to send/receive messages with. \"\"\" return self . _service_handle Attributes \u00a4 client_handle : Bidirectional . Handle [ T , U ] property \u00a4 Get a Handle for the client side to use. RETURNS DESCRIPTION Bidirectional . Handle [ T , U ] Object to send/receive messages with. service_handle : Bidirectional . Handle [ U , T ] property \u00a4 Get a Handle for the service side to use. RETURNS DESCRIPTION Bidirectional . Handle [ U , T ] Object to send/receive messages with. Classes \u00a4 Handle \u00a4 Bases: Sender [ V ] , Receiver [ W ] A handle to a Bidirectional instance. It can be used to send/receive values between the client and service. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_bidirectional.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 class Handle ( Sender [ V ], Receiver [ W ]): \"\"\"A handle to a [Bidirectional][frequenz.channels.Bidirectional] instance. It can be used to send/receive values between the client and service. \"\"\" def __init__ ( self , channel : Bidirectional [ V , W ] | Bidirectional [ W , V ], sender : Sender [ V ], receiver : Receiver [ W ], ) -> None : \"\"\"Create a `Bidirectional.Handle` instance. Args: channel: The underlying channel. sender: A sender to send values with. receiver: A receiver to receive values from. \"\"\" self . _chan = channel self . _sender = sender self . _receiver = receiver async def send ( self , msg : V ) -> None : \"\"\"Send a value to the other side. Args: msg: The value to send. Raises: SenderError: if the underlying channel was closed. A [ChannelClosedError][frequenz.channels.ChannelClosedError] is set as the cause. \"\"\" try : await self . _sender . send ( msg ) except SenderError as err : # If this comes from a channel error, then we inject another # ChannelError having the information about the Bidirectional # channel to hide (at least partially) the underlaying # Broadcast channels we use. if isinstance ( err . __cause__ , ChannelError ): this_chan_error = ChannelError ( f \"Error in the underlying channel { err . __cause__ . channel } : { err . __cause__ } \" , self . _chan , # pylint: disable=protected-access ) this_chan_error . __cause__ = err . __cause__ err . __cause__ = this_chan_error raise err async def ready ( self ) -> bool : \"\"\"Wait until the receiver is ready with a value or an error. Once a call to `ready()` has finished, the value should be read with a call to `consume()` (`receive()` or iterated over). The receiver will remain ready (this method will return immediately) until it is consumed. Returns: Whether the receiver is still active. \"\"\" return await self . _receiver . ready () # pylint: disable=protected-access def consume ( self ) -> W : \"\"\"Return the latest value once `_ready` is complete. Returns: The next value that was received. Raises: ReceiverStoppedError: if there is some problem with the receiver. ReceiverError: if there is some problem with the receiver. # noqa: DAR401 err (https://github.com/terrencepreilly/darglint/issues/181) \"\"\" try : return self . _receiver . consume () # pylint: disable=protected-access except ReceiverError as err : # If this comes from a channel error, then we inject another # ChannelError having the information about the Bidirectional # channel to hide (at least partially) the underlaying # Broadcast channels we use. if isinstance ( err . __cause__ , ChannelError ): this_chan_error = ChannelError ( f \"Error in the underlying channel { err . __cause__ . channel } : { err . __cause__ } \" , self . _chan , # pylint: disable=protected-access ) this_chan_error . __cause__ = err . __cause__ err . __cause__ = this_chan_error raise err Functions \u00a4 __init__ ( channel , sender , receiver ) \u00a4 Create a Bidirectional.Handle instance. PARAMETER DESCRIPTION channel The underlying channel. TYPE: Bidirectional [ V , W ] | Bidirectional [ W , V ] sender A sender to send values with. TYPE: Sender [ V ] receiver A receiver to receive values from. TYPE: Receiver [ W ] Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_bidirectional.py 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 def __init__ ( self , channel : Bidirectional [ V , W ] | Bidirectional [ W , V ], sender : Sender [ V ], receiver : Receiver [ W ], ) -> None : \"\"\"Create a `Bidirectional.Handle` instance. Args: channel: The underlying channel. sender: A sender to send values with. receiver: A receiver to receive values from. \"\"\" self . _chan = channel self . _sender = sender self . _receiver = receiver consume () \u00a4 Return the latest value once _ready is complete. RETURNS DESCRIPTION W The next value that was received. RAISES DESCRIPTION ReceiverStoppedError if there is some problem with the receiver. ReceiverError if there is some problem with the receiver. noqa: DAR401 err (https://github.com/terrencepreilly/darglint/issues/181) \u00a4 Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_bidirectional.py 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 def consume ( self ) -> W : \"\"\"Return the latest value once `_ready` is complete. Returns: The next value that was received. Raises: ReceiverStoppedError: if there is some problem with the receiver. ReceiverError: if there is some problem with the receiver. # noqa: DAR401 err (https://github.com/terrencepreilly/darglint/issues/181) \"\"\" try : return self . _receiver . consume () # pylint: disable=protected-access except ReceiverError as err : # If this comes from a channel error, then we inject another # ChannelError having the information about the Bidirectional # channel to hide (at least partially) the underlaying # Broadcast channels we use. if isinstance ( err . __cause__ , ChannelError ): this_chan_error = ChannelError ( f \"Error in the underlying channel { err . __cause__ . channel } : { err . __cause__ } \" , self . _chan , # pylint: disable=protected-access ) this_chan_error . __cause__ = err . __cause__ err . __cause__ = this_chan_error raise err ready () async \u00a4 Wait until the receiver is ready with a value or an error. Once a call to ready() has finished, the value should be read with a call to consume() ( receive() or iterated over). The receiver will remain ready (this method will return immediately) until it is consumed. RETURNS DESCRIPTION bool Whether the receiver is still active. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_bidirectional.py 71 72 73 74 75 76 77 78 79 80 81 82 async def ready ( self ) -> bool : \"\"\"Wait until the receiver is ready with a value or an error. Once a call to `ready()` has finished, the value should be read with a call to `consume()` (`receive()` or iterated over). The receiver will remain ready (this method will return immediately) until it is consumed. Returns: Whether the receiver is still active. \"\"\" return await self . _receiver . ready () # pylint: disable=protected-access send ( msg ) async \u00a4 Send a value to the other side. PARAMETER DESCRIPTION msg The value to send. TYPE: V RAISES DESCRIPTION SenderError if the underlying channel was closed. A ChannelClosedError is set as the cause. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_bidirectional.py 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 async def send ( self , msg : V ) -> None : \"\"\"Send a value to the other side. Args: msg: The value to send. Raises: SenderError: if the underlying channel was closed. A [ChannelClosedError][frequenz.channels.ChannelClosedError] is set as the cause. \"\"\" try : await self . _sender . send ( msg ) except SenderError as err : # If this comes from a channel error, then we inject another # ChannelError having the information about the Bidirectional # channel to hide (at least partially) the underlaying # Broadcast channels we use. if isinstance ( err . __cause__ , ChannelError ): this_chan_error = ChannelError ( f \"Error in the underlying channel { err . __cause__ . channel } : { err . __cause__ } \" , self . _chan , # pylint: disable=protected-access ) this_chan_error . __cause__ = err . __cause__ err . __cause__ = this_chan_error raise err Functions \u00a4 __init__ ( client_id , service_id ) \u00a4 Create a Bidirectional instance. PARAMETER DESCRIPTION client_id A name for the client, used to name the channels. TYPE: str service_id A name for the service end of the channels. TYPE: str Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_bidirectional.py 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 def __init__ ( self , client_id : str , service_id : str ) -> None : \"\"\"Create a `Bidirectional` instance. Args: client_id: A name for the client, used to name the channels. service_id: A name for the service end of the channels. \"\"\" self . _client_id = client_id self . _request_channel : Broadcast [ T ] = Broadcast ( f \"req_ { service_id } _ { client_id } \" ) self . _response_channel : Broadcast [ U ] = Broadcast ( f \"resp_ { service_id } _ { client_id } \" ) self . _client_handle = Bidirectional . Handle ( self , self . _request_channel . new_sender (), self . _response_channel . new_receiver (), ) self . _service_handle = Bidirectional . Handle ( self , self . _response_channel . new_sender (), self . _request_channel . new_receiver (), ) frequenz.channels.Broadcast \u00a4 Bases: Generic [ T ] A channel to broadcast messages to multiple receivers. Broadcast channels can have multiple senders and multiple receivers. Each message sent through any of the senders is received by all of the receivers. Internally, a broadcast receiver's buffer is implemented with just append/pop operations on either side of a deque , which are thread-safe. Because of this, Broadcast channels are thread-safe. When there are multiple channel receivers, they can be awaited simultaneously using Select , Merge or MergeNamed . Example async def send ( sender : channel . Sender ) -> None : while True : next = random . randint ( 3 , 17 ) print ( f \"sending: { next } \" ) await sender . send ( next ) async def recv ( id : int , receiver : channel . Receiver ) -> None : while True : next = await receiver . receive () print ( f \"receiver_ { id } received { next } \" ) await asyncio . sleep ( 0.1 ) # sleep (or work) with the data bcast = channel . Broadcast () sender = bcast . new_sender () receiver_1 = bcast . new_receiver () asyncio . create_task ( send ( sender )) await recv ( 1 , receiver_1 ) Check the tests and benchmarks directories for more examples. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_broadcast.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 class Broadcast ( Generic [ T ]): \"\"\"A channel to broadcast messages to multiple receivers. `Broadcast` channels can have multiple senders and multiple receivers. Each message sent through any of the senders is received by all of the receivers. Internally, a broadcast receiver's buffer is implemented with just append/pop operations on either side of a [deque][collections.deque], which are thread-safe. Because of this, `Broadcast` channels are thread-safe. When there are multiple channel receivers, they can be awaited simultaneously using [Select][frequenz.channels.util.Select], [Merge][frequenz.channels.util.Merge] or [MergeNamed][frequenz.channels.util.MergeNamed]. Example: ``` python async def send(sender: channel.Sender) -> None: while True: next = random.randint(3, 17) print(f\"sending: {next}\") await sender.send(next) async def recv(id: int, receiver: channel.Receiver) -> None: while True: next = await receiver.receive() print(f\"receiver_{id} received {next}\") await asyncio.sleep(0.1) # sleep (or work) with the data bcast = channel.Broadcast() sender = bcast.new_sender() receiver_1 = bcast.new_receiver() asyncio.create_task(send(sender)) await recv(1, receiver_1) ``` Check the `tests` and `benchmarks` directories for more examples. \"\"\" def __init__ ( self , name : str , resend_latest : bool = False ) -> None : \"\"\"Create a Broadcast channel. Args: name: A name for the broadcast channel, typically based on the type of data sent through it. Used to identify the channel in the logs. resend_latest: When True, every time a new receiver is created with `new_receiver`, it will automatically get sent the latest value on the channel. This allows new receivers on slow streams to get the latest value as soon as they are created, without having to wait for the next message on the channel to arrive. \"\"\" self . name : str = name self . _resend_latest = resend_latest self . recv_cv : Condition = Condition () self . receivers : Dict [ UUID , weakref . ReferenceType [ Receiver [ T ]]] = {} self . closed : bool = False self . _latest : Optional [ T ] = None async def close ( self ) -> None : \"\"\"Close the Broadcast channel. Any further attempts to [send()][frequenz.channels.Sender.send] data will return `False`. Receivers will still be able to drain the pending items on their queues, but after that, subsequent [receive()][frequenz.channels.Receiver.receive] calls will return `None` immediately. \"\"\" self . _latest = None self . closed = True async with self . recv_cv : self . recv_cv . notify_all () def new_sender ( self ) -> Sender [ T ]: \"\"\"Create a new broadcast sender. Returns: A Sender instance attached to the broadcast channel. \"\"\" return Sender ( self ) def new_receiver ( self , name : Optional [ str ] = None , maxsize : int = 50 ) -> Receiver [ T ]: \"\"\"Create a new broadcast receiver. Broadcast receivers have their own buffer, and when messages are not being consumed fast enough and the buffer fills up, old messages will get dropped just in this receiver. Args: name: A name to identify the receiver in the logs. maxsize: Size of the receiver's buffer. Returns: A Receiver instance attached to the broadcast channel. \"\"\" uuid = uuid4 () if name is None : name = str ( uuid ) recv : Receiver [ T ] = Receiver ( uuid , name , maxsize , self ) self . receivers [ uuid ] = weakref . ref ( recv ) if self . _resend_latest and self . _latest is not None : recv . enqueue ( self . _latest ) return recv def new_peekable ( self ) -> Peekable [ T ]: \"\"\"Create a new Peekable for the broadcast channel. A Peekable provides a [peek()][frequenz.channels.Peekable.peek] method that allows the user to get a peek at the latest value in the channel, without consuming anything. Returns: A Peekable to peek into the broadcast channel with. \"\"\" return Peekable ( self ) Functions \u00a4 __init__ ( name , resend_latest = False ) \u00a4 Create a Broadcast channel. PARAMETER DESCRIPTION name A name for the broadcast channel, typically based on the type of data sent through it. Used to identify the channel in the logs. TYPE: str resend_latest When True, every time a new receiver is created with new_receiver , it will automatically get sent the latest value on the channel. This allows new receivers on slow streams to get the latest value as soon as they are created, without having to wait for the next message on the channel to arrive. TYPE: bool DEFAULT: False Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_broadcast.py 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 def __init__ ( self , name : str , resend_latest : bool = False ) -> None : \"\"\"Create a Broadcast channel. Args: name: A name for the broadcast channel, typically based on the type of data sent through it. Used to identify the channel in the logs. resend_latest: When True, every time a new receiver is created with `new_receiver`, it will automatically get sent the latest value on the channel. This allows new receivers on slow streams to get the latest value as soon as they are created, without having to wait for the next message on the channel to arrive. \"\"\" self . name : str = name self . _resend_latest = resend_latest self . recv_cv : Condition = Condition () self . receivers : Dict [ UUID , weakref . ReferenceType [ Receiver [ T ]]] = {} self . closed : bool = False self . _latest : Optional [ T ] = None close () async \u00a4 Close the Broadcast channel. Any further attempts to send() data will return False . Receivers will still be able to drain the pending items on their queues, but after that, subsequent receive() calls will return None immediately. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_broadcast.py 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 async def close ( self ) -> None : \"\"\"Close the Broadcast channel. Any further attempts to [send()][frequenz.channels.Sender.send] data will return `False`. Receivers will still be able to drain the pending items on their queues, but after that, subsequent [receive()][frequenz.channels.Receiver.receive] calls will return `None` immediately. \"\"\" self . _latest = None self . closed = True async with self . recv_cv : self . recv_cv . notify_all () new_peekable () \u00a4 Create a new Peekable for the broadcast channel. A Peekable provides a peek() method that allows the user to get a peek at the latest value in the channel, without consuming anything. RETURNS DESCRIPTION Peekable [ T ] A Peekable to peek into the broadcast channel with. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_broadcast.py 144 145 146 147 148 149 150 151 152 153 154 def new_peekable ( self ) -> Peekable [ T ]: \"\"\"Create a new Peekable for the broadcast channel. A Peekable provides a [peek()][frequenz.channels.Peekable.peek] method that allows the user to get a peek at the latest value in the channel, without consuming anything. Returns: A Peekable to peek into the broadcast channel with. \"\"\" return Peekable ( self ) new_receiver ( name = None , maxsize = 50 ) \u00a4 Create a new broadcast receiver. Broadcast receivers have their own buffer, and when messages are not being consumed fast enough and the buffer fills up, old messages will get dropped just in this receiver. PARAMETER DESCRIPTION name A name to identify the receiver in the logs. TYPE: Optional [ str ] DEFAULT: None maxsize Size of the receiver's buffer. TYPE: int DEFAULT: 50 RETURNS DESCRIPTION Receiver [ T ] A Receiver instance attached to the broadcast channel. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_broadcast.py 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 def new_receiver ( self , name : Optional [ str ] = None , maxsize : int = 50 ) -> Receiver [ T ]: \"\"\"Create a new broadcast receiver. Broadcast receivers have their own buffer, and when messages are not being consumed fast enough and the buffer fills up, old messages will get dropped just in this receiver. Args: name: A name to identify the receiver in the logs. maxsize: Size of the receiver's buffer. Returns: A Receiver instance attached to the broadcast channel. \"\"\" uuid = uuid4 () if name is None : name = str ( uuid ) recv : Receiver [ T ] = Receiver ( uuid , name , maxsize , self ) self . receivers [ uuid ] = weakref . ref ( recv ) if self . _resend_latest and self . _latest is not None : recv . enqueue ( self . _latest ) return recv new_sender () \u00a4 Create a new broadcast sender. RETURNS DESCRIPTION Sender [ T ] A Sender instance attached to the broadcast channel. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_broadcast.py 111 112 113 114 115 116 117 def new_sender ( self ) -> Sender [ T ]: \"\"\"Create a new broadcast sender. Returns: A Sender instance attached to the broadcast channel. \"\"\" return Sender ( self ) frequenz.channels.ChannelClosedError \u00a4 Bases: ChannelError Error raised when trying to operate on a closed channel. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_exceptions.py 48 49 50 51 52 53 54 55 56 57 class ChannelClosedError ( ChannelError ): \"\"\"Error raised when trying to operate on a closed channel.\"\"\" def __init__ ( self , channel : Any ): \"\"\"Create a `ChannelClosedError` instance. Args: channel: A reference to the channel that was closed. \"\"\" super () . __init__ ( f \"Channel { channel } was closed\" , channel ) Functions \u00a4 __init__ ( channel ) \u00a4 Create a ChannelClosedError instance. PARAMETER DESCRIPTION channel A reference to the channel that was closed. TYPE: Any Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_exceptions.py 51 52 53 54 55 56 57 def __init__ ( self , channel : Any ): \"\"\"Create a `ChannelClosedError` instance. Args: channel: A reference to the channel that was closed. \"\"\" super () . __init__ ( f \"Channel { channel } was closed\" , channel ) frequenz.channels.ChannelError \u00a4 Bases: Error An error produced in a channel. All exceptions generated by channels inherit from this exception. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_exceptions.py 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 class ChannelError ( Error ): \"\"\"An error produced in a channel. All exceptions generated by channels inherit from this exception. \"\"\" def __init__ ( self , message : Any , channel : Any ): \"\"\"Create a ChannelError instance. Args: message: An error message. channel: A reference to the channel that encountered the error. \"\"\" super () . __init__ ( message ) self . channel : Any = channel Functions \u00a4 __init__ ( message , channel ) \u00a4 Create a ChannelError instance. PARAMETER DESCRIPTION message An error message. TYPE: Any channel A reference to the channel that encountered the error. TYPE: Any Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_exceptions.py 37 38 39 40 41 42 43 44 45 def __init__ ( self , message : Any , channel : Any ): \"\"\"Create a ChannelError instance. Args: message: An error message. channel: A reference to the channel that encountered the error. \"\"\" super () . __init__ ( message ) self . channel : Any = channel frequenz.channels.Error \u00a4 Bases: RuntimeError Base error. All exceptions generated by this library inherit from this exception. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_exceptions.py 16 17 18 19 20 21 22 23 24 25 26 27 28 class Error ( RuntimeError ): \"\"\"Base error. All exceptions generated by this library inherit from this exception. \"\"\" def __init__ ( self , message : Any ): \"\"\"Create a ChannelError instance. Args: message: An error message. \"\"\" super () . __init__ ( message ) Functions \u00a4 __init__ ( message ) \u00a4 Create a ChannelError instance. PARAMETER DESCRIPTION message An error message. TYPE: Any Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_exceptions.py 22 23 24 25 26 27 28 def __init__ ( self , message : Any ): \"\"\"Create a ChannelError instance. Args: message: An error message. \"\"\" super () . __init__ ( message ) frequenz.channels.Peekable \u00a4 Bases: ABC , Generic [ T ] A channel peekable. A Peekable provides a peek() method that allows the user to get a peek at the latest value in the channel, without consuming anything. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_base_classes.py 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 class Peekable ( ABC , Generic [ T ]): \"\"\"A channel peekable. A Peekable provides a [peek()][frequenz.channels.Peekable] method that allows the user to get a peek at the latest value in the channel, without consuming anything. \"\"\" @abstractmethod def peek ( self ) -> Optional [ T ]: \"\"\"Return the latest value that was sent to the channel. Returns: The latest value received by the channel, and `None`, if nothing has been sent to the channel yet. \"\"\" Functions \u00a4 peek () abstractmethod \u00a4 Return the latest value that was sent to the channel. RETURNS DESCRIPTION Optional [ T ] The latest value received by the channel, and None , if nothing has been sent to the channel yet. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_base_classes.py 147 148 149 150 151 152 153 154 @abstractmethod def peek ( self ) -> Optional [ T ]: \"\"\"Return the latest value that was sent to the channel. Returns: The latest value received by the channel, and `None`, if nothing has been sent to the channel yet. \"\"\" frequenz.channels.Receiver \u00a4 Bases: ABC , Generic [ T ] A channel Receiver. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_base_classes.py 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 class Receiver ( ABC , Generic [ T ]): \"\"\"A channel Receiver.\"\"\" async def __anext__ ( self ) -> T : \"\"\"Await the next value in the async iteration over received values. Returns: The next value received. Raises: StopAsyncIteration: if the receiver stopped producing messages. ReceiverError: if there is some problem with the receiver. \"\"\" try : await self . ready () return self . consume () except ReceiverStoppedError as exc : raise StopAsyncIteration () from exc @abstractmethod async def ready ( self ) -> bool : \"\"\"Wait until the receiver is ready with a value or an error. Once a call to `ready()` has finished, the value should be read with a call to `consume()` (`receive()` or iterated over). The receiver will remain ready (this method will return immediately) until it is consumed. Returns: Whether the receiver is still active. \"\"\" @abstractmethod def consume ( self ) -> T : \"\"\"Return the latest value once `ready()` is complete. `ready()` must be called before each call to `consume()`. Returns: The next value received. Raises: ReceiverStoppedError: if the receiver stopped producing messages. ReceiverError: if there is some problem with the receiver. \"\"\" def __aiter__ ( self ) -> Receiver [ T ]: \"\"\"Initialize the async iterator over received values. Returns: `self`, since no extra setup is needed for the iterator. \"\"\" return self async def receive ( self ) -> T : \"\"\"Receive a message from the channel. Returns: The received message. Raises: ReceiverStoppedError: if there is some problem with the receiver. ReceiverError: if there is some problem with the receiver. # noqa: DAR401 __cause__ (https://github.com/terrencepreilly/darglint/issues/181) \"\"\" try : received = await self . __anext__ () # pylint: disable=unnecessary-dunder-call except StopAsyncIteration as exc : # If we already had a cause and it was the receiver was stopped, # then reuse that error, as StopAsyncIteration is just an artifact # introduced by __anext__. if ( isinstance ( exc . __cause__ , ReceiverStoppedError ) # pylint is not smart enough to figure out we checked above # this is a ReceiverStoppedError and thus it does have # a receiver member and exc . __cause__ . receiver is self # pylint: disable=no-member ): raise exc . __cause__ raise ReceiverStoppedError ( self ) from exc return received def map ( self , call : Callable [[ T ], U ]) -> Receiver [ U ]: \"\"\"Return a receiver with `call` applied on incoming messages. Args: call: function to apply on incoming messages. Returns: A `Receiver` to read results of the given function from. \"\"\" return _Map ( self , call ) def into_peekable ( self ) -> Peekable [ T ]: \"\"\"Convert the `Receiver` implementation into a `Peekable`. Once this function has been called, the receiver will no longer be usable, and calling `receive` on the receiver will raise an exception. Raises: NotImplementedError: when a `Receiver` implementation doesn't have a custom `into_peekable` implementation. \"\"\" raise NotImplementedError ( \"This receiver does not implement `into_peekable`\" ) Functions \u00a4 __aiter__ () \u00a4 Initialize the async iterator over received values. RETURNS DESCRIPTION Receiver [ T ] self , since no extra setup is needed for the iterator. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_base_classes.py 78 79 80 81 82 83 84 def __aiter__ ( self ) -> Receiver [ T ]: \"\"\"Initialize the async iterator over received values. Returns: `self`, since no extra setup is needed for the iterator. \"\"\" return self __anext__ () async \u00a4 Await the next value in the async iteration over received values. RETURNS DESCRIPTION T The next value received. RAISES DESCRIPTION StopAsyncIteration if the receiver stopped producing messages. ReceiverError if there is some problem with the receiver. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_base_classes.py 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 async def __anext__ ( self ) -> T : \"\"\"Await the next value in the async iteration over received values. Returns: The next value received. Raises: StopAsyncIteration: if the receiver stopped producing messages. ReceiverError: if there is some problem with the receiver. \"\"\" try : await self . ready () return self . consume () except ReceiverStoppedError as exc : raise StopAsyncIteration () from exc consume () abstractmethod \u00a4 Return the latest value once ready() is complete. ready() must be called before each call to consume() . RETURNS DESCRIPTION T The next value received. RAISES DESCRIPTION ReceiverStoppedError if the receiver stopped producing messages. ReceiverError if there is some problem with the receiver. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_base_classes.py 64 65 66 67 68 69 70 71 72 73 74 75 76 @abstractmethod def consume ( self ) -> T : \"\"\"Return the latest value once `ready()` is complete. `ready()` must be called before each call to `consume()`. Returns: The next value received. Raises: ReceiverStoppedError: if the receiver stopped producing messages. ReceiverError: if there is some problem with the receiver. \"\"\" into_peekable () \u00a4 Convert the Receiver implementation into a Peekable . Once this function has been called, the receiver will no longer be usable, and calling receive on the receiver will raise an exception. RAISES DESCRIPTION NotImplementedError when a Receiver implementation doesn't have a custom into_peekable implementation. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_base_classes.py 126 127 128 129 130 131 132 133 134 135 136 def into_peekable ( self ) -> Peekable [ T ]: \"\"\"Convert the `Receiver` implementation into a `Peekable`. Once this function has been called, the receiver will no longer be usable, and calling `receive` on the receiver will raise an exception. Raises: NotImplementedError: when a `Receiver` implementation doesn't have a custom `into_peekable` implementation. \"\"\" raise NotImplementedError ( \"This receiver does not implement `into_peekable`\" ) map ( call ) \u00a4 Return a receiver with call applied on incoming messages. PARAMETER DESCRIPTION call function to apply on incoming messages. TYPE: Callable [[ T ], U ] RETURNS DESCRIPTION Receiver [ U ] A Receiver to read results of the given function from. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_base_classes.py 115 116 117 118 119 120 121 122 123 124 def map ( self , call : Callable [[ T ], U ]) -> Receiver [ U ]: \"\"\"Return a receiver with `call` applied on incoming messages. Args: call: function to apply on incoming messages. Returns: A `Receiver` to read results of the given function from. \"\"\" return _Map ( self , call ) ready () abstractmethod async \u00a4 Wait until the receiver is ready with a value or an error. Once a call to ready() has finished, the value should be read with a call to consume() ( receive() or iterated over). The receiver will remain ready (this method will return immediately) until it is consumed. RETURNS DESCRIPTION bool Whether the receiver is still active. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_base_classes.py 51 52 53 54 55 56 57 58 59 60 61 62 @abstractmethod async def ready ( self ) -> bool : \"\"\"Wait until the receiver is ready with a value or an error. Once a call to `ready()` has finished, the value should be read with a call to `consume()` (`receive()` or iterated over). The receiver will remain ready (this method will return immediately) until it is consumed. Returns: Whether the receiver is still active. \"\"\" receive () async \u00a4 Receive a message from the channel. RETURNS DESCRIPTION T The received message. RAISES DESCRIPTION ReceiverStoppedError if there is some problem with the receiver. ReceiverError if there is some problem with the receiver. noqa: DAR401 cause (https://github.com/terrencepreilly/darglint/issues/181) \u00a4 Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_base_classes.py 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 async def receive ( self ) -> T : \"\"\"Receive a message from the channel. Returns: The received message. Raises: ReceiverStoppedError: if there is some problem with the receiver. ReceiverError: if there is some problem with the receiver. # noqa: DAR401 __cause__ (https://github.com/terrencepreilly/darglint/issues/181) \"\"\" try : received = await self . __anext__ () # pylint: disable=unnecessary-dunder-call except StopAsyncIteration as exc : # If we already had a cause and it was the receiver was stopped, # then reuse that error, as StopAsyncIteration is just an artifact # introduced by __anext__. if ( isinstance ( exc . __cause__ , ReceiverStoppedError ) # pylint is not smart enough to figure out we checked above # this is a ReceiverStoppedError and thus it does have # a receiver member and exc . __cause__ . receiver is self # pylint: disable=no-member ): raise exc . __cause__ raise ReceiverStoppedError ( self ) from exc return received frequenz.channels.ReceiverError \u00a4 Bases: Error , Generic [ T ] An error produced in a Receiver . All exceptions generated by receivers inherit from this exception. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_exceptions.py 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 class ReceiverError ( Error , Generic [ T ]): \"\"\"An error produced in a [Receiver][frequenz.channels.Receiver]. All exceptions generated by receivers inherit from this exception. \"\"\" def __init__ ( self , message : Any , receiver : _base_classes . Receiver [ T ]): \"\"\"Create an instance. Args: message: An error message. receiver: The [Receiver][frequenz.channels.Receiver] where the error happened. \"\"\" super () . __init__ ( message ) self . receiver : _base_classes . Receiver [ T ] = receiver Functions \u00a4 __init__ ( message , receiver ) \u00a4 Create an instance. PARAMETER DESCRIPTION message An error message. TYPE: Any receiver The Receiver where the error happened. TYPE: _base_classes . Receiver [ T ] Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_exceptions.py 84 85 86 87 88 89 90 91 92 93 def __init__ ( self , message : Any , receiver : _base_classes . Receiver [ T ]): \"\"\"Create an instance. Args: message: An error message. receiver: The [Receiver][frequenz.channels.Receiver] where the error happened. \"\"\" super () . __init__ ( message ) self . receiver : _base_classes . Receiver [ T ] = receiver frequenz.channels.ReceiverInvalidatedError \u00a4 Bases: ReceiverError [ T ] The Receiver was invalidated. This happens when the Receiver is converted into a Peekable . Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_exceptions.py 109 110 111 112 113 114 115 class ReceiverInvalidatedError ( ReceiverError [ T ]): \"\"\"The [Receiver][frequenz.channels.Receiver] was invalidated. This happens when the Receiver is converted [into][frequenz.channels.Receiver.into_peekable] a [Peekable][frequenz.channels.Peekable]. \"\"\" frequenz.channels.ReceiverStoppedError \u00a4 Bases: ReceiverError [ T ] The Receiver stopped producing messages. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_exceptions.py 96 97 98 99 100 101 102 103 104 105 106 class ReceiverStoppedError ( ReceiverError [ T ]): \"\"\"The [Receiver][frequenz.channels.Receiver] stopped producing messages.\"\"\" def __init__ ( self , receiver : _base_classes . Receiver [ T ]): \"\"\"Create an instance. Args: receiver: The [Receiver][frequenz.channels.Receiver] where the error happened. \"\"\" super () . __init__ ( f \"Receiver { receiver } was stopped\" , receiver ) Functions \u00a4 __init__ ( receiver ) \u00a4 Create an instance. PARAMETER DESCRIPTION receiver The Receiver where the error happened. TYPE: _base_classes . Receiver [ T ] Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_exceptions.py 99 100 101 102 103 104 105 106 def __init__ ( self , receiver : _base_classes . Receiver [ T ]): \"\"\"Create an instance. Args: receiver: The [Receiver][frequenz.channels.Receiver] where the error happened. \"\"\" super () . __init__ ( f \"Receiver { receiver } was stopped\" , receiver ) frequenz.channels.Sender \u00a4 Bases: ABC , Generic [ T ] A channel Sender. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_base_classes.py 17 18 19 20 21 22 23 24 25 26 27 28 29 class Sender ( ABC , Generic [ T ]): \"\"\"A channel Sender.\"\"\" @abstractmethod async def send ( self , msg : T ) -> None : \"\"\"Send a message to the channel. Args: msg: The message to be sent. Raises: SenderError: if there was an error sending the message. \"\"\" Functions \u00a4 send ( msg ) abstractmethod async \u00a4 Send a message to the channel. PARAMETER DESCRIPTION msg The message to be sent. TYPE: T RAISES DESCRIPTION SenderError if there was an error sending the message. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_base_classes.py 20 21 22 23 24 25 26 27 28 29 @abstractmethod async def send ( self , msg : T ) -> None : \"\"\"Send a message to the channel. Args: msg: The message to be sent. Raises: SenderError: if there was an error sending the message. \"\"\" frequenz.channels.SenderError \u00a4 Bases: Error , Generic [ T ] An error produced in a Sender . All exceptions generated by senders inherit from this exception. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_exceptions.py 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 class SenderError ( Error , Generic [ T ]): \"\"\"An error produced in a [Sender][frequenz.channels.Sender]. All exceptions generated by senders inherit from this exception. \"\"\" def __init__ ( self , message : Any , sender : _base_classes . Sender [ T ]): \"\"\"Create an instance. Args: message: An error message. sender: The [Sender][frequenz.channels.Sender] where the error happened. \"\"\" super () . __init__ ( message ) self . sender : _base_classes . Sender [ T ] = sender Functions \u00a4 __init__ ( message , sender ) \u00a4 Create an instance. PARAMETER DESCRIPTION message An error message. TYPE: Any sender The Sender where the error happened. TYPE: _base_classes . Sender [ T ] Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_exceptions.py 66 67 68 69 70 71 72 73 74 75 def __init__ ( self , message : Any , sender : _base_classes . Sender [ T ]): \"\"\"Create an instance. Args: message: An error message. sender: The [Sender][frequenz.channels.Sender] where the error happened. \"\"\" super () . __init__ ( message ) self . sender : _base_classes . Sender [ T ] = sender","title":"channels"},{"location":"reference/frequenz/channels/#frequenz.channels","text":"Frequenz Channels. This package contains channel implementations. Channels: Anycast : A channel that supports multiple senders and multiple receivers. A message sent through a sender will be received by exactly one receiver. Bidirectional : A channel providing a client and a service handle to send and receive bidirectionally. Broadcast : A channel to broadcast messages from multiple senders to multiple receivers. Each message sent through any of the senders is received by all of the receivers. Other base classes: Peekable : An object to allow users to get a peek at the latest value in the channel, without consuming anything. Receiver : An object that can wait for and consume messages from a channel. Sender : An object that can send messages to a channel. Utilities: util : A module with utilities, like special receivers that implement timers, file watchers, merge receivers, or wait for messages in multiple channels. Exception classes: Error : Base class for all errors in this library. ChannelError : Base class for all errors related to channels. ChannelClosedError : Error raised when trying to operate (send, receive, etc.) through a closed channel. SenderError : Base class for all errors related to senders. ReceiverError : Base class for all errors related to receivers. ReceiverStoppedError : A receiver stopped producing messages. ReceiverInvalidatedError : A receiver is not longer valid (for example if it was converted into a peekable.","title":"channels"},{"location":"reference/frequenz/channels/#frequenz.channels-classes","text":"","title":"Classes"},{"location":"reference/frequenz/channels/#frequenz.channels.Anycast","text":"Bases: Generic [ T ] A channel for sending data across async tasks. Anycast channels support multiple senders and multiple receivers. A message sent through a sender will be received by exactly one receiver. In cases where each message need to be received by every receiver, a Broadcast channel may be used. Uses an deque internally, so Anycast channels are not thread-safe. When there are multiple channel receivers, they can be awaited simultaneously using Select , Merge or MergeNamed . Example async def send ( sender : channel . Sender ) -> None : while True : next = random . randint ( 3 , 17 ) print ( f \"sending: { next } \" ) await sender . send ( next ) async def recv ( id : int , receiver : channel . Receiver ) -> None : while True : next = await receiver . receive () print ( f \"receiver_ { id } received { next } \" ) await asyncio . sleep ( 0.1 ) # sleep (or work) with the data acast = channel . Anycast () sender = acast . new_sender () receiver_1 = acast . new_receiver () asyncio . create_task ( send ( sender )) await recv ( 1 , receiver_1 ) Check the tests and benchmarks directories for more examples. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_anycast.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 class Anycast ( Generic [ T ]): \"\"\"A channel for sending data across async tasks. Anycast channels support multiple senders and multiple receivers. A message sent through a sender will be received by exactly one receiver. In cases where each message need to be received by every receiver, a [Broadcast][frequenz.channels.Broadcast] channel may be used. Uses an [deque][collections.deque] internally, so Anycast channels are not thread-safe. When there are multiple channel receivers, they can be awaited simultaneously using [Select][frequenz.channels.util.Select], [Merge][frequenz.channels.util.Merge] or [MergeNamed][frequenz.channels.util.MergeNamed]. Example: ``` python async def send(sender: channel.Sender) -> None: while True: next = random.randint(3, 17) print(f\"sending: {next}\") await sender.send(next) async def recv(id: int, receiver: channel.Receiver) -> None: while True: next = await receiver.receive() print(f\"receiver_{id} received {next}\") await asyncio.sleep(0.1) # sleep (or work) with the data acast = channel.Anycast() sender = acast.new_sender() receiver_1 = acast.new_receiver() asyncio.create_task(send(sender)) await recv(1, receiver_1) ``` Check the `tests` and `benchmarks` directories for more examples. \"\"\" def __init__ ( self , maxsize : int = 10 ) -> None : \"\"\"Create an Anycast channel. Args: maxsize: Size of the channel's buffer. \"\"\" self . limit : int = maxsize self . deque : Deque [ T ] = deque ( maxlen = maxsize ) self . send_cv : Condition = Condition () self . recv_cv : Condition = Condition () self . closed : bool = False async def close ( self ) -> None : \"\"\"Close the channel. Any further attempts to [send()][frequenz.channels.Sender.send] data will return `False`. Receivers will still be able to drain the pending items on the channel, but after that, subsequent [receive()][frequenz.channels.Receiver.receive] calls will return `None` immediately. \"\"\" self . closed = True async with self . send_cv : self . send_cv . notify_all () async with self . recv_cv : self . recv_cv . notify_all () def new_sender ( self ) -> Sender [ T ]: \"\"\"Create a new sender. Returns: A Sender instance attached to the Anycast channel. \"\"\" return Sender ( self ) def new_receiver ( self ) -> Receiver [ T ]: \"\"\"Create a new receiver. Returns: A Receiver instance attached to the Anycast channel. \"\"\" return Receiver ( self )","title":"Anycast"},{"location":"reference/frequenz/channels/#frequenz.channels.Anycast-functions","text":"","title":"Functions"},{"location":"reference/frequenz/channels/#frequenz.channels._anycast.Anycast.__init__","text":"Create an Anycast channel. PARAMETER DESCRIPTION maxsize Size of the channel's buffer. TYPE: int DEFAULT: 10 Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_anycast.py 64 65 66 67 68 69 70 71 72 73 74 def __init__ ( self , maxsize : int = 10 ) -> None : \"\"\"Create an Anycast channel. Args: maxsize: Size of the channel's buffer. \"\"\" self . limit : int = maxsize self . deque : Deque [ T ] = deque ( maxlen = maxsize ) self . send_cv : Condition = Condition () self . recv_cv : Condition = Condition () self . closed : bool = False","title":"__init__()"},{"location":"reference/frequenz/channels/#frequenz.channels._anycast.Anycast.close","text":"Close the channel. Any further attempts to send() data will return False . Receivers will still be able to drain the pending items on the channel, but after that, subsequent receive() calls will return None immediately. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_anycast.py 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 async def close ( self ) -> None : \"\"\"Close the channel. Any further attempts to [send()][frequenz.channels.Sender.send] data will return `False`. Receivers will still be able to drain the pending items on the channel, but after that, subsequent [receive()][frequenz.channels.Receiver.receive] calls will return `None` immediately. \"\"\" self . closed = True async with self . send_cv : self . send_cv . notify_all () async with self . recv_cv : self . recv_cv . notify_all ()","title":"close()"},{"location":"reference/frequenz/channels/#frequenz.channels._anycast.Anycast.new_receiver","text":"Create a new receiver. RETURNS DESCRIPTION Receiver [ T ] A Receiver instance attached to the Anycast channel. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_anycast.py 102 103 104 105 106 107 108 def new_receiver ( self ) -> Receiver [ T ]: \"\"\"Create a new receiver. Returns: A Receiver instance attached to the Anycast channel. \"\"\" return Receiver ( self )","title":"new_receiver()"},{"location":"reference/frequenz/channels/#frequenz.channels._anycast.Anycast.new_sender","text":"Create a new sender. RETURNS DESCRIPTION Sender [ T ] A Sender instance attached to the Anycast channel. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_anycast.py 94 95 96 97 98 99 100 def new_sender ( self ) -> Sender [ T ]: \"\"\"Create a new sender. Returns: A Sender instance attached to the Anycast channel. \"\"\" return Sender ( self )","title":"new_sender()"},{"location":"reference/frequenz/channels/#frequenz.channels.Bidirectional","text":"Bases: Generic [ T , U ] A wrapper class for simulating bidirectional channels. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_bidirectional.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 class Bidirectional ( Generic [ T , U ]): \"\"\"A wrapper class for simulating bidirectional channels.\"\"\" class Handle ( Sender [ V ], Receiver [ W ]): \"\"\"A handle to a [Bidirectional][frequenz.channels.Bidirectional] instance. It can be used to send/receive values between the client and service. \"\"\" def __init__ ( self , channel : Bidirectional [ V , W ] | Bidirectional [ W , V ], sender : Sender [ V ], receiver : Receiver [ W ], ) -> None : \"\"\"Create a `Bidirectional.Handle` instance. Args: channel: The underlying channel. sender: A sender to send values with. receiver: A receiver to receive values from. \"\"\" self . _chan = channel self . _sender = sender self . _receiver = receiver async def send ( self , msg : V ) -> None : \"\"\"Send a value to the other side. Args: msg: The value to send. Raises: SenderError: if the underlying channel was closed. A [ChannelClosedError][frequenz.channels.ChannelClosedError] is set as the cause. \"\"\" try : await self . _sender . send ( msg ) except SenderError as err : # If this comes from a channel error, then we inject another # ChannelError having the information about the Bidirectional # channel to hide (at least partially) the underlaying # Broadcast channels we use. if isinstance ( err . __cause__ , ChannelError ): this_chan_error = ChannelError ( f \"Error in the underlying channel { err . __cause__ . channel } : { err . __cause__ } \" , self . _chan , # pylint: disable=protected-access ) this_chan_error . __cause__ = err . __cause__ err . __cause__ = this_chan_error raise err async def ready ( self ) -> bool : \"\"\"Wait until the receiver is ready with a value or an error. Once a call to `ready()` has finished, the value should be read with a call to `consume()` (`receive()` or iterated over). The receiver will remain ready (this method will return immediately) until it is consumed. Returns: Whether the receiver is still active. \"\"\" return await self . _receiver . ready () # pylint: disable=protected-access def consume ( self ) -> W : \"\"\"Return the latest value once `_ready` is complete. Returns: The next value that was received. Raises: ReceiverStoppedError: if there is some problem with the receiver. ReceiverError: if there is some problem with the receiver. # noqa: DAR401 err (https://github.com/terrencepreilly/darglint/issues/181) \"\"\" try : return self . _receiver . consume () # pylint: disable=protected-access except ReceiverError as err : # If this comes from a channel error, then we inject another # ChannelError having the information about the Bidirectional # channel to hide (at least partially) the underlaying # Broadcast channels we use. if isinstance ( err . __cause__ , ChannelError ): this_chan_error = ChannelError ( f \"Error in the underlying channel { err . __cause__ . channel } : { err . __cause__ } \" , self . _chan , # pylint: disable=protected-access ) this_chan_error . __cause__ = err . __cause__ err . __cause__ = this_chan_error raise err def __init__ ( self , client_id : str , service_id : str ) -> None : \"\"\"Create a `Bidirectional` instance. Args: client_id: A name for the client, used to name the channels. service_id: A name for the service end of the channels. \"\"\" self . _client_id = client_id self . _request_channel : Broadcast [ T ] = Broadcast ( f \"req_ { service_id } _ { client_id } \" ) self . _response_channel : Broadcast [ U ] = Broadcast ( f \"resp_ { service_id } _ { client_id } \" ) self . _client_handle = Bidirectional . Handle ( self , self . _request_channel . new_sender (), self . _response_channel . new_receiver (), ) self . _service_handle = Bidirectional . Handle ( self , self . _response_channel . new_sender (), self . _request_channel . new_receiver (), ) @property def client_handle ( self ) -> Bidirectional . Handle [ T , U ]: \"\"\"Get a `Handle` for the client side to use. Returns: Object to send/receive messages with. \"\"\" return self . _client_handle @property def service_handle ( self ) -> Bidirectional . Handle [ U , T ]: \"\"\"Get a `Handle` for the service side to use. Returns: Object to send/receive messages with. \"\"\" return self . _service_handle","title":"Bidirectional"},{"location":"reference/frequenz/channels/#frequenz.channels.Bidirectional-attributes","text":"","title":"Attributes"},{"location":"reference/frequenz/channels/#frequenz.channels._bidirectional.Bidirectional.client_handle","text":"Get a Handle for the client side to use. RETURNS DESCRIPTION Bidirectional . Handle [ T , U ] Object to send/receive messages with.","title":"client_handle"},{"location":"reference/frequenz/channels/#frequenz.channels._bidirectional.Bidirectional.service_handle","text":"Get a Handle for the service side to use. RETURNS DESCRIPTION Bidirectional . Handle [ U , T ] Object to send/receive messages with.","title":"service_handle"},{"location":"reference/frequenz/channels/#frequenz.channels.Bidirectional-classes","text":"","title":"Classes"},{"location":"reference/frequenz/channels/#frequenz.channels._bidirectional.Bidirectional.Handle","text":"Bases: Sender [ V ] , Receiver [ W ] A handle to a Bidirectional instance. It can be used to send/receive values between the client and service. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_bidirectional.py 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 class Handle ( Sender [ V ], Receiver [ W ]): \"\"\"A handle to a [Bidirectional][frequenz.channels.Bidirectional] instance. It can be used to send/receive values between the client and service. \"\"\" def __init__ ( self , channel : Bidirectional [ V , W ] | Bidirectional [ W , V ], sender : Sender [ V ], receiver : Receiver [ W ], ) -> None : \"\"\"Create a `Bidirectional.Handle` instance. Args: channel: The underlying channel. sender: A sender to send values with. receiver: A receiver to receive values from. \"\"\" self . _chan = channel self . _sender = sender self . _receiver = receiver async def send ( self , msg : V ) -> None : \"\"\"Send a value to the other side. Args: msg: The value to send. Raises: SenderError: if the underlying channel was closed. A [ChannelClosedError][frequenz.channels.ChannelClosedError] is set as the cause. \"\"\" try : await self . _sender . send ( msg ) except SenderError as err : # If this comes from a channel error, then we inject another # ChannelError having the information about the Bidirectional # channel to hide (at least partially) the underlaying # Broadcast channels we use. if isinstance ( err . __cause__ , ChannelError ): this_chan_error = ChannelError ( f \"Error in the underlying channel { err . __cause__ . channel } : { err . __cause__ } \" , self . _chan , # pylint: disable=protected-access ) this_chan_error . __cause__ = err . __cause__ err . __cause__ = this_chan_error raise err async def ready ( self ) -> bool : \"\"\"Wait until the receiver is ready with a value or an error. Once a call to `ready()` has finished, the value should be read with a call to `consume()` (`receive()` or iterated over). The receiver will remain ready (this method will return immediately) until it is consumed. Returns: Whether the receiver is still active. \"\"\" return await self . _receiver . ready () # pylint: disable=protected-access def consume ( self ) -> W : \"\"\"Return the latest value once `_ready` is complete. Returns: The next value that was received. Raises: ReceiverStoppedError: if there is some problem with the receiver. ReceiverError: if there is some problem with the receiver. # noqa: DAR401 err (https://github.com/terrencepreilly/darglint/issues/181) \"\"\" try : return self . _receiver . consume () # pylint: disable=protected-access except ReceiverError as err : # If this comes from a channel error, then we inject another # ChannelError having the information about the Bidirectional # channel to hide (at least partially) the underlaying # Broadcast channels we use. if isinstance ( err . __cause__ , ChannelError ): this_chan_error = ChannelError ( f \"Error in the underlying channel { err . __cause__ . channel } : { err . __cause__ } \" , self . _chan , # pylint: disable=protected-access ) this_chan_error . __cause__ = err . __cause__ err . __cause__ = this_chan_error raise err Functions \u00a4 __init__ ( channel , sender , receiver ) \u00a4 Create a Bidirectional.Handle instance. PARAMETER DESCRIPTION channel The underlying channel. TYPE: Bidirectional [ V , W ] | Bidirectional [ W , V ] sender A sender to send values with. TYPE: Sender [ V ] receiver A receiver to receive values from. TYPE: Receiver [ W ] Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_bidirectional.py 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 def __init__ ( self , channel : Bidirectional [ V , W ] | Bidirectional [ W , V ], sender : Sender [ V ], receiver : Receiver [ W ], ) -> None : \"\"\"Create a `Bidirectional.Handle` instance. Args: channel: The underlying channel. sender: A sender to send values with. receiver: A receiver to receive values from. \"\"\" self . _chan = channel self . _sender = sender self . _receiver = receiver consume () \u00a4 Return the latest value once _ready is complete. RETURNS DESCRIPTION W The next value that was received. RAISES DESCRIPTION ReceiverStoppedError if there is some problem with the receiver. ReceiverError if there is some problem with the receiver.","title":"Handle"},{"location":"reference/frequenz/channels/#frequenz.channels._bidirectional.Bidirectional.Handle.consume--noqa-dar401-err-httpsgithubcomterrencepreillydarglintissues181","text":"Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_bidirectional.py 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 def consume ( self ) -> W : \"\"\"Return the latest value once `_ready` is complete. Returns: The next value that was received. Raises: ReceiverStoppedError: if there is some problem with the receiver. ReceiverError: if there is some problem with the receiver. # noqa: DAR401 err (https://github.com/terrencepreilly/darglint/issues/181) \"\"\" try : return self . _receiver . consume () # pylint: disable=protected-access except ReceiverError as err : # If this comes from a channel error, then we inject another # ChannelError having the information about the Bidirectional # channel to hide (at least partially) the underlaying # Broadcast channels we use. if isinstance ( err . __cause__ , ChannelError ): this_chan_error = ChannelError ( f \"Error in the underlying channel { err . __cause__ . channel } : { err . __cause__ } \" , self . _chan , # pylint: disable=protected-access ) this_chan_error . __cause__ = err . __cause__ err . __cause__ = this_chan_error raise err ready () async \u00a4 Wait until the receiver is ready with a value or an error. Once a call to ready() has finished, the value should be read with a call to consume() ( receive() or iterated over). The receiver will remain ready (this method will return immediately) until it is consumed. RETURNS DESCRIPTION bool Whether the receiver is still active. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_bidirectional.py 71 72 73 74 75 76 77 78 79 80 81 82 async def ready ( self ) -> bool : \"\"\"Wait until the receiver is ready with a value or an error. Once a call to `ready()` has finished, the value should be read with a call to `consume()` (`receive()` or iterated over). The receiver will remain ready (this method will return immediately) until it is consumed. Returns: Whether the receiver is still active. \"\"\" return await self . _receiver . ready () # pylint: disable=protected-access send ( msg ) async \u00a4 Send a value to the other side. PARAMETER DESCRIPTION msg The value to send. TYPE: V RAISES DESCRIPTION SenderError if the underlying channel was closed. A ChannelClosedError is set as the cause. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_bidirectional.py 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 async def send ( self , msg : V ) -> None : \"\"\"Send a value to the other side. Args: msg: The value to send. Raises: SenderError: if the underlying channel was closed. A [ChannelClosedError][frequenz.channels.ChannelClosedError] is set as the cause. \"\"\" try : await self . _sender . send ( msg ) except SenderError as err : # If this comes from a channel error, then we inject another # ChannelError having the information about the Bidirectional # channel to hide (at least partially) the underlaying # Broadcast channels we use. if isinstance ( err . __cause__ , ChannelError ): this_chan_error = ChannelError ( f \"Error in the underlying channel { err . __cause__ . channel } : { err . __cause__ } \" , self . _chan , # pylint: disable=protected-access ) this_chan_error . __cause__ = err . __cause__ err . __cause__ = this_chan_error raise err","title":"noqa: DAR401 err (https://github.com/terrencepreilly/darglint/issues/181)"},{"location":"reference/frequenz/channels/#frequenz.channels.Bidirectional-functions","text":"","title":"Functions"},{"location":"reference/frequenz/channels/#frequenz.channels._bidirectional.Bidirectional.__init__","text":"Create a Bidirectional instance. PARAMETER DESCRIPTION client_id A name for the client, used to name the channels. TYPE: str service_id A name for the service end of the channels. TYPE: str Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_bidirectional.py 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 def __init__ ( self , client_id : str , service_id : str ) -> None : \"\"\"Create a `Bidirectional` instance. Args: client_id: A name for the client, used to name the channels. service_id: A name for the service end of the channels. \"\"\" self . _client_id = client_id self . _request_channel : Broadcast [ T ] = Broadcast ( f \"req_ { service_id } _ { client_id } \" ) self . _response_channel : Broadcast [ U ] = Broadcast ( f \"resp_ { service_id } _ { client_id } \" ) self . _client_handle = Bidirectional . Handle ( self , self . _request_channel . new_sender (), self . _response_channel . new_receiver (), ) self . _service_handle = Bidirectional . Handle ( self , self . _response_channel . new_sender (), self . _request_channel . new_receiver (), )","title":"__init__()"},{"location":"reference/frequenz/channels/#frequenz.channels.Broadcast","text":"Bases: Generic [ T ] A channel to broadcast messages to multiple receivers. Broadcast channels can have multiple senders and multiple receivers. Each message sent through any of the senders is received by all of the receivers. Internally, a broadcast receiver's buffer is implemented with just append/pop operations on either side of a deque , which are thread-safe. Because of this, Broadcast channels are thread-safe. When there are multiple channel receivers, they can be awaited simultaneously using Select , Merge or MergeNamed . Example async def send ( sender : channel . Sender ) -> None : while True : next = random . randint ( 3 , 17 ) print ( f \"sending: { next } \" ) await sender . send ( next ) async def recv ( id : int , receiver : channel . Receiver ) -> None : while True : next = await receiver . receive () print ( f \"receiver_ { id } received { next } \" ) await asyncio . sleep ( 0.1 ) # sleep (or work) with the data bcast = channel . Broadcast () sender = bcast . new_sender () receiver_1 = bcast . new_receiver () asyncio . create_task ( send ( sender )) await recv ( 1 , receiver_1 ) Check the tests and benchmarks directories for more examples. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_broadcast.py 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 class Broadcast ( Generic [ T ]): \"\"\"A channel to broadcast messages to multiple receivers. `Broadcast` channels can have multiple senders and multiple receivers. Each message sent through any of the senders is received by all of the receivers. Internally, a broadcast receiver's buffer is implemented with just append/pop operations on either side of a [deque][collections.deque], which are thread-safe. Because of this, `Broadcast` channels are thread-safe. When there are multiple channel receivers, they can be awaited simultaneously using [Select][frequenz.channels.util.Select], [Merge][frequenz.channels.util.Merge] or [MergeNamed][frequenz.channels.util.MergeNamed]. Example: ``` python async def send(sender: channel.Sender) -> None: while True: next = random.randint(3, 17) print(f\"sending: {next}\") await sender.send(next) async def recv(id: int, receiver: channel.Receiver) -> None: while True: next = await receiver.receive() print(f\"receiver_{id} received {next}\") await asyncio.sleep(0.1) # sleep (or work) with the data bcast = channel.Broadcast() sender = bcast.new_sender() receiver_1 = bcast.new_receiver() asyncio.create_task(send(sender)) await recv(1, receiver_1) ``` Check the `tests` and `benchmarks` directories for more examples. \"\"\" def __init__ ( self , name : str , resend_latest : bool = False ) -> None : \"\"\"Create a Broadcast channel. Args: name: A name for the broadcast channel, typically based on the type of data sent through it. Used to identify the channel in the logs. resend_latest: When True, every time a new receiver is created with `new_receiver`, it will automatically get sent the latest value on the channel. This allows new receivers on slow streams to get the latest value as soon as they are created, without having to wait for the next message on the channel to arrive. \"\"\" self . name : str = name self . _resend_latest = resend_latest self . recv_cv : Condition = Condition () self . receivers : Dict [ UUID , weakref . ReferenceType [ Receiver [ T ]]] = {} self . closed : bool = False self . _latest : Optional [ T ] = None async def close ( self ) -> None : \"\"\"Close the Broadcast channel. Any further attempts to [send()][frequenz.channels.Sender.send] data will return `False`. Receivers will still be able to drain the pending items on their queues, but after that, subsequent [receive()][frequenz.channels.Receiver.receive] calls will return `None` immediately. \"\"\" self . _latest = None self . closed = True async with self . recv_cv : self . recv_cv . notify_all () def new_sender ( self ) -> Sender [ T ]: \"\"\"Create a new broadcast sender. Returns: A Sender instance attached to the broadcast channel. \"\"\" return Sender ( self ) def new_receiver ( self , name : Optional [ str ] = None , maxsize : int = 50 ) -> Receiver [ T ]: \"\"\"Create a new broadcast receiver. Broadcast receivers have their own buffer, and when messages are not being consumed fast enough and the buffer fills up, old messages will get dropped just in this receiver. Args: name: A name to identify the receiver in the logs. maxsize: Size of the receiver's buffer. Returns: A Receiver instance attached to the broadcast channel. \"\"\" uuid = uuid4 () if name is None : name = str ( uuid ) recv : Receiver [ T ] = Receiver ( uuid , name , maxsize , self ) self . receivers [ uuid ] = weakref . ref ( recv ) if self . _resend_latest and self . _latest is not None : recv . enqueue ( self . _latest ) return recv def new_peekable ( self ) -> Peekable [ T ]: \"\"\"Create a new Peekable for the broadcast channel. A Peekable provides a [peek()][frequenz.channels.Peekable.peek] method that allows the user to get a peek at the latest value in the channel, without consuming anything. Returns: A Peekable to peek into the broadcast channel with. \"\"\" return Peekable ( self )","title":"Broadcast"},{"location":"reference/frequenz/channels/#frequenz.channels.Broadcast-functions","text":"","title":"Functions"},{"location":"reference/frequenz/channels/#frequenz.channels._broadcast.Broadcast.__init__","text":"Create a Broadcast channel. PARAMETER DESCRIPTION name A name for the broadcast channel, typically based on the type of data sent through it. Used to identify the channel in the logs. TYPE: str resend_latest When True, every time a new receiver is created with new_receiver , it will automatically get sent the latest value on the channel. This allows new receivers on slow streams to get the latest value as soon as they are created, without having to wait for the next message on the channel to arrive. TYPE: bool DEFAULT: False Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_broadcast.py 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 def __init__ ( self , name : str , resend_latest : bool = False ) -> None : \"\"\"Create a Broadcast channel. Args: name: A name for the broadcast channel, typically based on the type of data sent through it. Used to identify the channel in the logs. resend_latest: When True, every time a new receiver is created with `new_receiver`, it will automatically get sent the latest value on the channel. This allows new receivers on slow streams to get the latest value as soon as they are created, without having to wait for the next message on the channel to arrive. \"\"\" self . name : str = name self . _resend_latest = resend_latest self . recv_cv : Condition = Condition () self . receivers : Dict [ UUID , weakref . ReferenceType [ Receiver [ T ]]] = {} self . closed : bool = False self . _latest : Optional [ T ] = None","title":"__init__()"},{"location":"reference/frequenz/channels/#frequenz.channels._broadcast.Broadcast.close","text":"Close the Broadcast channel. Any further attempts to send() data will return False . Receivers will still be able to drain the pending items on their queues, but after that, subsequent receive() calls will return None immediately. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_broadcast.py 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 async def close ( self ) -> None : \"\"\"Close the Broadcast channel. Any further attempts to [send()][frequenz.channels.Sender.send] data will return `False`. Receivers will still be able to drain the pending items on their queues, but after that, subsequent [receive()][frequenz.channels.Receiver.receive] calls will return `None` immediately. \"\"\" self . _latest = None self . closed = True async with self . recv_cv : self . recv_cv . notify_all ()","title":"close()"},{"location":"reference/frequenz/channels/#frequenz.channels._broadcast.Broadcast.new_peekable","text":"Create a new Peekable for the broadcast channel. A Peekable provides a peek() method that allows the user to get a peek at the latest value in the channel, without consuming anything. RETURNS DESCRIPTION Peekable [ T ] A Peekable to peek into the broadcast channel with. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_broadcast.py 144 145 146 147 148 149 150 151 152 153 154 def new_peekable ( self ) -> Peekable [ T ]: \"\"\"Create a new Peekable for the broadcast channel. A Peekable provides a [peek()][frequenz.channels.Peekable.peek] method that allows the user to get a peek at the latest value in the channel, without consuming anything. Returns: A Peekable to peek into the broadcast channel with. \"\"\" return Peekable ( self )","title":"new_peekable()"},{"location":"reference/frequenz/channels/#frequenz.channels._broadcast.Broadcast.new_receiver","text":"Create a new broadcast receiver. Broadcast receivers have their own buffer, and when messages are not being consumed fast enough and the buffer fills up, old messages will get dropped just in this receiver. PARAMETER DESCRIPTION name A name to identify the receiver in the logs. TYPE: Optional [ str ] DEFAULT: None maxsize Size of the receiver's buffer. TYPE: int DEFAULT: 50 RETURNS DESCRIPTION Receiver [ T ] A Receiver instance attached to the broadcast channel. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_broadcast.py 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 def new_receiver ( self , name : Optional [ str ] = None , maxsize : int = 50 ) -> Receiver [ T ]: \"\"\"Create a new broadcast receiver. Broadcast receivers have their own buffer, and when messages are not being consumed fast enough and the buffer fills up, old messages will get dropped just in this receiver. Args: name: A name to identify the receiver in the logs. maxsize: Size of the receiver's buffer. Returns: A Receiver instance attached to the broadcast channel. \"\"\" uuid = uuid4 () if name is None : name = str ( uuid ) recv : Receiver [ T ] = Receiver ( uuid , name , maxsize , self ) self . receivers [ uuid ] = weakref . ref ( recv ) if self . _resend_latest and self . _latest is not None : recv . enqueue ( self . _latest ) return recv","title":"new_receiver()"},{"location":"reference/frequenz/channels/#frequenz.channels._broadcast.Broadcast.new_sender","text":"Create a new broadcast sender. RETURNS DESCRIPTION Sender [ T ] A Sender instance attached to the broadcast channel. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_broadcast.py 111 112 113 114 115 116 117 def new_sender ( self ) -> Sender [ T ]: \"\"\"Create a new broadcast sender. Returns: A Sender instance attached to the broadcast channel. \"\"\" return Sender ( self )","title":"new_sender()"},{"location":"reference/frequenz/channels/#frequenz.channels.ChannelClosedError","text":"Bases: ChannelError Error raised when trying to operate on a closed channel. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_exceptions.py 48 49 50 51 52 53 54 55 56 57 class ChannelClosedError ( ChannelError ): \"\"\"Error raised when trying to operate on a closed channel.\"\"\" def __init__ ( self , channel : Any ): \"\"\"Create a `ChannelClosedError` instance. Args: channel: A reference to the channel that was closed. \"\"\" super () . __init__ ( f \"Channel { channel } was closed\" , channel )","title":"ChannelClosedError"},{"location":"reference/frequenz/channels/#frequenz.channels.ChannelClosedError-functions","text":"","title":"Functions"},{"location":"reference/frequenz/channels/#frequenz.channels._exceptions.ChannelClosedError.__init__","text":"Create a ChannelClosedError instance. PARAMETER DESCRIPTION channel A reference to the channel that was closed. TYPE: Any Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_exceptions.py 51 52 53 54 55 56 57 def __init__ ( self , channel : Any ): \"\"\"Create a `ChannelClosedError` instance. Args: channel: A reference to the channel that was closed. \"\"\" super () . __init__ ( f \"Channel { channel } was closed\" , channel )","title":"__init__()"},{"location":"reference/frequenz/channels/#frequenz.channels.ChannelError","text":"Bases: Error An error produced in a channel. All exceptions generated by channels inherit from this exception. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_exceptions.py 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 class ChannelError ( Error ): \"\"\"An error produced in a channel. All exceptions generated by channels inherit from this exception. \"\"\" def __init__ ( self , message : Any , channel : Any ): \"\"\"Create a ChannelError instance. Args: message: An error message. channel: A reference to the channel that encountered the error. \"\"\" super () . __init__ ( message ) self . channel : Any = channel","title":"ChannelError"},{"location":"reference/frequenz/channels/#frequenz.channels.ChannelError-functions","text":"","title":"Functions"},{"location":"reference/frequenz/channels/#frequenz.channels._exceptions.ChannelError.__init__","text":"Create a ChannelError instance. PARAMETER DESCRIPTION message An error message. TYPE: Any channel A reference to the channel that encountered the error. TYPE: Any Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_exceptions.py 37 38 39 40 41 42 43 44 45 def __init__ ( self , message : Any , channel : Any ): \"\"\"Create a ChannelError instance. Args: message: An error message. channel: A reference to the channel that encountered the error. \"\"\" super () . __init__ ( message ) self . channel : Any = channel","title":"__init__()"},{"location":"reference/frequenz/channels/#frequenz.channels.Error","text":"Bases: RuntimeError Base error. All exceptions generated by this library inherit from this exception. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_exceptions.py 16 17 18 19 20 21 22 23 24 25 26 27 28 class Error ( RuntimeError ): \"\"\"Base error. All exceptions generated by this library inherit from this exception. \"\"\" def __init__ ( self , message : Any ): \"\"\"Create a ChannelError instance. Args: message: An error message. \"\"\" super () . __init__ ( message )","title":"Error"},{"location":"reference/frequenz/channels/#frequenz.channels.Error-functions","text":"","title":"Functions"},{"location":"reference/frequenz/channels/#frequenz.channels._exceptions.Error.__init__","text":"Create a ChannelError instance. PARAMETER DESCRIPTION message An error message. TYPE: Any Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_exceptions.py 22 23 24 25 26 27 28 def __init__ ( self , message : Any ): \"\"\"Create a ChannelError instance. Args: message: An error message. \"\"\" super () . __init__ ( message )","title":"__init__()"},{"location":"reference/frequenz/channels/#frequenz.channels.Peekable","text":"Bases: ABC , Generic [ T ] A channel peekable. A Peekable provides a peek() method that allows the user to get a peek at the latest value in the channel, without consuming anything. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_base_classes.py 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 class Peekable ( ABC , Generic [ T ]): \"\"\"A channel peekable. A Peekable provides a [peek()][frequenz.channels.Peekable] method that allows the user to get a peek at the latest value in the channel, without consuming anything. \"\"\" @abstractmethod def peek ( self ) -> Optional [ T ]: \"\"\"Return the latest value that was sent to the channel. Returns: The latest value received by the channel, and `None`, if nothing has been sent to the channel yet. \"\"\"","title":"Peekable"},{"location":"reference/frequenz/channels/#frequenz.channels.Peekable-functions","text":"","title":"Functions"},{"location":"reference/frequenz/channels/#frequenz.channels._base_classes.Peekable.peek","text":"Return the latest value that was sent to the channel. RETURNS DESCRIPTION Optional [ T ] The latest value received by the channel, and None , if nothing has been sent to the channel yet. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_base_classes.py 147 148 149 150 151 152 153 154 @abstractmethod def peek ( self ) -> Optional [ T ]: \"\"\"Return the latest value that was sent to the channel. Returns: The latest value received by the channel, and `None`, if nothing has been sent to the channel yet. \"\"\"","title":"peek()"},{"location":"reference/frequenz/channels/#frequenz.channels.Receiver","text":"Bases: ABC , Generic [ T ] A channel Receiver. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_base_classes.py 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 class Receiver ( ABC , Generic [ T ]): \"\"\"A channel Receiver.\"\"\" async def __anext__ ( self ) -> T : \"\"\"Await the next value in the async iteration over received values. Returns: The next value received. Raises: StopAsyncIteration: if the receiver stopped producing messages. ReceiverError: if there is some problem with the receiver. \"\"\" try : await self . ready () return self . consume () except ReceiverStoppedError as exc : raise StopAsyncIteration () from exc @abstractmethod async def ready ( self ) -> bool : \"\"\"Wait until the receiver is ready with a value or an error. Once a call to `ready()` has finished, the value should be read with a call to `consume()` (`receive()` or iterated over). The receiver will remain ready (this method will return immediately) until it is consumed. Returns: Whether the receiver is still active. \"\"\" @abstractmethod def consume ( self ) -> T : \"\"\"Return the latest value once `ready()` is complete. `ready()` must be called before each call to `consume()`. Returns: The next value received. Raises: ReceiverStoppedError: if the receiver stopped producing messages. ReceiverError: if there is some problem with the receiver. \"\"\" def __aiter__ ( self ) -> Receiver [ T ]: \"\"\"Initialize the async iterator over received values. Returns: `self`, since no extra setup is needed for the iterator. \"\"\" return self async def receive ( self ) -> T : \"\"\"Receive a message from the channel. Returns: The received message. Raises: ReceiverStoppedError: if there is some problem with the receiver. ReceiverError: if there is some problem with the receiver. # noqa: DAR401 __cause__ (https://github.com/terrencepreilly/darglint/issues/181) \"\"\" try : received = await self . __anext__ () # pylint: disable=unnecessary-dunder-call except StopAsyncIteration as exc : # If we already had a cause and it was the receiver was stopped, # then reuse that error, as StopAsyncIteration is just an artifact # introduced by __anext__. if ( isinstance ( exc . __cause__ , ReceiverStoppedError ) # pylint is not smart enough to figure out we checked above # this is a ReceiverStoppedError and thus it does have # a receiver member and exc . __cause__ . receiver is self # pylint: disable=no-member ): raise exc . __cause__ raise ReceiverStoppedError ( self ) from exc return received def map ( self , call : Callable [[ T ], U ]) -> Receiver [ U ]: \"\"\"Return a receiver with `call` applied on incoming messages. Args: call: function to apply on incoming messages. Returns: A `Receiver` to read results of the given function from. \"\"\" return _Map ( self , call ) def into_peekable ( self ) -> Peekable [ T ]: \"\"\"Convert the `Receiver` implementation into a `Peekable`. Once this function has been called, the receiver will no longer be usable, and calling `receive` on the receiver will raise an exception. Raises: NotImplementedError: when a `Receiver` implementation doesn't have a custom `into_peekable` implementation. \"\"\" raise NotImplementedError ( \"This receiver does not implement `into_peekable`\" )","title":"Receiver"},{"location":"reference/frequenz/channels/#frequenz.channels.Receiver-functions","text":"","title":"Functions"},{"location":"reference/frequenz/channels/#frequenz.channels._base_classes.Receiver.__aiter__","text":"Initialize the async iterator over received values. RETURNS DESCRIPTION Receiver [ T ] self , since no extra setup is needed for the iterator. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_base_classes.py 78 79 80 81 82 83 84 def __aiter__ ( self ) -> Receiver [ T ]: \"\"\"Initialize the async iterator over received values. Returns: `self`, since no extra setup is needed for the iterator. \"\"\" return self","title":"__aiter__()"},{"location":"reference/frequenz/channels/#frequenz.channels._base_classes.Receiver.__anext__","text":"Await the next value in the async iteration over received values. RETURNS DESCRIPTION T The next value received. RAISES DESCRIPTION StopAsyncIteration if the receiver stopped producing messages. ReceiverError if there is some problem with the receiver. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_base_classes.py 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 async def __anext__ ( self ) -> T : \"\"\"Await the next value in the async iteration over received values. Returns: The next value received. Raises: StopAsyncIteration: if the receiver stopped producing messages. ReceiverError: if there is some problem with the receiver. \"\"\" try : await self . ready () return self . consume () except ReceiverStoppedError as exc : raise StopAsyncIteration () from exc","title":"__anext__()"},{"location":"reference/frequenz/channels/#frequenz.channels._base_classes.Receiver.consume","text":"Return the latest value once ready() is complete. ready() must be called before each call to consume() . RETURNS DESCRIPTION T The next value received. RAISES DESCRIPTION ReceiverStoppedError if the receiver stopped producing messages. ReceiverError if there is some problem with the receiver. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_base_classes.py 64 65 66 67 68 69 70 71 72 73 74 75 76 @abstractmethod def consume ( self ) -> T : \"\"\"Return the latest value once `ready()` is complete. `ready()` must be called before each call to `consume()`. Returns: The next value received. Raises: ReceiverStoppedError: if the receiver stopped producing messages. ReceiverError: if there is some problem with the receiver. \"\"\"","title":"consume()"},{"location":"reference/frequenz/channels/#frequenz.channels._base_classes.Receiver.into_peekable","text":"Convert the Receiver implementation into a Peekable . Once this function has been called, the receiver will no longer be usable, and calling receive on the receiver will raise an exception. RAISES DESCRIPTION NotImplementedError when a Receiver implementation doesn't have a custom into_peekable implementation. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_base_classes.py 126 127 128 129 130 131 132 133 134 135 136 def into_peekable ( self ) -> Peekable [ T ]: \"\"\"Convert the `Receiver` implementation into a `Peekable`. Once this function has been called, the receiver will no longer be usable, and calling `receive` on the receiver will raise an exception. Raises: NotImplementedError: when a `Receiver` implementation doesn't have a custom `into_peekable` implementation. \"\"\" raise NotImplementedError ( \"This receiver does not implement `into_peekable`\" )","title":"into_peekable()"},{"location":"reference/frequenz/channels/#frequenz.channels._base_classes.Receiver.map","text":"Return a receiver with call applied on incoming messages. PARAMETER DESCRIPTION call function to apply on incoming messages. TYPE: Callable [[ T ], U ] RETURNS DESCRIPTION Receiver [ U ] A Receiver to read results of the given function from. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_base_classes.py 115 116 117 118 119 120 121 122 123 124 def map ( self , call : Callable [[ T ], U ]) -> Receiver [ U ]: \"\"\"Return a receiver with `call` applied on incoming messages. Args: call: function to apply on incoming messages. Returns: A `Receiver` to read results of the given function from. \"\"\" return _Map ( self , call )","title":"map()"},{"location":"reference/frequenz/channels/#frequenz.channels._base_classes.Receiver.ready","text":"Wait until the receiver is ready with a value or an error. Once a call to ready() has finished, the value should be read with a call to consume() ( receive() or iterated over). The receiver will remain ready (this method will return immediately) until it is consumed. RETURNS DESCRIPTION bool Whether the receiver is still active. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_base_classes.py 51 52 53 54 55 56 57 58 59 60 61 62 @abstractmethod async def ready ( self ) -> bool : \"\"\"Wait until the receiver is ready with a value or an error. Once a call to `ready()` has finished, the value should be read with a call to `consume()` (`receive()` or iterated over). The receiver will remain ready (this method will return immediately) until it is consumed. Returns: Whether the receiver is still active. \"\"\"","title":"ready()"},{"location":"reference/frequenz/channels/#frequenz.channels._base_classes.Receiver.receive","text":"Receive a message from the channel. RETURNS DESCRIPTION T The received message. RAISES DESCRIPTION ReceiverStoppedError if there is some problem with the receiver. ReceiverError if there is some problem with the receiver.","title":"receive()"},{"location":"reference/frequenz/channels/#frequenz.channels._base_classes.Receiver.receive--noqa-dar401-cause-httpsgithubcomterrencepreillydarglintissues181","text":"Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_base_classes.py 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 async def receive ( self ) -> T : \"\"\"Receive a message from the channel. Returns: The received message. Raises: ReceiverStoppedError: if there is some problem with the receiver. ReceiverError: if there is some problem with the receiver. # noqa: DAR401 __cause__ (https://github.com/terrencepreilly/darglint/issues/181) \"\"\" try : received = await self . __anext__ () # pylint: disable=unnecessary-dunder-call except StopAsyncIteration as exc : # If we already had a cause and it was the receiver was stopped, # then reuse that error, as StopAsyncIteration is just an artifact # introduced by __anext__. if ( isinstance ( exc . __cause__ , ReceiverStoppedError ) # pylint is not smart enough to figure out we checked above # this is a ReceiverStoppedError and thus it does have # a receiver member and exc . __cause__ . receiver is self # pylint: disable=no-member ): raise exc . __cause__ raise ReceiverStoppedError ( self ) from exc return received","title":"noqa: DAR401 cause (https://github.com/terrencepreilly/darglint/issues/181)"},{"location":"reference/frequenz/channels/#frequenz.channels.ReceiverError","text":"Bases: Error , Generic [ T ] An error produced in a Receiver . All exceptions generated by receivers inherit from this exception. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_exceptions.py 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 class ReceiverError ( Error , Generic [ T ]): \"\"\"An error produced in a [Receiver][frequenz.channels.Receiver]. All exceptions generated by receivers inherit from this exception. \"\"\" def __init__ ( self , message : Any , receiver : _base_classes . Receiver [ T ]): \"\"\"Create an instance. Args: message: An error message. receiver: The [Receiver][frequenz.channels.Receiver] where the error happened. \"\"\" super () . __init__ ( message ) self . receiver : _base_classes . Receiver [ T ] = receiver","title":"ReceiverError"},{"location":"reference/frequenz/channels/#frequenz.channels.ReceiverError-functions","text":"","title":"Functions"},{"location":"reference/frequenz/channels/#frequenz.channels._exceptions.ReceiverError.__init__","text":"Create an instance. PARAMETER DESCRIPTION message An error message. TYPE: Any receiver The Receiver where the error happened. TYPE: _base_classes . Receiver [ T ] Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_exceptions.py 84 85 86 87 88 89 90 91 92 93 def __init__ ( self , message : Any , receiver : _base_classes . Receiver [ T ]): \"\"\"Create an instance. Args: message: An error message. receiver: The [Receiver][frequenz.channels.Receiver] where the error happened. \"\"\" super () . __init__ ( message ) self . receiver : _base_classes . Receiver [ T ] = receiver","title":"__init__()"},{"location":"reference/frequenz/channels/#frequenz.channels.ReceiverInvalidatedError","text":"Bases: ReceiverError [ T ] The Receiver was invalidated. This happens when the Receiver is converted into a Peekable . Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_exceptions.py 109 110 111 112 113 114 115 class ReceiverInvalidatedError ( ReceiverError [ T ]): \"\"\"The [Receiver][frequenz.channels.Receiver] was invalidated. This happens when the Receiver is converted [into][frequenz.channels.Receiver.into_peekable] a [Peekable][frequenz.channels.Peekable]. \"\"\"","title":"ReceiverInvalidatedError"},{"location":"reference/frequenz/channels/#frequenz.channels.ReceiverStoppedError","text":"Bases: ReceiverError [ T ] The Receiver stopped producing messages. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_exceptions.py 96 97 98 99 100 101 102 103 104 105 106 class ReceiverStoppedError ( ReceiverError [ T ]): \"\"\"The [Receiver][frequenz.channels.Receiver] stopped producing messages.\"\"\" def __init__ ( self , receiver : _base_classes . Receiver [ T ]): \"\"\"Create an instance. Args: receiver: The [Receiver][frequenz.channels.Receiver] where the error happened. \"\"\" super () . __init__ ( f \"Receiver { receiver } was stopped\" , receiver )","title":"ReceiverStoppedError"},{"location":"reference/frequenz/channels/#frequenz.channels.ReceiverStoppedError-functions","text":"","title":"Functions"},{"location":"reference/frequenz/channels/#frequenz.channels._exceptions.ReceiverStoppedError.__init__","text":"Create an instance. PARAMETER DESCRIPTION receiver The Receiver where the error happened. TYPE: _base_classes . Receiver [ T ] Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_exceptions.py 99 100 101 102 103 104 105 106 def __init__ ( self , receiver : _base_classes . Receiver [ T ]): \"\"\"Create an instance. Args: receiver: The [Receiver][frequenz.channels.Receiver] where the error happened. \"\"\" super () . __init__ ( f \"Receiver { receiver } was stopped\" , receiver )","title":"__init__()"},{"location":"reference/frequenz/channels/#frequenz.channels.Sender","text":"Bases: ABC , Generic [ T ] A channel Sender. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_base_classes.py 17 18 19 20 21 22 23 24 25 26 27 28 29 class Sender ( ABC , Generic [ T ]): \"\"\"A channel Sender.\"\"\" @abstractmethod async def send ( self , msg : T ) -> None : \"\"\"Send a message to the channel. Args: msg: The message to be sent. Raises: SenderError: if there was an error sending the message. \"\"\"","title":"Sender"},{"location":"reference/frequenz/channels/#frequenz.channels.Sender-functions","text":"","title":"Functions"},{"location":"reference/frequenz/channels/#frequenz.channels._base_classes.Sender.send","text":"Send a message to the channel. PARAMETER DESCRIPTION msg The message to be sent. TYPE: T RAISES DESCRIPTION SenderError if there was an error sending the message. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_base_classes.py 20 21 22 23 24 25 26 27 28 29 @abstractmethod async def send ( self , msg : T ) -> None : \"\"\"Send a message to the channel. Args: msg: The message to be sent. Raises: SenderError: if there was an error sending the message. \"\"\"","title":"send()"},{"location":"reference/frequenz/channels/#frequenz.channels.SenderError","text":"Bases: Error , Generic [ T ] An error produced in a Sender . All exceptions generated by senders inherit from this exception. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_exceptions.py 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 class SenderError ( Error , Generic [ T ]): \"\"\"An error produced in a [Sender][frequenz.channels.Sender]. All exceptions generated by senders inherit from this exception. \"\"\" def __init__ ( self , message : Any , sender : _base_classes . Sender [ T ]): \"\"\"Create an instance. Args: message: An error message. sender: The [Sender][frequenz.channels.Sender] where the error happened. \"\"\" super () . __init__ ( message ) self . sender : _base_classes . Sender [ T ] = sender","title":"SenderError"},{"location":"reference/frequenz/channels/#frequenz.channels.SenderError-functions","text":"","title":"Functions"},{"location":"reference/frequenz/channels/#frequenz.channels._exceptions.SenderError.__init__","text":"Create an instance. PARAMETER DESCRIPTION message An error message. TYPE: Any sender The Sender where the error happened. TYPE: _base_classes . Sender [ T ] Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/_exceptions.py 66 67 68 69 70 71 72 73 74 75 def __init__ ( self , message : Any , sender : _base_classes . Sender [ T ]): \"\"\"Create an instance. Args: message: An error message. sender: The [Sender][frequenz.channels.Sender] where the error happened. \"\"\" super () . __init__ ( message ) self . sender : _base_classes . Sender [ T ] = sender","title":"__init__()"},{"location":"reference/frequenz/channels/util/","text":"frequenz.channels.util \u00a4 Channel utilities. A module with several utilities to work with channels: FileWatcher : A receiver that watches for file events. Merge : A receiver that merge messages coming from multiple receivers into a single stream. MergeNamed : A receiver that merge messages coming from multiple receivers into a single named stream, allowing to identify the origin of each message. Timer : A receiver that ticks at certain intervals. Select : A helper to select the next available message for each receiver in a group of receivers. Classes \u00a4 frequenz.channels.util.FileWatcher \u00a4 Bases: Receiver [ Event ] A channel receiver that watches for file events. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_file_watcher.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 class FileWatcher ( Receiver [ \"FileWatcher.Event\" ]): \"\"\"A channel receiver that watches for file events.\"\"\" class EventType ( Enum ): \"\"\"Available types of changes to watch for.\"\"\" CREATE = Change . added MODIFY = Change . modified DELETE = Change . deleted @dataclass ( frozen = True ) class Event : \"\"\"A file change event.\"\"\" type : FileWatcher . EventType \"\"\"The type of change that was observed.\"\"\" path : pathlib . Path \"\"\"The path where the change was observed.\"\"\" def __init__ ( self , paths : list [ pathlib . Path | str ], event_types : set [ EventType ] | None = None , ) -> None : \"\"\"Create a `FileWatcher` instance. Args: paths: Paths to watch for changes. event_types: Types of events to watch for or `None` to watch for all event types. \"\"\" if event_types is None : event_types = set ( FileWatcher . EventType ) # all types self . event_types = event_types self . _stop_event = asyncio . Event () self . _paths = [ path if isinstance ( path , pathlib . Path ) else pathlib . Path ( path ) for path in paths ] self . _awatch = awatch ( * self . _paths , stop_event = self . _stop_event , watch_filter = self . _filter_events ) self . _awatch_stopped_exc : Exception | None = None self . _changes : set [ FileChange ] = set () def _filter_events ( self , change : Change , path : str , # pylint: disable=unused-argument ) -> bool : \"\"\"Filter events based on the event type and path. Args: change: The type of change to be notified. path: The path of the file that changed. Returns: Whether the event should be notified. \"\"\" return change in [ event_type . value for event_type in self . event_types ] def __del__ ( self ) -> None : \"\"\"Cleanup registered watches. `awatch` passes the `stop_event` to a separate task/thread. This way `awatch` getting destroyed properly. The background task will continue until the signal is received. \"\"\" self . _stop_event . set () async def ready ( self ) -> bool : \"\"\"Wait until the receiver is ready with a value or an error. Once a call to `ready()` has finished, the value should be read with a call to `consume()` (`receive()` or iterated over). The receiver will remain ready (this method will return immediately) until it is consumed. Returns: Whether the receiver is still active. \"\"\" # if there are messages waiting to be consumed, return immediately. if self . _changes : return True # if it was already stopped, return immediately. if self . _awatch_stopped_exc is not None : return False try : self . _changes = await self . _awatch . __anext__ () except StopAsyncIteration as err : self . _awatch_stopped_exc = err return True def consume ( self ) -> Event : \"\"\"Return the latest event once `ready` is complete. Returns: The next event that was received. Raises: ReceiverStoppedError: if there is some problem with the receiver. \"\"\" if not self . _changes and self . _awatch_stopped_exc is not None : raise ReceiverStoppedError ( self ) from self._awatch_stopped_exc assert self . _changes , \"`consume()` must be preceeded by a call to `ready()`\" # Tuple of (Change, path) returned by watchfiles change , path_str = self . _changes . pop () return FileWatcher . Event ( type = FileWatcher . EventType ( change ), path = pathlib . Path ( path_str ) ) Classes \u00a4 Event dataclass \u00a4 A file change event. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_file_watcher.py 30 31 32 33 34 35 36 37 @dataclass ( frozen = True ) class Event : \"\"\"A file change event.\"\"\" type : FileWatcher . EventType \"\"\"The type of change that was observed.\"\"\" path : pathlib . Path \"\"\"The path where the change was observed.\"\"\" Attributes \u00a4 path : pathlib . Path instance-attribute \u00a4 The path where the change was observed. type : FileWatcher . EventType instance-attribute \u00a4 The type of change that was observed. EventType \u00a4 Bases: Enum Available types of changes to watch for. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_file_watcher.py 23 24 25 26 27 28 class EventType ( Enum ): \"\"\"Available types of changes to watch for.\"\"\" CREATE = Change . added MODIFY = Change . modified DELETE = Change . deleted Functions \u00a4 __del__ () \u00a4 Cleanup registered watches. awatch passes the stop_event to a separate task/thread. This way awatch getting destroyed properly. The background task will continue until the signal is received. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_file_watcher.py 82 83 84 85 86 87 88 89 def __del__ ( self ) -> None : \"\"\"Cleanup registered watches. `awatch` passes the `stop_event` to a separate task/thread. This way `awatch` getting destroyed properly. The background task will continue until the signal is received. \"\"\" self . _stop_event . set () __init__ ( paths , event_types = None ) \u00a4 Create a FileWatcher instance. PARAMETER DESCRIPTION paths Paths to watch for changes. TYPE: list [ pathlib . Path | str ] event_types Types of events to watch for or None to watch for all event types. TYPE: set [ EventType ] | None DEFAULT: None Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_file_watcher.py 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 def __init__ ( self , paths : list [ pathlib . Path | str ], event_types : set [ EventType ] | None = None , ) -> None : \"\"\"Create a `FileWatcher` instance. Args: paths: Paths to watch for changes. event_types: Types of events to watch for or `None` to watch for all event types. \"\"\" if event_types is None : event_types = set ( FileWatcher . EventType ) # all types self . event_types = event_types self . _stop_event = asyncio . Event () self . _paths = [ path if isinstance ( path , pathlib . Path ) else pathlib . Path ( path ) for path in paths ] self . _awatch = awatch ( * self . _paths , stop_event = self . _stop_event , watch_filter = self . _filter_events ) self . _awatch_stopped_exc : Exception | None = None self . _changes : set [ FileChange ] = set () consume () \u00a4 Return the latest event once ready is complete. RETURNS DESCRIPTION Event The next event that was received. RAISES DESCRIPTION ReceiverStoppedError if there is some problem with the receiver. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_file_watcher.py 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 def consume ( self ) -> Event : \"\"\"Return the latest event once `ready` is complete. Returns: The next event that was received. Raises: ReceiverStoppedError: if there is some problem with the receiver. \"\"\" if not self . _changes and self . _awatch_stopped_exc is not None : raise ReceiverStoppedError ( self ) from self._awatch_stopped_exc assert self . _changes , \"`consume()` must be preceeded by a call to `ready()`\" # Tuple of (Change, path) returned by watchfiles change , path_str = self . _changes . pop () return FileWatcher . Event ( type = FileWatcher . EventType ( change ), path = pathlib . Path ( path_str ) ) ready () async \u00a4 Wait until the receiver is ready with a value or an error. Once a call to ready() has finished, the value should be read with a call to consume() ( receive() or iterated over). The receiver will remain ready (this method will return immediately) until it is consumed. RETURNS DESCRIPTION bool Whether the receiver is still active. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_file_watcher.py 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 async def ready ( self ) -> bool : \"\"\"Wait until the receiver is ready with a value or an error. Once a call to `ready()` has finished, the value should be read with a call to `consume()` (`receive()` or iterated over). The receiver will remain ready (this method will return immediately) until it is consumed. Returns: Whether the receiver is still active. \"\"\" # if there are messages waiting to be consumed, return immediately. if self . _changes : return True # if it was already stopped, return immediately. if self . _awatch_stopped_exc is not None : return False try : self . _changes = await self . _awatch . __anext__ () except StopAsyncIteration as err : self . _awatch_stopped_exc = err return True frequenz.channels.util.Merge \u00a4 Bases: Receiver [ T ] Merge messages coming from multiple channels into a single stream. Example For example, if there are two channel receivers with the same type, they can be awaited together, and their results merged into a single stream, by using Merge like this: merge = Merge ( receiver1 , receiver2 ) while msg := await merge . receive (): # do something with msg pass When merge is no longer needed, then it should be stopped using self.stop() method. This will cleanup any internal pending async tasks. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_merge.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 class Merge ( Receiver [ T ]): \"\"\"Merge messages coming from multiple channels into a single stream. Example: For example, if there are two channel receivers with the same type, they can be awaited together, and their results merged into a single stream, by using `Merge` like this: ```python merge = Merge(receiver1, receiver2) while msg := await merge.receive(): # do something with msg pass ``` When `merge` is no longer needed, then it should be stopped using `self.stop()` method. This will cleanup any internal pending async tasks. \"\"\" def __init__ ( self , * args : Receiver [ T ]) -> None : \"\"\"Create a `Merge` instance. Args: *args: sequence of channel receivers. \"\"\" self . _receivers = { str ( id ): recv for id , recv in enumerate ( args )} self . _pending : Set [ asyncio . Task [ Any ]] = { asyncio . create_task ( recv . __anext__ (), name = name ) for name , recv in self . _receivers . items () } self . _results : Deque [ T ] = deque ( maxlen = len ( self . _receivers )) def __del__ ( self ) -> None : \"\"\"Cleanup any pending tasks.\"\"\" for task in self . _pending : if not task . done () and task . get_loop () . is_running (): task . cancel () async def stop ( self ) -> None : \"\"\"Stop the `Merge` instance and cleanup any pending tasks.\"\"\" for task in self . _pending : task . cancel () await asyncio . gather ( * self . _pending , return_exceptions = True ) self . _pending = set () async def ready ( self ) -> bool : \"\"\"Wait until the receiver is ready with a value or an error. Once a call to `ready()` has finished, the value should be read with a call to `consume()` (`receive()` or iterated over). The receiver will remain ready (this method will return immediately) until it is consumed. Returns: Whether the receiver is still active. \"\"\" # we use a while loop to continue to wait for new data, in case the # previous `wait` completed because a channel was closed. while True : # if there are messages waiting to be consumed, return immediately. if len ( self . _results ) > 0 : return True # if there are no more pending receivers, we return immediately. if len ( self . _pending ) == 0 : return False done , self . _pending = await asyncio . wait ( self . _pending , return_when = asyncio . FIRST_COMPLETED ) for item in done : name = item . get_name () # if channel is closed, don't add a task for it again. if isinstance ( item . exception (), StopAsyncIteration ): continue result = item . result () self . _results . append ( result ) self . _pending . add ( # pylint: disable=unnecessary-dunder-call asyncio . create_task ( self . _receivers [ name ] . __anext__ (), name = name ) ) def consume ( self ) -> T : \"\"\"Return the latest value once `ready` is complete. Returns: The next value that was received. Raises: ReceiverStoppedError: if the receiver stopped producing messages. ReceiverError: if there is some problem with the receiver. \"\"\" if not self . _results and not self . _pending : raise ReceiverStoppedError ( self ) assert self . _results , \"`consume()` must be preceeded by a call to `ready()`\" return self . _results . popleft () Functions \u00a4 __del__ () \u00a4 Cleanup any pending tasks. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_merge.py 46 47 48 49 50 def __del__ ( self ) -> None : \"\"\"Cleanup any pending tasks.\"\"\" for task in self . _pending : if not task . done () and task . get_loop () . is_running (): task . cancel () __init__ ( * args ) \u00a4 Create a Merge instance. PARAMETER DESCRIPTION *args sequence of channel receivers. TYPE: Receiver [ T ] DEFAULT: () Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_merge.py 33 34 35 36 37 38 39 40 41 42 43 44 def __init__ ( self , * args : Receiver [ T ]) -> None : \"\"\"Create a `Merge` instance. Args: *args: sequence of channel receivers. \"\"\" self . _receivers = { str ( id ): recv for id , recv in enumerate ( args )} self . _pending : Set [ asyncio . Task [ Any ]] = { asyncio . create_task ( recv . __anext__ (), name = name ) for name , recv in self . _receivers . items () } self . _results : Deque [ T ] = deque ( maxlen = len ( self . _receivers )) consume () \u00a4 Return the latest value once ready is complete. RETURNS DESCRIPTION T The next value that was received. RAISES DESCRIPTION ReceiverStoppedError if the receiver stopped producing messages. ReceiverError if there is some problem with the receiver. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_merge.py 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 def consume ( self ) -> T : \"\"\"Return the latest value once `ready` is complete. Returns: The next value that was received. Raises: ReceiverStoppedError: if the receiver stopped producing messages. ReceiverError: if there is some problem with the receiver. \"\"\" if not self . _results and not self . _pending : raise ReceiverStoppedError ( self ) assert self . _results , \"`consume()` must be preceeded by a call to `ready()`\" return self . _results . popleft () ready () async \u00a4 Wait until the receiver is ready with a value or an error. Once a call to ready() has finished, the value should be read with a call to consume() ( receive() or iterated over). The receiver will remain ready (this method will return immediately) until it is consumed. RETURNS DESCRIPTION bool Whether the receiver is still active. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_merge.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 async def ready ( self ) -> bool : \"\"\"Wait until the receiver is ready with a value or an error. Once a call to `ready()` has finished, the value should be read with a call to `consume()` (`receive()` or iterated over). The receiver will remain ready (this method will return immediately) until it is consumed. Returns: Whether the receiver is still active. \"\"\" # we use a while loop to continue to wait for new data, in case the # previous `wait` completed because a channel was closed. while True : # if there are messages waiting to be consumed, return immediately. if len ( self . _results ) > 0 : return True # if there are no more pending receivers, we return immediately. if len ( self . _pending ) == 0 : return False done , self . _pending = await asyncio . wait ( self . _pending , return_when = asyncio . FIRST_COMPLETED ) for item in done : name = item . get_name () # if channel is closed, don't add a task for it again. if isinstance ( item . exception (), StopAsyncIteration ): continue result = item . result () self . _results . append ( result ) self . _pending . add ( # pylint: disable=unnecessary-dunder-call asyncio . create_task ( self . _receivers [ name ] . __anext__ (), name = name ) ) stop () async \u00a4 Stop the Merge instance and cleanup any pending tasks. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_merge.py 52 53 54 55 56 57 async def stop ( self ) -> None : \"\"\"Stop the `Merge` instance and cleanup any pending tasks.\"\"\" for task in self . _pending : task . cancel () await asyncio . gather ( * self . _pending , return_exceptions = True ) self . _pending = set () frequenz.channels.util.MergeNamed \u00a4 Bases: Receiver [ Tuple [ str , T ]] Merge messages coming from multiple named channels into a single stream. When MergeNamed is no longer needed, then it should be stopped using self.stop() method. This will cleanup any internal pending async tasks. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_merge_named.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 class MergeNamed ( Receiver [ Tuple [ str , T ]]): \"\"\"Merge messages coming from multiple named channels into a single stream. When `MergeNamed` is no longer needed, then it should be stopped using `self.stop()` method. This will cleanup any internal pending async tasks. \"\"\" def __init__ ( self , ** kwargs : Receiver [ T ]) -> None : \"\"\"Create a `MergeNamed` instance. Args: **kwargs: sequence of channel receivers. \"\"\" self . _receivers = kwargs self . _pending : Set [ asyncio . Task [ Any ]] = { asyncio . create_task ( recv . __anext__ (), name = name ) for name , recv in self . _receivers . items () } self . _results : Deque [ Tuple [ str , T ]] = deque ( maxlen = len ( self . _receivers )) def __del__ ( self ) -> None : \"\"\"Cleanup any pending tasks.\"\"\" for task in self . _pending : if not task . done () and task . get_loop () . is_running (): task . cancel () async def stop ( self ) -> None : \"\"\"Stop the `MergeNamed` instance and cleanup any pending tasks.\"\"\" for task in self . _pending : task . cancel () await asyncio . gather ( * self . _pending , return_exceptions = True ) self . _pending = set () async def ready ( self ) -> bool : \"\"\"Wait until the receiver is ready with a value or an error. Once a call to `ready()` has finished, the value should be read with a call to `consume()` (`receive()` or iterated over). The receiver will remain ready (this method will return immediately) until it is consumed. Returns: Whether the receiver is still active. \"\"\" # we use a while loop to continue to wait for new data, in case the # previous `wait` completed because a channel was closed. while True : # if there are messages waiting to be consumed, return immediately. if len ( self . _results ) > 0 : return True # if there are no more pending receivers, we return immediately. if len ( self . _pending ) == 0 : return False done , self . _pending = await asyncio . wait ( self . _pending , return_when = asyncio . FIRST_COMPLETED ) for item in done : name = item . get_name () # if channel is closed, don't add a task for it again. if isinstance ( item . exception (), StopAsyncIteration ): continue result = item . result () self . _results . append (( name , result )) self . _pending . add ( # pylint: disable=unnecessary-dunder-call asyncio . create_task ( self . _receivers [ name ] . __anext__ (), name = name ) ) def consume ( self ) -> Tuple [ str , T ]: \"\"\"Return the latest value once `ready` is complete. Returns: The next key, value that was received. Raises: ReceiverStoppedError: if the receiver stopped producing messages. ReceiverError: if there is some problem with the receiver. \"\"\" if not self . _results and not self . _pending : raise ReceiverStoppedError ( self ) assert self . _results , \"`consume()` must be preceeded by a call to `ready()`\" return self . _results . popleft () Functions \u00a4 __del__ () \u00a4 Cleanup any pending tasks. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_merge_named.py 34 35 36 37 38 def __del__ ( self ) -> None : \"\"\"Cleanup any pending tasks.\"\"\" for task in self . _pending : if not task . done () and task . get_loop () . is_running (): task . cancel () __init__ ( ** kwargs ) \u00a4 Create a MergeNamed instance. PARAMETER DESCRIPTION **kwargs sequence of channel receivers. TYPE: Receiver [ T ] DEFAULT: {} Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_merge_named.py 21 22 23 24 25 26 27 28 29 30 31 32 def __init__ ( self , ** kwargs : Receiver [ T ]) -> None : \"\"\"Create a `MergeNamed` instance. Args: **kwargs: sequence of channel receivers. \"\"\" self . _receivers = kwargs self . _pending : Set [ asyncio . Task [ Any ]] = { asyncio . create_task ( recv . __anext__ (), name = name ) for name , recv in self . _receivers . items () } self . _results : Deque [ Tuple [ str , T ]] = deque ( maxlen = len ( self . _receivers )) consume () \u00a4 Return the latest value once ready is complete. RETURNS DESCRIPTION Tuple [ str , T ] The next key, value that was received. RAISES DESCRIPTION ReceiverStoppedError if the receiver stopped producing messages. ReceiverError if there is some problem with the receiver. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_merge_named.py 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 def consume ( self ) -> Tuple [ str , T ]: \"\"\"Return the latest value once `ready` is complete. Returns: The next key, value that was received. Raises: ReceiverStoppedError: if the receiver stopped producing messages. ReceiverError: if there is some problem with the receiver. \"\"\" if not self . _results and not self . _pending : raise ReceiverStoppedError ( self ) assert self . _results , \"`consume()` must be preceeded by a call to `ready()`\" return self . _results . popleft () ready () async \u00a4 Wait until the receiver is ready with a value or an error. Once a call to ready() has finished, the value should be read with a call to consume() ( receive() or iterated over). The receiver will remain ready (this method will return immediately) until it is consumed. RETURNS DESCRIPTION bool Whether the receiver is still active. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_merge_named.py 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 async def ready ( self ) -> bool : \"\"\"Wait until the receiver is ready with a value or an error. Once a call to `ready()` has finished, the value should be read with a call to `consume()` (`receive()` or iterated over). The receiver will remain ready (this method will return immediately) until it is consumed. Returns: Whether the receiver is still active. \"\"\" # we use a while loop to continue to wait for new data, in case the # previous `wait` completed because a channel was closed. while True : # if there are messages waiting to be consumed, return immediately. if len ( self . _results ) > 0 : return True # if there are no more pending receivers, we return immediately. if len ( self . _pending ) == 0 : return False done , self . _pending = await asyncio . wait ( self . _pending , return_when = asyncio . FIRST_COMPLETED ) for item in done : name = item . get_name () # if channel is closed, don't add a task for it again. if isinstance ( item . exception (), StopAsyncIteration ): continue result = item . result () self . _results . append (( name , result )) self . _pending . add ( # pylint: disable=unnecessary-dunder-call asyncio . create_task ( self . _receivers [ name ] . __anext__ (), name = name ) ) stop () async \u00a4 Stop the MergeNamed instance and cleanup any pending tasks. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_merge_named.py 40 41 42 43 44 45 async def stop ( self ) -> None : \"\"\"Stop the `MergeNamed` instance and cleanup any pending tasks.\"\"\" for task in self . _pending : task . cancel () await asyncio . gather ( * self . _pending , return_exceptions = True ) self . _pending = set () frequenz.channels.util.MissedTickPolicy \u00a4 Bases: abc . ABC A policy to handle timer missed ticks. This is only relevant if the timer is not ready to trigger when it should (an interval passed) which can happen if the event loop is busy processing other tasks. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_timer.py 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 class MissedTickPolicy ( abc . ABC ): \"\"\"A policy to handle timer missed ticks. This is only relevant if the timer is not ready to trigger when it should (an interval passed) which can happen if the event loop is busy processing other tasks. \"\"\" @abc . abstractmethod def calculate_next_tick_time ( self , * , interval : int , scheduled_tick_time : int , now : int ) -> int : \"\"\"Calculate the next tick time according to `missed_tick_policy`. This method is called by `ready()` after it has determined that the timer has triggered. It will check if the timer has missed any ticks and handle them according to `missed_tick_policy`. Args: interval: The interval between ticks (in microseconds). scheduled_tick_time: The time the current tick was scheduled to trigger (in microseconds). now: The current loop time (in microseconds). Returns: The next tick time (in microseconds) according to `missed_tick_policy`. \"\"\" return 0 # dummy value to avoid darglint warnings Functions \u00a4 calculate_next_tick_time ( * , interval , scheduled_tick_time , now ) abstractmethod \u00a4 Calculate the next tick time according to missed_tick_policy . This method is called by ready() after it has determined that the timer has triggered. It will check if the timer has missed any ticks and handle them according to missed_tick_policy . PARAMETER DESCRIPTION interval The interval between ticks (in microseconds). TYPE: int scheduled_tick_time The time the current tick was scheduled to trigger (in microseconds). TYPE: int now The current loop time (in microseconds). TYPE: int RETURNS DESCRIPTION int The next tick time (in microseconds) according to missed_tick_policy . Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_timer.py 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 @abc . abstractmethod def calculate_next_tick_time ( self , * , interval : int , scheduled_tick_time : int , now : int ) -> int : \"\"\"Calculate the next tick time according to `missed_tick_policy`. This method is called by `ready()` after it has determined that the timer has triggered. It will check if the timer has missed any ticks and handle them according to `missed_tick_policy`. Args: interval: The interval between ticks (in microseconds). scheduled_tick_time: The time the current tick was scheduled to trigger (in microseconds). now: The current loop time (in microseconds). Returns: The next tick time (in microseconds) according to `missed_tick_policy`. \"\"\" return 0 # dummy value to avoid darglint warnings frequenz.channels.util.Select \u00a4 Select the next available message from a group of Receivers. If Select was created with more Receiver than what are read in the if-chain after each call to ready() , messages coming in the additional receivers are dropped, and a warning message is logged. Receiver s also function as Receiver . When Select is no longer needed, then it should be stopped using self.stop() method. This would cleanup any internal pending async tasks. Example For example, if there are two receivers that you want to simultaneously wait on, this can be done with: select = Select ( name1 = receiver1 , name2 = receiver2 ) while await select . ready (): if msg := select . name1 : if val := msg . inner : # do something with `val` pass else : # handle closure of receiver. pass elif msg := select . name2 : # do something with `msg.inner` pass Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_select.py 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 class Select : \"\"\"Select the next available message from a group of Receivers. If `Select` was created with more `Receiver` than what are read in the if-chain after each call to [ready()][frequenz.channels.util.Select.ready], messages coming in the additional receivers are dropped, and a warning message is logged. [Receiver][frequenz.channels.Receiver]s also function as `Receiver`. When Select is no longer needed, then it should be stopped using `self.stop()` method. This would cleanup any internal pending async tasks. Example: For example, if there are two receivers that you want to simultaneously wait on, this can be done with: ```python select = Select(name1 = receiver1, name2 = receiver2) while await select.ready(): if msg := select.name1: if val := msg.inner: # do something with `val` pass else: # handle closure of receiver. pass elif msg := select.name2: # do something with `msg.inner` pass ``` \"\"\" def __init__ ( self , ** kwargs : Receiver [ Any ]) -> None : \"\"\"Create a `Select` instance. Args: **kwargs: sequence of receivers \"\"\" self . _receivers = kwargs self . _pending : Set [ asyncio . Task [ bool ]] = set () for name , recv in self . _receivers . items (): self . _pending . add ( asyncio . create_task ( recv . ready (), name = name )) self . _ready_count = 0 self . _prev_ready_count = 0 self . _result : Dict [ str , Optional [ _ReadyReceiver ]] = { name : None for name in self . _receivers } def __del__ ( self ) -> None : \"\"\"Cleanup any pending tasks.\"\"\" for task in self . _pending : if not task . done () and task . get_loop () . is_running (): task . cancel () async def stop ( self ) -> None : \"\"\"Stop the `Select` instance and cleanup any pending tasks.\"\"\" for task in self . _pending : task . cancel () await asyncio . gather ( * self . _pending , return_exceptions = True ) self . _pending = set () async def ready ( self ) -> bool : \"\"\"Wait until there is a message in any of the receivers. Returns `True` if there is a message available, and `False` if all receivers have closed. Returns: Whether there are further messages or not. \"\"\" # This function will change radically soon # pylint: disable=too-many-nested-blocks if self . _ready_count > 0 : if self . _ready_count == self . _prev_ready_count : dropped_names : List [ str ] = [] for name , value in self . _result . items (): if value is not None : dropped_names . append ( name ) if value . recv is not None : try : value . recv . consume () except ReceiverStoppedError : pass self . _result [ name ] = None self . _ready_count = 0 self . _prev_ready_count = 0 logger . warning ( \"Select.ready() dropped data from receiver(s): %s , \" \"because no messages have been fetched since the last call to ready().\" , dropped_names , ) else : self . _prev_ready_count = self . _ready_count return True if len ( self . _pending ) == 0 : return False # once all the pending messages have been consumed, reset the # `_prev_ready_count` as well, and wait for new messages. self . _prev_ready_count = 0 done , self . _pending = await asyncio . wait ( self . _pending , return_when = asyncio . FIRST_COMPLETED ) for task in done : name = task . get_name () recv = self . _receivers [ name ] receiver_active = task . result () if receiver_active : ready_recv = recv else : ready_recv = None self . _ready_count += 1 self . _result [ name ] = _ReadyReceiver ( ready_recv ) # if channel or Receiver is closed # don't add a task for it again. if not receiver_active : continue self . _pending . add ( asyncio . create_task ( recv . ready (), name = name )) return True def __getattr__ ( self , name : str ) -> Optional [ Any ]: \"\"\"Return the latest unread message from a `Receiver`, if available. Args: name: Name of the channel. Returns: Latest unread message for the specified `Receiver`, or `None`. Raises: KeyError: when the name was not specified when creating the `Select` instance. \"\"\" result = self . _result [ name ] if result is None : return result self . _result [ name ] = None self . _ready_count -= 1 return result . get () Functions \u00a4 __del__ () \u00a4 Cleanup any pending tasks. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_select.py 108 109 110 111 112 def __del__ ( self ) -> None : \"\"\"Cleanup any pending tasks.\"\"\" for task in self . _pending : if not task . done () and task . get_loop () . is_running (): task . cancel () __getattr__ ( name ) \u00a4 Return the latest unread message from a Receiver , if available. PARAMETER DESCRIPTION name Name of the channel. TYPE: str RETURNS DESCRIPTION Optional [ Any ] Latest unread message for the specified Receiver , or None . RAISES DESCRIPTION KeyError when the name was not specified when creating the Select instance. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_select.py 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 def __getattr__ ( self , name : str ) -> Optional [ Any ]: \"\"\"Return the latest unread message from a `Receiver`, if available. Args: name: Name of the channel. Returns: Latest unread message for the specified `Receiver`, or `None`. Raises: KeyError: when the name was not specified when creating the `Select` instance. \"\"\" result = self . _result [ name ] if result is None : return result self . _result [ name ] = None self . _ready_count -= 1 return result . get () __init__ ( ** kwargs ) \u00a4 Create a Select instance. PARAMETER DESCRIPTION **kwargs sequence of receivers TYPE: Receiver [ Any ] DEFAULT: {} Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_select.py 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 def __init__ ( self , ** kwargs : Receiver [ Any ]) -> None : \"\"\"Create a `Select` instance. Args: **kwargs: sequence of receivers \"\"\" self . _receivers = kwargs self . _pending : Set [ asyncio . Task [ bool ]] = set () for name , recv in self . _receivers . items (): self . _pending . add ( asyncio . create_task ( recv . ready (), name = name )) self . _ready_count = 0 self . _prev_ready_count = 0 self . _result : Dict [ str , Optional [ _ReadyReceiver ]] = { name : None for name in self . _receivers } ready () async \u00a4 Wait until there is a message in any of the receivers. Returns True if there is a message available, and False if all receivers have closed. RETURNS DESCRIPTION bool Whether there are further messages or not. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_select.py 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 async def ready ( self ) -> bool : \"\"\"Wait until there is a message in any of the receivers. Returns `True` if there is a message available, and `False` if all receivers have closed. Returns: Whether there are further messages or not. \"\"\" # This function will change radically soon # pylint: disable=too-many-nested-blocks if self . _ready_count > 0 : if self . _ready_count == self . _prev_ready_count : dropped_names : List [ str ] = [] for name , value in self . _result . items (): if value is not None : dropped_names . append ( name ) if value . recv is not None : try : value . recv . consume () except ReceiverStoppedError : pass self . _result [ name ] = None self . _ready_count = 0 self . _prev_ready_count = 0 logger . warning ( \"Select.ready() dropped data from receiver(s): %s , \" \"because no messages have been fetched since the last call to ready().\" , dropped_names , ) else : self . _prev_ready_count = self . _ready_count return True if len ( self . _pending ) == 0 : return False # once all the pending messages have been consumed, reset the # `_prev_ready_count` as well, and wait for new messages. self . _prev_ready_count = 0 done , self . _pending = await asyncio . wait ( self . _pending , return_when = asyncio . FIRST_COMPLETED ) for task in done : name = task . get_name () recv = self . _receivers [ name ] receiver_active = task . result () if receiver_active : ready_recv = recv else : ready_recv = None self . _ready_count += 1 self . _result [ name ] = _ReadyReceiver ( ready_recv ) # if channel or Receiver is closed # don't add a task for it again. if not receiver_active : continue self . _pending . add ( asyncio . create_task ( recv . ready (), name = name )) return True stop () async \u00a4 Stop the Select instance and cleanup any pending tasks. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_select.py 114 115 116 117 118 119 async def stop ( self ) -> None : \"\"\"Stop the `Select` instance and cleanup any pending tasks.\"\"\" for task in self . _pending : task . cancel () await asyncio . gather ( * self . _pending , return_exceptions = True ) self . _pending = set () frequenz.channels.util.SkipMissedAndDrift \u00a4 Bases: MissedTickPolicy A policy that drops all the missed ticks, triggers immediately and resets. This will behave effectively as if the timer was reset() at the time it had triggered last, so the start time will change (and the drift will be accumulated each time a tick is delayed, but only the relative drift will be returned on each tick). The reset happens only if the delay is larger than delay_tolerance , so it is possible to ignore small delays and not drift in those cases. Example Assume a timer with interval 1 second and delay_tolerance=0.1 , the first tick, T0 , happens exactly at time 0, the second tick, T1 , happens at time 1.2 (0.2 seconds late), so the timer triggers immmediately but drifts a bit. The next tick, T2.2 , happens at 2.3 seconds (0.1 seconds late), so it also triggers immediately but it doesn't drift because the delay is under the delay_tolerance . The next tick, T3.2 , triggers at 4.3 seconds (1.1 seconds late), so it also triggers immediately but the timer drifts by 1.1 seconds and the tick T4.2 is skipped (not triggered). The next tick, T5.3 , triggers at 5.3 seconds so is right on time (no drift) and the same happens for tick T6.3 , which triggers at 6.3 seconds. 0 1 2 3 4 5 6 o---------|-o-------|--o------|---------|--o------|--o------|--o--> time T0 T1 T2.2 T3.2 T5.3 T6.3 Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_timer.py 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 class SkipMissedAndDrift ( MissedTickPolicy ): \"\"\"A policy that drops all the missed ticks, triggers immediately and resets. This will behave effectively as if the timer was `reset()` at the time it had triggered last, so the start time will change (and the drift will be accumulated each time a tick is delayed, but only the relative drift will be returned on each tick). The reset happens only if the delay is larger than `delay_tolerance`, so it is possible to ignore small delays and not drift in those cases. Example: Assume a timer with interval 1 second and `delay_tolerance=0.1`, the first tick, `T0`, happens exactly at time 0, the second tick, `T1`, happens at time 1.2 (0.2 seconds late), so the timer triggers immmediately but drifts a bit. The next tick, `T2.2`, happens at 2.3 seconds (0.1 seconds late), so it also triggers immediately but it doesn't drift because the delay is under the `delay_tolerance`. The next tick, `T3.2`, triggers at 4.3 seconds (1.1 seconds late), so it also triggers immediately but the timer drifts by 1.1 seconds and the tick `T4.2` is skipped (not triggered). The next tick, `T5.3`, triggers at 5.3 seconds so is right on time (no drift) and the same happens for tick `T6.3`, which triggers at 6.3 seconds. ``` 0 1 2 3 4 5 6 o---------|-o-------|--o------|---------|--o------|--o------|--o--> time T0 T1 T2.2 T3.2 T5.3 T6.3 ``` \"\"\" def __init__ ( self , * , delay_tolerance : timedelta = timedelta ( 0 )): \"\"\" Create an instance. See the class documenation for more details. Args: delay_tolerance: The maximum delay that is tolerated before starting to drift. If a tick is delayed less than this, then it is not considered a missed tick and the timer doesn't accumulate this drift. Raises: ValueError: If `delay_tolerance` is negative. \"\"\" self . _tolerance : int = _to_microseconds ( delay_tolerance ) \"\"\"The maximum allowed delay before starting to drift.\"\"\" if self . _tolerance < 0 : raise ValueError ( \"delay_tolerance must be positive\" ) @property def delay_tolerance ( self ) -> timedelta : \"\"\"Return the maximum delay that is tolerated before starting to drift. Returns: The maximum delay that is tolerated before starting to drift. \"\"\" return timedelta ( microseconds = self . _tolerance ) def calculate_next_tick_time ( self , * , now : int , scheduled_tick_time : int , interval : int ) -> int : \"\"\"Calculate the next tick time. If the drift is larger than `delay_tolerance`, then it returns `now + interval` (so the timer drifts), otherwise it returns `scheduled_tick_time + interval` (we consider the delay too small and avoid small drifts). Args: now: The current loop time (in microseconds). scheduled_tick_time: The time the current tick was scheduled to trigger (in microseconds). interval: The interval between ticks (in microseconds). Returns: The next tick time (in microseconds). \"\"\" drift = now - scheduled_tick_time if drift > self . _tolerance : return now + interval return scheduled_tick_time + interval Attributes \u00a4 delay_tolerance : timedelta property \u00a4 Return the maximum delay that is tolerated before starting to drift. RETURNS DESCRIPTION timedelta The maximum delay that is tolerated before starting to drift. Functions \u00a4 __init__ ( * , delay_tolerance = timedelta ( 0 )) \u00a4 Create an instance. See the class documenation for more details. PARAMETER DESCRIPTION delay_tolerance The maximum delay that is tolerated before starting to drift. If a tick is delayed less than this, then it is not considered a missed tick and the timer doesn't accumulate this drift. TYPE: timedelta DEFAULT: timedelta(0) RAISES DESCRIPTION ValueError If delay_tolerance is negative. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_timer.py 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 def __init__ ( self , * , delay_tolerance : timedelta = timedelta ( 0 )): \"\"\" Create an instance. See the class documenation for more details. Args: delay_tolerance: The maximum delay that is tolerated before starting to drift. If a tick is delayed less than this, then it is not considered a missed tick and the timer doesn't accumulate this drift. Raises: ValueError: If `delay_tolerance` is negative. \"\"\" self . _tolerance : int = _to_microseconds ( delay_tolerance ) \"\"\"The maximum allowed delay before starting to drift.\"\"\" if self . _tolerance < 0 : raise ValueError ( \"delay_tolerance must be positive\" ) calculate_next_tick_time ( * , now , scheduled_tick_time , interval ) \u00a4 Calculate the next tick time. If the drift is larger than delay_tolerance , then it returns now + interval (so the timer drifts), otherwise it returns scheduled_tick_time + interval (we consider the delay too small and avoid small drifts). PARAMETER DESCRIPTION now The current loop time (in microseconds). TYPE: int scheduled_tick_time The time the current tick was scheduled to trigger (in microseconds). TYPE: int interval The interval between ticks (in microseconds). TYPE: int RETURNS DESCRIPTION int The next tick time (in microseconds). Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_timer.py 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 def calculate_next_tick_time ( self , * , now : int , scheduled_tick_time : int , interval : int ) -> int : \"\"\"Calculate the next tick time. If the drift is larger than `delay_tolerance`, then it returns `now + interval` (so the timer drifts), otherwise it returns `scheduled_tick_time + interval` (we consider the delay too small and avoid small drifts). Args: now: The current loop time (in microseconds). scheduled_tick_time: The time the current tick was scheduled to trigger (in microseconds). interval: The interval between ticks (in microseconds). Returns: The next tick time (in microseconds). \"\"\" drift = now - scheduled_tick_time if drift > self . _tolerance : return now + interval return scheduled_tick_time + interval frequenz.channels.util.SkipMissedAndResync \u00a4 Bases: MissedTickPolicy A policy that drops all the missed ticks, triggers immediately and resyncs. If ticks are missed, the timer will trigger immediately returing the drift and it will schedule to trigger again on the next multiple of interval , effectively skipping any missed ticks, but resyncing with the original start time. Example Assume a timer with interval 1 second, the tick T0 happens exactly at time 0, the second tick, T1 , happens at time 1.2 (0.2 seconds late), so it trigges immediately. The third tick, T2 , happens at time 2.3 (0.3 seconds late), so it also triggers immediately. The fourth tick, T3 , happens at time 4.3 (1.3 seconds late), so it also triggers immediately but the fifth tick, T4 , which was also already delayed (by 0.3 seconds) is skipped. The sixth tick, T5 , happens at 5.1 (0.1 seconds late), so it triggers immediately again. The seventh tick, T6 , happens at 6.0, right on time. 0 1 2 3 4 o 5 6 o---------|-o-------|--o------|---------|--o------|o--------o-----> time T0 T1 T2 T3 T5 T6 Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_timer.py 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 class SkipMissedAndResync ( MissedTickPolicy ): \"\"\"A policy that drops all the missed ticks, triggers immediately and resyncs. If ticks are missed, the timer will trigger immediately returing the drift and it will schedule to trigger again on the next multiple of `interval`, effectively skipping any missed ticks, but resyncing with the original start time. Example: Assume a timer with interval 1 second, the tick `T0` happens exactly at time 0, the second tick, `T1`, happens at time 1.2 (0.2 seconds late), so it trigges immediately. The third tick, `T2`, happens at time 2.3 (0.3 seconds late), so it also triggers immediately. The fourth tick, `T3`, happens at time 4.3 (1.3 seconds late), so it also triggers immediately but the fifth tick, `T4`, which was also already delayed (by 0.3 seconds) is skipped. The sixth tick, `T5`, happens at 5.1 (0.1 seconds late), so it triggers immediately again. The seventh tick, `T6`, happens at 6.0, right on time. ``` 0 1 2 3 4 o 5 6 o---------|-o-------|--o------|---------|--o------|o--------o-----> time T0 T1 T2 T3 T5 T6 ``` \"\"\" def calculate_next_tick_time ( self , * , now : int , scheduled_tick_time : int , interval : int ) -> int : \"\"\"Calculate the next tick time. Calculate the next multiple of `interval` after `scheduled_tick_time`. Args: now: The current loop time (in microseconds). scheduled_tick_time: The time the current tick was scheduled to trigger (in microseconds). interval: The interval between ticks (in microseconds). Returns: The next tick time (in microseconds). \"\"\" # We need to resync (align) the next tick time to the current time drift = now - scheduled_tick_time delta_to_next_tick = interval - ( drift % interval ) return now + delta_to_next_tick Functions \u00a4 calculate_next_tick_time ( * , now , scheduled_tick_time , interval ) \u00a4 Calculate the next tick time. Calculate the next multiple of interval after scheduled_tick_time . PARAMETER DESCRIPTION now The current loop time (in microseconds). TYPE: int scheduled_tick_time The time the current tick was scheduled to trigger (in microseconds). TYPE: int interval The interval between ticks (in microseconds). TYPE: int RETURNS DESCRIPTION int The next tick time (in microseconds). Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_timer.py 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 def calculate_next_tick_time ( self , * , now : int , scheduled_tick_time : int , interval : int ) -> int : \"\"\"Calculate the next tick time. Calculate the next multiple of `interval` after `scheduled_tick_time`. Args: now: The current loop time (in microseconds). scheduled_tick_time: The time the current tick was scheduled to trigger (in microseconds). interval: The interval between ticks (in microseconds). Returns: The next tick time (in microseconds). \"\"\" # We need to resync (align) the next tick time to the current time drift = now - scheduled_tick_time delta_to_next_tick = interval - ( drift % interval ) return now + delta_to_next_tick frequenz.channels.util.Timer \u00a4 Bases: Receiver [ timedelta ] A timer receiver that triggers every interval time. The timer as microseconds resolution, so the interval must be at least 1 microsecond. The message it produces is a timedelta containing the drift of the timer, i.e. the difference between when the timer should have triggered and the time when it actually triggered. This drift will likely never be 0 , because if there is a task that is running when it should trigger, the timer will be delayed. In this case the drift will be positive. A negative drift should be technically impossible, as the timer uses asyncio s loop monotonic clock. If the timer is delayed too much, then the timer will behave according to the missed_tick_policy . Missing ticks might or might not trigger a message and the drift could be accumulated or not depending on the chosen policy. The timer accepts an optional loop , which will be used to track the time. If loop is None , then the running loop will be used (if there is no running loop most calls will raise a RuntimeError ). Starting the timer can be delayed if necessary by using auto_start=False (for example until we have a running loop). A call to reset() , ready() , receive() or the async iterator interface to await for a new message will start the timer. For the most common cases, a specialized constructor is provided: periodic() timeout() Periodic timer example async for drift in Timer . periodic ( timedelta ( seconds = 1.0 )): print ( f \"The timer has triggered { drift =} \" ) But you can also use Select to combine it with other receivers, and even start it (semi) manually: timer = Timer . timeout ( timedelta ( seconds = 1.0 ), auto_start = False ) # Do some other initialization, the timer will start automatically if # a message is awaited (or manually via `reset()`). select = Select ( bat_1 = receiver1 , timer = timer ) while await select . ready (): if msg := select . bat_1 : if val := msg . inner : process_data ( val ) else : logging . warn ( \"battery channel closed\" ) elif drift := select . timer : # Print some regular battery data print ( f \"Battery is charged at { battery . soc } %\" ) if stop_logging : timer . stop () elif start_logging : timer . reset () Timeout example timer = Timer . timeout ( timedelta ( seconds = 1.0 ), auto_start = False ) select = Select ( bat_1 = receiver1 , heavy_process = receiver2 , timeout = timer ) while await select . ready (): if msg := select . bat_1 : if val := msg . inner : process_data ( val ) timer . reset () else : logging . warn ( \"battery channel closed\" ) if msg := select . heavy_process : if val := msg . inner : do_heavy_processing ( val ) else : logging . warn ( \"processing channel closed\" ) elif drift := select . timeout : logging . warn ( \"No data received in time\" ) In this case do_heavy_processing might take 2 seconds, and we don't want our timeout timer to trigger for the missed ticks, and want the next tick to be relative to the time timer was last triggered. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_timer.py 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 class Timer ( Receiver [ timedelta ]): \"\"\"A timer receiver that triggers every `interval` time. The timer as microseconds resolution, so the `interval` must be at least 1 microsecond. The message it produces is a `timedelta` containing the drift of the timer, i.e. the difference between when the timer should have triggered and the time when it actually triggered. This drift will likely never be `0`, because if there is a task that is running when it should trigger, the timer will be delayed. In this case the drift will be positive. A negative drift should be technically impossible, as the timer uses `asyncio`s loop monotonic clock. If the timer is delayed too much, then the timer will behave according to the `missed_tick_policy`. Missing ticks might or might not trigger a message and the drift could be accumulated or not depending on the chosen policy. The timer accepts an optional `loop`, which will be used to track the time. If `loop` is `None`, then the running loop will be used (if there is no running loop most calls will raise a `RuntimeError`). Starting the timer can be delayed if necessary by using `auto_start=False` (for example until we have a running loop). A call to `reset()`, `ready()`, `receive()` or the async iterator interface to await for a new message will start the timer. For the most common cases, a specialized constructor is provided: * [`periodic()`][frequenz.channels.util.Timer.periodic] * [`timeout()`][frequenz.channels.util.Timer.timeout] Example: Periodic timer example ```python async for drift in Timer.periodic(timedelta(seconds=1.0)): print(f\"The timer has triggered {drift=}\") ``` But you can also use [`Select`][frequenz.channels.util.Select] to combine it with other receivers, and even start it (semi) manually: ```python timer = Timer.timeout(timedelta(seconds=1.0), auto_start=False) # Do some other initialization, the timer will start automatically if # a message is awaited (or manually via `reset()`). select = Select(bat_1=receiver1, timer=timer) while await select.ready(): if msg := select.bat_1: if val := msg.inner: process_data(val) else: logging.warn(\"battery channel closed\") elif drift := select.timer: # Print some regular battery data print(f\"Battery is charged at {battery.soc}%\") if stop_logging: timer.stop() elif start_logging: timer.reset() ``` Example: Timeout example ```python timer = Timer.timeout(timedelta(seconds=1.0), auto_start=False) select = Select(bat_1=receiver1, heavy_process=receiver2, timeout=timer) while await select.ready(): if msg := select.bat_1: if val := msg.inner: process_data(val) timer.reset() else: logging.warn(\"battery channel closed\") if msg := select.heavy_process: if val := msg.inner: do_heavy_processing(val) else: logging.warn(\"processing channel closed\") elif drift := select.timeout: logging.warn(\"No data received in time\") ``` In this case `do_heavy_processing` might take 2 seconds, and we don't want our timeout timer to trigger for the missed ticks, and want the next tick to be relative to the time timer was last triggered. \"\"\" def __init__ ( self , interval : timedelta , missed_tick_policy : MissedTickPolicy , / , * , auto_start : bool = True , loop : asyncio . AbstractEventLoop | None = None , ) -> None : \"\"\"Create an instance. See the class documentation for details. Args: interval: The time between timer ticks. Must be at least 1 microsecond. missed_tick_policy: The policy of the timer when it misses a tick. See the documentation of `MissedTickPolicy` for details. auto_start: Whether the timer should be started when the instance is created. This can only be `True` if there is already a running loop or an explicit `loop` that is running was passed. loop: The event loop to use to track time. If `None`, `asyncio.get_running_loop()` will be used. Raises: RuntimeError: if it was called without a loop and there is no running loop. ValueError: if `interval` is not positive or is smaller than 1 microsecond. \"\"\" self . _interval : int = _to_microseconds ( interval ) \"\"\"The time to between timer ticks.\"\"\" self . _missed_tick_policy : MissedTickPolicy = missed_tick_policy \"\"\"The policy of the timer when it misses a tick. See the documentation of `MissedTickPolicy` for details. \"\"\" self . _loop : asyncio . AbstractEventLoop = ( loop if loop is not None else asyncio . get_running_loop () ) \"\"\"The event loop to use to track time.\"\"\" self . _stopped : bool = True \"\"\"Whether the timer was requested to stop. If this is `False`, then the timer is running. If this is `True`, then it is stopped or there is a request to stop it or it was not started yet: * If `_next_msg_time` is `None`, it means it wasn't started yet (it was created with `auto_start=False`). Any receiving method will start it by calling `reset()` in this case. * If `_next_msg_time` is not `None`, it means there was a request to stop it. In this case receiving methods will raise a `ReceiverClosedError`. \"\"\" self . _next_tick_time : int | None = None \"\"\"The absolute (monotonic) time when the timer should trigger. If this is `None`, it means the timer didn't start yet, but it should be started as soon as it is used. \"\"\" self . _current_drift : timedelta | None = None \"\"\"The difference between `_next_msg_time` and the triggered time. This is calculated by `ready()` but is returned by `consume()`. If `None` it means `ready()` wasn't called and `consume()` will assert. `consume()` will set it back to `None` to tell `ready()` that it needs to wait again. \"\"\" if self . _interval <= 0 : raise ValueError ( \"The `interval` must be positive and at least 1 microsecond, \" f \"not { interval } ( { self . _interval } microseconds)\" ) if auto_start : self . reset () @classmethod def timeout ( cls , delay : timedelta , / , * , auto_start : bool = True , loop : asyncio . AbstractEventLoop | None = None , ) -> Timer : \"\"\"Create a timer useful for tracking timeouts. This is basically a shortcut to create a timer with `SkipMissedAndDrift(delay_tolerance=timedelta(0))` as the missed tick policy. See the class documentation for details. Args: delay: The time until the timer ticks. Must be at least 1 microsecond. auto_start: Whether the timer should be started when the instance is created. This can only be `True` if there is already a running loop or an explicit `loop` that is running was passed. loop: The event loop to use to track time. If `None`, `asyncio.get_running_loop()` will be used. Returns: The timer instance. Raises: RuntimeError: if it was called without a loop and there is no running loop. ValueError: if `interval` is not positive or is smaller than 1 microsecond. \"\"\" return Timer ( delay , SkipMissedAndDrift ( delay_tolerance = timedelta ( 0 )), auto_start = auto_start , loop = loop , ) @classmethod def periodic ( cls , period : timedelta , / , * , skip_missed_ticks : bool = False , auto_start : bool = True , loop : asyncio . AbstractEventLoop | None = None , ) -> Timer : \"\"\"Create a periodic timer. This is basically a shortcut to create a timer with either `TriggerAllMissed()` or `SkipMissedAndResync()` as the missed tick policy (depending on `skip_missed_ticks`). See the class documentation for details. Args: period: The time between timer ticks. Must be at least 1 microsecond. skip_missed_ticks: Whether to skip missed ticks or trigger them all until it catches up. auto_start: Whether the timer should be started when the instance is created. This can only be `True` if there is already a running loop or an explicit `loop` that is running was passed. loop: The event loop to use to track time. If `None`, `asyncio.get_running_loop()` will be used. Returns: The timer instance. Raises: RuntimeError: if it was called without a loop and there is no running loop. ValueError: if `interval` is not positive or is smaller than 1 microsecond. \"\"\" missed_tick_policy = ( SkipMissedAndResync () if skip_missed_ticks else TriggerAllMissed () ) return Timer ( period , missed_tick_policy , auto_start = auto_start , loop = loop , ) @property def interval ( self ) -> timedelta : \"\"\"The interval between timer ticks. Returns: The interval between timer ticks. \"\"\" return timedelta ( microseconds = self . _interval ) @property def missed_tick_policy ( self ) -> MissedTickPolicy : \"\"\"The policy of the timer when it misses a tick. Returns: The policy of the timer when it misses a tick. \"\"\" return self . _missed_tick_policy @property def loop ( self ) -> asyncio . AbstractEventLoop : \"\"\"The event loop used by the timer to track time. Returns: The event loop used by the timer to track time. \"\"\" return self . _loop @property def is_running ( self ) -> bool : \"\"\"Whether the timer is running. This will be `False` if the timer was stopped, or not started yet. Returns: Whether the timer is running. \"\"\" return not self . _stopped def reset ( self ) -> None : \"\"\"Reset the timer to start timing from now. If the timer was stopped, or not started yet, it will be started. This can only be called with a running loop, see the class documentation for more details. Raises: RuntimeError: if it was called without a running loop. \"\"\" self . _stopped = False self . _next_tick_time = self . _now () + self . _interval self . _current_drift = None def stop ( self ) -> None : \"\"\"Stop the timer. Once `stop` has been called, all subsequent calls to `ready()` will immediately return False and calls to `consume()` / `receive()` or any use of the async iterator interface will raise a `ReceiverStoppedError`. You can restart the timer with `reset()`. \"\"\" self . _stopped = True # We need to make sure it's not None, otherwise `ready()` will start it self . _next_tick_time = self . _now () async def ready ( self ) -> bool : \"\"\"Wait until the timer `interval` passed. Once a call to `ready()` has finished, the resulting tick information must be read with a call to `consume()` (`receive()` or iterated over) to tell the timer it should wait for the next interval. The timer will remain ready (this method will return immediately) until it is consumed. Returns: Whether the timer was started and it is still running. Raises: RuntimeError: if it was called without a running loop. \"\"\" # If there are messages waiting to be consumed, return immediately. if self . _current_drift is not None : return True # If `_next_tick_time` is `None`, it means it was created with # `auto_start=False` and should be started. if self . _next_tick_time is None : self . reset () assert ( self . _next_tick_time is not None ), \"This should be assigned by reset()\" # If a stop was explicitly requested, we bail out. if self . _stopped : return False now = self . _now () time_to_next_tick = self . _next_tick_time - now # If we didn't reach the tick yet, sleep until we do. if time_to_next_tick > 0 : await asyncio . sleep ( time_to_next_tick / 1_000_000 ) now = self . _now () # If a stop was explicitly requested during the sleep, we bail out. if self . _stopped : return False self . _current_drift = timedelta ( microseconds = now - self . _next_tick_time ) self . _next_tick_time = self . _missed_tick_policy . calculate_next_tick_time ( now = now , scheduled_tick_time = self . _next_tick_time , interval = self . _interval , ) return True def consume ( self ) -> timedelta : \"\"\"Return the latest drift once `ready()` is complete. Once the timer has triggered (`ready()` is done), this method returns the difference between when the timer should have triggered and the time when it actually triggered. See the class documentation for more details. Returns: The difference between when the timer should have triggered and the time when it actually did. Raises: ReceiverStoppedError: if the timer was stopped via `stop()`. \"\"\" # If it was stopped and there it no pending result, we raise # (if there is a pending result, then we still want to return it first) if self . _stopped and self . _current_drift is None : raise ReceiverStoppedError ( self ) assert ( self . _current_drift is not None ), \"calls to `consume()` must be follow a call to `ready()`\" drift = self . _current_drift self . _current_drift = None return drift def _now ( self ) -> int : \"\"\"Return the current monotonic clock time in microseconds. Returns: The current monotonic clock time in microseconds. \"\"\" return _to_microseconds ( self . _loop . time ()) Attributes \u00a4 interval : timedelta property \u00a4 The interval between timer ticks. RETURNS DESCRIPTION timedelta The interval between timer ticks. is_running : bool property \u00a4 Whether the timer is running. This will be False if the timer was stopped, or not started yet. RETURNS DESCRIPTION bool Whether the timer is running. loop : asyncio . AbstractEventLoop property \u00a4 The event loop used by the timer to track time. RETURNS DESCRIPTION asyncio . AbstractEventLoop The event loop used by the timer to track time. missed_tick_policy : MissedTickPolicy property \u00a4 The policy of the timer when it misses a tick. RETURNS DESCRIPTION MissedTickPolicy The policy of the timer when it misses a tick. Functions \u00a4 __init__ ( interval , missed_tick_policy , / , * , auto_start = True , loop = None ) \u00a4 Create an instance. See the class documentation for details. PARAMETER DESCRIPTION interval The time between timer ticks. Must be at least 1 microsecond. TYPE: timedelta missed_tick_policy The policy of the timer when it misses a tick. See the documentation of MissedTickPolicy for details. TYPE: MissedTickPolicy auto_start Whether the timer should be started when the instance is created. This can only be True if there is already a running loop or an explicit loop that is running was passed. TYPE: bool DEFAULT: True loop The event loop to use to track time. If None , asyncio.get_running_loop() will be used. TYPE: asyncio . AbstractEventLoop | None DEFAULT: None RAISES DESCRIPTION RuntimeError if it was called without a loop and there is no running loop. ValueError if interval is not positive or is smaller than 1 microsecond. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_timer.py 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 def __init__ ( self , interval : timedelta , missed_tick_policy : MissedTickPolicy , / , * , auto_start : bool = True , loop : asyncio . AbstractEventLoop | None = None , ) -> None : \"\"\"Create an instance. See the class documentation for details. Args: interval: The time between timer ticks. Must be at least 1 microsecond. missed_tick_policy: The policy of the timer when it misses a tick. See the documentation of `MissedTickPolicy` for details. auto_start: Whether the timer should be started when the instance is created. This can only be `True` if there is already a running loop or an explicit `loop` that is running was passed. loop: The event loop to use to track time. If `None`, `asyncio.get_running_loop()` will be used. Raises: RuntimeError: if it was called without a loop and there is no running loop. ValueError: if `interval` is not positive or is smaller than 1 microsecond. \"\"\" self . _interval : int = _to_microseconds ( interval ) \"\"\"The time to between timer ticks.\"\"\" self . _missed_tick_policy : MissedTickPolicy = missed_tick_policy \"\"\"The policy of the timer when it misses a tick. See the documentation of `MissedTickPolicy` for details. \"\"\" self . _loop : asyncio . AbstractEventLoop = ( loop if loop is not None else asyncio . get_running_loop () ) \"\"\"The event loop to use to track time.\"\"\" self . _stopped : bool = True \"\"\"Whether the timer was requested to stop. If this is `False`, then the timer is running. If this is `True`, then it is stopped or there is a request to stop it or it was not started yet: * If `_next_msg_time` is `None`, it means it wasn't started yet (it was created with `auto_start=False`). Any receiving method will start it by calling `reset()` in this case. * If `_next_msg_time` is not `None`, it means there was a request to stop it. In this case receiving methods will raise a `ReceiverClosedError`. \"\"\" self . _next_tick_time : int | None = None \"\"\"The absolute (monotonic) time when the timer should trigger. If this is `None`, it means the timer didn't start yet, but it should be started as soon as it is used. \"\"\" self . _current_drift : timedelta | None = None \"\"\"The difference between `_next_msg_time` and the triggered time. This is calculated by `ready()` but is returned by `consume()`. If `None` it means `ready()` wasn't called and `consume()` will assert. `consume()` will set it back to `None` to tell `ready()` that it needs to wait again. \"\"\" if self . _interval <= 0 : raise ValueError ( \"The `interval` must be positive and at least 1 microsecond, \" f \"not { interval } ( { self . _interval } microseconds)\" ) if auto_start : self . reset () consume () \u00a4 Return the latest drift once ready() is complete. Once the timer has triggered ( ready() is done), this method returns the difference between when the timer should have triggered and the time when it actually triggered. See the class documentation for more details. RETURNS DESCRIPTION timedelta The difference between when the timer should have triggered and the time when it actually did. RAISES DESCRIPTION ReceiverStoppedError if the timer was stopped via stop() . Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_timer.py 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 def consume ( self ) -> timedelta : \"\"\"Return the latest drift once `ready()` is complete. Once the timer has triggered (`ready()` is done), this method returns the difference between when the timer should have triggered and the time when it actually triggered. See the class documentation for more details. Returns: The difference between when the timer should have triggered and the time when it actually did. Raises: ReceiverStoppedError: if the timer was stopped via `stop()`. \"\"\" # If it was stopped and there it no pending result, we raise # (if there is a pending result, then we still want to return it first) if self . _stopped and self . _current_drift is None : raise ReceiverStoppedError ( self ) assert ( self . _current_drift is not None ), \"calls to `consume()` must be follow a call to `ready()`\" drift = self . _current_drift self . _current_drift = None return drift periodic ( period , / , * , skip_missed_ticks = False , auto_start = True , loop = None ) classmethod \u00a4 Create a periodic timer. This is basically a shortcut to create a timer with either TriggerAllMissed() or SkipMissedAndResync() as the missed tick policy (depending on skip_missed_ticks ). See the class documentation for details. PARAMETER DESCRIPTION period The time between timer ticks. Must be at least 1 microsecond. TYPE: timedelta skip_missed_ticks Whether to skip missed ticks or trigger them all until it catches up. TYPE: bool DEFAULT: False auto_start Whether the timer should be started when the instance is created. This can only be True if there is already a running loop or an explicit loop that is running was passed. TYPE: bool DEFAULT: True loop The event loop to use to track time. If None , asyncio.get_running_loop() will be used. TYPE: asyncio . AbstractEventLoop | None DEFAULT: None RETURNS DESCRIPTION Timer The timer instance. RAISES DESCRIPTION RuntimeError if it was called without a loop and there is no running loop. ValueError if interval is not positive or is smaller than 1 microsecond. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_timer.py 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 @classmethod def periodic ( cls , period : timedelta , / , * , skip_missed_ticks : bool = False , auto_start : bool = True , loop : asyncio . AbstractEventLoop | None = None , ) -> Timer : \"\"\"Create a periodic timer. This is basically a shortcut to create a timer with either `TriggerAllMissed()` or `SkipMissedAndResync()` as the missed tick policy (depending on `skip_missed_ticks`). See the class documentation for details. Args: period: The time between timer ticks. Must be at least 1 microsecond. skip_missed_ticks: Whether to skip missed ticks or trigger them all until it catches up. auto_start: Whether the timer should be started when the instance is created. This can only be `True` if there is already a running loop or an explicit `loop` that is running was passed. loop: The event loop to use to track time. If `None`, `asyncio.get_running_loop()` will be used. Returns: The timer instance. Raises: RuntimeError: if it was called without a loop and there is no running loop. ValueError: if `interval` is not positive or is smaller than 1 microsecond. \"\"\" missed_tick_policy = ( SkipMissedAndResync () if skip_missed_ticks else TriggerAllMissed () ) return Timer ( period , missed_tick_policy , auto_start = auto_start , loop = loop , ) ready () async \u00a4 Wait until the timer interval passed. Once a call to ready() has finished, the resulting tick information must be read with a call to consume() ( receive() or iterated over) to tell the timer it should wait for the next interval. The timer will remain ready (this method will return immediately) until it is consumed. RETURNS DESCRIPTION bool Whether the timer was started and it is still running. RAISES DESCRIPTION RuntimeError if it was called without a running loop. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_timer.py 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 async def ready ( self ) -> bool : \"\"\"Wait until the timer `interval` passed. Once a call to `ready()` has finished, the resulting tick information must be read with a call to `consume()` (`receive()` or iterated over) to tell the timer it should wait for the next interval. The timer will remain ready (this method will return immediately) until it is consumed. Returns: Whether the timer was started and it is still running. Raises: RuntimeError: if it was called without a running loop. \"\"\" # If there are messages waiting to be consumed, return immediately. if self . _current_drift is not None : return True # If `_next_tick_time` is `None`, it means it was created with # `auto_start=False` and should be started. if self . _next_tick_time is None : self . reset () assert ( self . _next_tick_time is not None ), \"This should be assigned by reset()\" # If a stop was explicitly requested, we bail out. if self . _stopped : return False now = self . _now () time_to_next_tick = self . _next_tick_time - now # If we didn't reach the tick yet, sleep until we do. if time_to_next_tick > 0 : await asyncio . sleep ( time_to_next_tick / 1_000_000 ) now = self . _now () # If a stop was explicitly requested during the sleep, we bail out. if self . _stopped : return False self . _current_drift = timedelta ( microseconds = now - self . _next_tick_time ) self . _next_tick_time = self . _missed_tick_policy . calculate_next_tick_time ( now = now , scheduled_tick_time = self . _next_tick_time , interval = self . _interval , ) return True reset () \u00a4 Reset the timer to start timing from now. If the timer was stopped, or not started yet, it will be started. This can only be called with a running loop, see the class documentation for more details. RAISES DESCRIPTION RuntimeError if it was called without a running loop. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_timer.py 551 552 553 554 555 556 557 558 559 560 561 562 563 564 def reset ( self ) -> None : \"\"\"Reset the timer to start timing from now. If the timer was stopped, or not started yet, it will be started. This can only be called with a running loop, see the class documentation for more details. Raises: RuntimeError: if it was called without a running loop. \"\"\" self . _stopped = False self . _next_tick_time = self . _now () + self . _interval self . _current_drift = None stop () \u00a4 Stop the timer. Once stop has been called, all subsequent calls to ready() will immediately return False and calls to consume() / receive() or any use of the async iterator interface will raise a ReceiverStoppedError . You can restart the timer with reset() . Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_timer.py 566 567 568 569 570 571 572 573 574 575 576 577 578 def stop ( self ) -> None : \"\"\"Stop the timer. Once `stop` has been called, all subsequent calls to `ready()` will immediately return False and calls to `consume()` / `receive()` or any use of the async iterator interface will raise a `ReceiverStoppedError`. You can restart the timer with `reset()`. \"\"\" self . _stopped = True # We need to make sure it's not None, otherwise `ready()` will start it self . _next_tick_time = self . _now () timeout ( delay , / , * , auto_start = True , loop = None ) classmethod \u00a4 Create a timer useful for tracking timeouts. This is basically a shortcut to create a timer with SkipMissedAndDrift(delay_tolerance=timedelta(0)) as the missed tick policy. See the class documentation for details. PARAMETER DESCRIPTION delay The time until the timer ticks. Must be at least 1 microsecond. TYPE: timedelta auto_start Whether the timer should be started when the instance is created. This can only be True if there is already a running loop or an explicit loop that is running was passed. TYPE: bool DEFAULT: True loop The event loop to use to track time. If None , asyncio.get_running_loop() will be used. TYPE: asyncio . AbstractEventLoop | None DEFAULT: None RETURNS DESCRIPTION Timer The timer instance. RAISES DESCRIPTION RuntimeError if it was called without a loop and there is no running loop. ValueError if interval is not positive or is smaller than 1 microsecond. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_timer.py 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 @classmethod def timeout ( cls , delay : timedelta , / , * , auto_start : bool = True , loop : asyncio . AbstractEventLoop | None = None , ) -> Timer : \"\"\"Create a timer useful for tracking timeouts. This is basically a shortcut to create a timer with `SkipMissedAndDrift(delay_tolerance=timedelta(0))` as the missed tick policy. See the class documentation for details. Args: delay: The time until the timer ticks. Must be at least 1 microsecond. auto_start: Whether the timer should be started when the instance is created. This can only be `True` if there is already a running loop or an explicit `loop` that is running was passed. loop: The event loop to use to track time. If `None`, `asyncio.get_running_loop()` will be used. Returns: The timer instance. Raises: RuntimeError: if it was called without a loop and there is no running loop. ValueError: if `interval` is not positive or is smaller than 1 microsecond. \"\"\" return Timer ( delay , SkipMissedAndDrift ( delay_tolerance = timedelta ( 0 )), auto_start = auto_start , loop = loop , ) frequenz.channels.util.TriggerAllMissed \u00a4 Bases: MissedTickPolicy A policy that triggers all the missed ticks immediately until it catches up. Example Assume a timer with interval 1 second, the tick T0 happens exactly at time 0, the second tick, T1 , happens at time 1.2 (0.2 seconds late), so it trigges immediately. The third tick, T2 , happens at time 2.3 (0.3 seconds late), so it also triggers immediately. The fourth tick, T3 , happens at time 4.3 (1.3 seconds late), so it also triggers immediately as well as the fifth tick, T4 , which was also already delayed (by 0.3 seconds), so it catches up. The sixth tick, T5 , happens at 5.1 (0.1 seconds late), so it triggers immediately again. The seventh tick, T6 , happens at 6.0, right on time. 0 1 2 3 4 o 5 6 o---------|-o-------|--o------|---------|--o------|o--------o-----> time T0 T1 T2 T3 T5 T6 T4 Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_timer.py 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 class TriggerAllMissed ( MissedTickPolicy ): \"\"\"A policy that triggers all the missed ticks immediately until it catches up. Example: Assume a timer with interval 1 second, the tick `T0` happens exactly at time 0, the second tick, `T1`, happens at time 1.2 (0.2 seconds late), so it trigges immediately. The third tick, `T2`, happens at time 2.3 (0.3 seconds late), so it also triggers immediately. The fourth tick, `T3`, happens at time 4.3 (1.3 seconds late), so it also triggers immediately as well as the fifth tick, `T4`, which was also already delayed (by 0.3 seconds), so it catches up. The sixth tick, `T5`, happens at 5.1 (0.1 seconds late), so it triggers immediately again. The seventh tick, `T6`, happens at 6.0, right on time. ``` 0 1 2 3 4 o 5 6 o---------|-o-------|--o------|---------|--o------|o--------o-----> time T0 T1 T2 T3 T5 T6 T4 ``` \"\"\" def calculate_next_tick_time ( self , * , now : int , scheduled_tick_time : int , interval : int ) -> int : \"\"\"Calculate the next tick time. This method always returns `scheduled_tick_time + interval`, as all ticks need to produce a trigger event. Args: now: The current loop time (in microseconds). scheduled_tick_time: The time the current tick was scheduled to trigger (in microseconds). interval: The interval between ticks (in microseconds). Returns: The next tick time (in microseconds). \"\"\" return scheduled_tick_time + interval Functions \u00a4 calculate_next_tick_time ( * , now , scheduled_tick_time , interval ) \u00a4 Calculate the next tick time. This method always returns scheduled_tick_time + interval , as all ticks need to produce a trigger event. PARAMETER DESCRIPTION now The current loop time (in microseconds). TYPE: int scheduled_tick_time The time the current tick was scheduled to trigger (in microseconds). TYPE: int interval The interval between ticks (in microseconds). TYPE: int RETURNS DESCRIPTION int The next tick time (in microseconds). Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_timer.py 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 def calculate_next_tick_time ( self , * , now : int , scheduled_tick_time : int , interval : int ) -> int : \"\"\"Calculate the next tick time. This method always returns `scheduled_tick_time + interval`, as all ticks need to produce a trigger event. Args: now: The current loop time (in microseconds). scheduled_tick_time: The time the current tick was scheduled to trigger (in microseconds). interval: The interval between ticks (in microseconds). Returns: The next tick time (in microseconds). \"\"\" return scheduled_tick_time + interval","title":"util"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util","text":"Channel utilities. A module with several utilities to work with channels: FileWatcher : A receiver that watches for file events. Merge : A receiver that merge messages coming from multiple receivers into a single stream. MergeNamed : A receiver that merge messages coming from multiple receivers into a single named stream, allowing to identify the origin of each message. Timer : A receiver that ticks at certain intervals. Select : A helper to select the next available message for each receiver in a group of receivers.","title":"util"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util-classes","text":"","title":"Classes"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util.FileWatcher","text":"Bases: Receiver [ Event ] A channel receiver that watches for file events. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_file_watcher.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 class FileWatcher ( Receiver [ \"FileWatcher.Event\" ]): \"\"\"A channel receiver that watches for file events.\"\"\" class EventType ( Enum ): \"\"\"Available types of changes to watch for.\"\"\" CREATE = Change . added MODIFY = Change . modified DELETE = Change . deleted @dataclass ( frozen = True ) class Event : \"\"\"A file change event.\"\"\" type : FileWatcher . EventType \"\"\"The type of change that was observed.\"\"\" path : pathlib . Path \"\"\"The path where the change was observed.\"\"\" def __init__ ( self , paths : list [ pathlib . Path | str ], event_types : set [ EventType ] | None = None , ) -> None : \"\"\"Create a `FileWatcher` instance. Args: paths: Paths to watch for changes. event_types: Types of events to watch for or `None` to watch for all event types. \"\"\" if event_types is None : event_types = set ( FileWatcher . EventType ) # all types self . event_types = event_types self . _stop_event = asyncio . Event () self . _paths = [ path if isinstance ( path , pathlib . Path ) else pathlib . Path ( path ) for path in paths ] self . _awatch = awatch ( * self . _paths , stop_event = self . _stop_event , watch_filter = self . _filter_events ) self . _awatch_stopped_exc : Exception | None = None self . _changes : set [ FileChange ] = set () def _filter_events ( self , change : Change , path : str , # pylint: disable=unused-argument ) -> bool : \"\"\"Filter events based on the event type and path. Args: change: The type of change to be notified. path: The path of the file that changed. Returns: Whether the event should be notified. \"\"\" return change in [ event_type . value for event_type in self . event_types ] def __del__ ( self ) -> None : \"\"\"Cleanup registered watches. `awatch` passes the `stop_event` to a separate task/thread. This way `awatch` getting destroyed properly. The background task will continue until the signal is received. \"\"\" self . _stop_event . set () async def ready ( self ) -> bool : \"\"\"Wait until the receiver is ready with a value or an error. Once a call to `ready()` has finished, the value should be read with a call to `consume()` (`receive()` or iterated over). The receiver will remain ready (this method will return immediately) until it is consumed. Returns: Whether the receiver is still active. \"\"\" # if there are messages waiting to be consumed, return immediately. if self . _changes : return True # if it was already stopped, return immediately. if self . _awatch_stopped_exc is not None : return False try : self . _changes = await self . _awatch . __anext__ () except StopAsyncIteration as err : self . _awatch_stopped_exc = err return True def consume ( self ) -> Event : \"\"\"Return the latest event once `ready` is complete. Returns: The next event that was received. Raises: ReceiverStoppedError: if there is some problem with the receiver. \"\"\" if not self . _changes and self . _awatch_stopped_exc is not None : raise ReceiverStoppedError ( self ) from self._awatch_stopped_exc assert self . _changes , \"`consume()` must be preceeded by a call to `ready()`\" # Tuple of (Change, path) returned by watchfiles change , path_str = self . _changes . pop () return FileWatcher . Event ( type = FileWatcher . EventType ( change ), path = pathlib . Path ( path_str ) )","title":"FileWatcher"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util.FileWatcher-classes","text":"","title":"Classes"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util._file_watcher.FileWatcher.Event","text":"A file change event. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_file_watcher.py 30 31 32 33 34 35 36 37 @dataclass ( frozen = True ) class Event : \"\"\"A file change event.\"\"\" type : FileWatcher . EventType \"\"\"The type of change that was observed.\"\"\" path : pathlib . Path \"\"\"The path where the change was observed.\"\"\" Attributes \u00a4 path : pathlib . Path instance-attribute \u00a4 The path where the change was observed. type : FileWatcher . EventType instance-attribute \u00a4 The type of change that was observed.","title":"Event"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util._file_watcher.FileWatcher.EventType","text":"Bases: Enum Available types of changes to watch for. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_file_watcher.py 23 24 25 26 27 28 class EventType ( Enum ): \"\"\"Available types of changes to watch for.\"\"\" CREATE = Change . added MODIFY = Change . modified DELETE = Change . deleted","title":"EventType"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util.FileWatcher-functions","text":"","title":"Functions"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util._file_watcher.FileWatcher.__del__","text":"Cleanup registered watches. awatch passes the stop_event to a separate task/thread. This way awatch getting destroyed properly. The background task will continue until the signal is received. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_file_watcher.py 82 83 84 85 86 87 88 89 def __del__ ( self ) -> None : \"\"\"Cleanup registered watches. `awatch` passes the `stop_event` to a separate task/thread. This way `awatch` getting destroyed properly. The background task will continue until the signal is received. \"\"\" self . _stop_event . set ()","title":"__del__()"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util._file_watcher.FileWatcher.__init__","text":"Create a FileWatcher instance. PARAMETER DESCRIPTION paths Paths to watch for changes. TYPE: list [ pathlib . Path | str ] event_types Types of events to watch for or None to watch for all event types. TYPE: set [ EventType ] | None DEFAULT: None Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_file_watcher.py 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 def __init__ ( self , paths : list [ pathlib . Path | str ], event_types : set [ EventType ] | None = None , ) -> None : \"\"\"Create a `FileWatcher` instance. Args: paths: Paths to watch for changes. event_types: Types of events to watch for or `None` to watch for all event types. \"\"\" if event_types is None : event_types = set ( FileWatcher . EventType ) # all types self . event_types = event_types self . _stop_event = asyncio . Event () self . _paths = [ path if isinstance ( path , pathlib . Path ) else pathlib . Path ( path ) for path in paths ] self . _awatch = awatch ( * self . _paths , stop_event = self . _stop_event , watch_filter = self . _filter_events ) self . _awatch_stopped_exc : Exception | None = None self . _changes : set [ FileChange ] = set ()","title":"__init__()"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util._file_watcher.FileWatcher.consume","text":"Return the latest event once ready is complete. RETURNS DESCRIPTION Event The next event that was received. RAISES DESCRIPTION ReceiverStoppedError if there is some problem with the receiver. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_file_watcher.py 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 def consume ( self ) -> Event : \"\"\"Return the latest event once `ready` is complete. Returns: The next event that was received. Raises: ReceiverStoppedError: if there is some problem with the receiver. \"\"\" if not self . _changes and self . _awatch_stopped_exc is not None : raise ReceiverStoppedError ( self ) from self._awatch_stopped_exc assert self . _changes , \"`consume()` must be preceeded by a call to `ready()`\" # Tuple of (Change, path) returned by watchfiles change , path_str = self . _changes . pop () return FileWatcher . Event ( type = FileWatcher . EventType ( change ), path = pathlib . Path ( path_str ) )","title":"consume()"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util._file_watcher.FileWatcher.ready","text":"Wait until the receiver is ready with a value or an error. Once a call to ready() has finished, the value should be read with a call to consume() ( receive() or iterated over). The receiver will remain ready (this method will return immediately) until it is consumed. RETURNS DESCRIPTION bool Whether the receiver is still active. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_file_watcher.py 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 async def ready ( self ) -> bool : \"\"\"Wait until the receiver is ready with a value or an error. Once a call to `ready()` has finished, the value should be read with a call to `consume()` (`receive()` or iterated over). The receiver will remain ready (this method will return immediately) until it is consumed. Returns: Whether the receiver is still active. \"\"\" # if there are messages waiting to be consumed, return immediately. if self . _changes : return True # if it was already stopped, return immediately. if self . _awatch_stopped_exc is not None : return False try : self . _changes = await self . _awatch . __anext__ () except StopAsyncIteration as err : self . _awatch_stopped_exc = err return True","title":"ready()"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util.Merge","text":"Bases: Receiver [ T ] Merge messages coming from multiple channels into a single stream. Example For example, if there are two channel receivers with the same type, they can be awaited together, and their results merged into a single stream, by using Merge like this: merge = Merge ( receiver1 , receiver2 ) while msg := await merge . receive (): # do something with msg pass When merge is no longer needed, then it should be stopped using self.stop() method. This will cleanup any internal pending async tasks. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_merge.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 class Merge ( Receiver [ T ]): \"\"\"Merge messages coming from multiple channels into a single stream. Example: For example, if there are two channel receivers with the same type, they can be awaited together, and their results merged into a single stream, by using `Merge` like this: ```python merge = Merge(receiver1, receiver2) while msg := await merge.receive(): # do something with msg pass ``` When `merge` is no longer needed, then it should be stopped using `self.stop()` method. This will cleanup any internal pending async tasks. \"\"\" def __init__ ( self , * args : Receiver [ T ]) -> None : \"\"\"Create a `Merge` instance. Args: *args: sequence of channel receivers. \"\"\" self . _receivers = { str ( id ): recv for id , recv in enumerate ( args )} self . _pending : Set [ asyncio . Task [ Any ]] = { asyncio . create_task ( recv . __anext__ (), name = name ) for name , recv in self . _receivers . items () } self . _results : Deque [ T ] = deque ( maxlen = len ( self . _receivers )) def __del__ ( self ) -> None : \"\"\"Cleanup any pending tasks.\"\"\" for task in self . _pending : if not task . done () and task . get_loop () . is_running (): task . cancel () async def stop ( self ) -> None : \"\"\"Stop the `Merge` instance and cleanup any pending tasks.\"\"\" for task in self . _pending : task . cancel () await asyncio . gather ( * self . _pending , return_exceptions = True ) self . _pending = set () async def ready ( self ) -> bool : \"\"\"Wait until the receiver is ready with a value or an error. Once a call to `ready()` has finished, the value should be read with a call to `consume()` (`receive()` or iterated over). The receiver will remain ready (this method will return immediately) until it is consumed. Returns: Whether the receiver is still active. \"\"\" # we use a while loop to continue to wait for new data, in case the # previous `wait` completed because a channel was closed. while True : # if there are messages waiting to be consumed, return immediately. if len ( self . _results ) > 0 : return True # if there are no more pending receivers, we return immediately. if len ( self . _pending ) == 0 : return False done , self . _pending = await asyncio . wait ( self . _pending , return_when = asyncio . FIRST_COMPLETED ) for item in done : name = item . get_name () # if channel is closed, don't add a task for it again. if isinstance ( item . exception (), StopAsyncIteration ): continue result = item . result () self . _results . append ( result ) self . _pending . add ( # pylint: disable=unnecessary-dunder-call asyncio . create_task ( self . _receivers [ name ] . __anext__ (), name = name ) ) def consume ( self ) -> T : \"\"\"Return the latest value once `ready` is complete. Returns: The next value that was received. Raises: ReceiverStoppedError: if the receiver stopped producing messages. ReceiverError: if there is some problem with the receiver. \"\"\" if not self . _results and not self . _pending : raise ReceiverStoppedError ( self ) assert self . _results , \"`consume()` must be preceeded by a call to `ready()`\" return self . _results . popleft ()","title":"Merge"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util.Merge-functions","text":"","title":"Functions"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util._merge.Merge.__del__","text":"Cleanup any pending tasks. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_merge.py 46 47 48 49 50 def __del__ ( self ) -> None : \"\"\"Cleanup any pending tasks.\"\"\" for task in self . _pending : if not task . done () and task . get_loop () . is_running (): task . cancel ()","title":"__del__()"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util._merge.Merge.__init__","text":"Create a Merge instance. PARAMETER DESCRIPTION *args sequence of channel receivers. TYPE: Receiver [ T ] DEFAULT: () Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_merge.py 33 34 35 36 37 38 39 40 41 42 43 44 def __init__ ( self , * args : Receiver [ T ]) -> None : \"\"\"Create a `Merge` instance. Args: *args: sequence of channel receivers. \"\"\" self . _receivers = { str ( id ): recv for id , recv in enumerate ( args )} self . _pending : Set [ asyncio . Task [ Any ]] = { asyncio . create_task ( recv . __anext__ (), name = name ) for name , recv in self . _receivers . items () } self . _results : Deque [ T ] = deque ( maxlen = len ( self . _receivers ))","title":"__init__()"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util._merge.Merge.consume","text":"Return the latest value once ready is complete. RETURNS DESCRIPTION T The next value that was received. RAISES DESCRIPTION ReceiverStoppedError if the receiver stopped producing messages. ReceiverError if there is some problem with the receiver. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_merge.py 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 def consume ( self ) -> T : \"\"\"Return the latest value once `ready` is complete. Returns: The next value that was received. Raises: ReceiverStoppedError: if the receiver stopped producing messages. ReceiverError: if there is some problem with the receiver. \"\"\" if not self . _results and not self . _pending : raise ReceiverStoppedError ( self ) assert self . _results , \"`consume()` must be preceeded by a call to `ready()`\" return self . _results . popleft ()","title":"consume()"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util._merge.Merge.ready","text":"Wait until the receiver is ready with a value or an error. Once a call to ready() has finished, the value should be read with a call to consume() ( receive() or iterated over). The receiver will remain ready (this method will return immediately) until it is consumed. RETURNS DESCRIPTION bool Whether the receiver is still active. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_merge.py 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 async def ready ( self ) -> bool : \"\"\"Wait until the receiver is ready with a value or an error. Once a call to `ready()` has finished, the value should be read with a call to `consume()` (`receive()` or iterated over). The receiver will remain ready (this method will return immediately) until it is consumed. Returns: Whether the receiver is still active. \"\"\" # we use a while loop to continue to wait for new data, in case the # previous `wait` completed because a channel was closed. while True : # if there are messages waiting to be consumed, return immediately. if len ( self . _results ) > 0 : return True # if there are no more pending receivers, we return immediately. if len ( self . _pending ) == 0 : return False done , self . _pending = await asyncio . wait ( self . _pending , return_when = asyncio . FIRST_COMPLETED ) for item in done : name = item . get_name () # if channel is closed, don't add a task for it again. if isinstance ( item . exception (), StopAsyncIteration ): continue result = item . result () self . _results . append ( result ) self . _pending . add ( # pylint: disable=unnecessary-dunder-call asyncio . create_task ( self . _receivers [ name ] . __anext__ (), name = name ) )","title":"ready()"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util._merge.Merge.stop","text":"Stop the Merge instance and cleanup any pending tasks. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_merge.py 52 53 54 55 56 57 async def stop ( self ) -> None : \"\"\"Stop the `Merge` instance and cleanup any pending tasks.\"\"\" for task in self . _pending : task . cancel () await asyncio . gather ( * self . _pending , return_exceptions = True ) self . _pending = set ()","title":"stop()"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util.MergeNamed","text":"Bases: Receiver [ Tuple [ str , T ]] Merge messages coming from multiple named channels into a single stream. When MergeNamed is no longer needed, then it should be stopped using self.stop() method. This will cleanup any internal pending async tasks. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_merge_named.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 class MergeNamed ( Receiver [ Tuple [ str , T ]]): \"\"\"Merge messages coming from multiple named channels into a single stream. When `MergeNamed` is no longer needed, then it should be stopped using `self.stop()` method. This will cleanup any internal pending async tasks. \"\"\" def __init__ ( self , ** kwargs : Receiver [ T ]) -> None : \"\"\"Create a `MergeNamed` instance. Args: **kwargs: sequence of channel receivers. \"\"\" self . _receivers = kwargs self . _pending : Set [ asyncio . Task [ Any ]] = { asyncio . create_task ( recv . __anext__ (), name = name ) for name , recv in self . _receivers . items () } self . _results : Deque [ Tuple [ str , T ]] = deque ( maxlen = len ( self . _receivers )) def __del__ ( self ) -> None : \"\"\"Cleanup any pending tasks.\"\"\" for task in self . _pending : if not task . done () and task . get_loop () . is_running (): task . cancel () async def stop ( self ) -> None : \"\"\"Stop the `MergeNamed` instance and cleanup any pending tasks.\"\"\" for task in self . _pending : task . cancel () await asyncio . gather ( * self . _pending , return_exceptions = True ) self . _pending = set () async def ready ( self ) -> bool : \"\"\"Wait until the receiver is ready with a value or an error. Once a call to `ready()` has finished, the value should be read with a call to `consume()` (`receive()` or iterated over). The receiver will remain ready (this method will return immediately) until it is consumed. Returns: Whether the receiver is still active. \"\"\" # we use a while loop to continue to wait for new data, in case the # previous `wait` completed because a channel was closed. while True : # if there are messages waiting to be consumed, return immediately. if len ( self . _results ) > 0 : return True # if there are no more pending receivers, we return immediately. if len ( self . _pending ) == 0 : return False done , self . _pending = await asyncio . wait ( self . _pending , return_when = asyncio . FIRST_COMPLETED ) for item in done : name = item . get_name () # if channel is closed, don't add a task for it again. if isinstance ( item . exception (), StopAsyncIteration ): continue result = item . result () self . _results . append (( name , result )) self . _pending . add ( # pylint: disable=unnecessary-dunder-call asyncio . create_task ( self . _receivers [ name ] . __anext__ (), name = name ) ) def consume ( self ) -> Tuple [ str , T ]: \"\"\"Return the latest value once `ready` is complete. Returns: The next key, value that was received. Raises: ReceiverStoppedError: if the receiver stopped producing messages. ReceiverError: if there is some problem with the receiver. \"\"\" if not self . _results and not self . _pending : raise ReceiverStoppedError ( self ) assert self . _results , \"`consume()` must be preceeded by a call to `ready()`\" return self . _results . popleft ()","title":"MergeNamed"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util.MergeNamed-functions","text":"","title":"Functions"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util._merge_named.MergeNamed.__del__","text":"Cleanup any pending tasks. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_merge_named.py 34 35 36 37 38 def __del__ ( self ) -> None : \"\"\"Cleanup any pending tasks.\"\"\" for task in self . _pending : if not task . done () and task . get_loop () . is_running (): task . cancel ()","title":"__del__()"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util._merge_named.MergeNamed.__init__","text":"Create a MergeNamed instance. PARAMETER DESCRIPTION **kwargs sequence of channel receivers. TYPE: Receiver [ T ] DEFAULT: {} Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_merge_named.py 21 22 23 24 25 26 27 28 29 30 31 32 def __init__ ( self , ** kwargs : Receiver [ T ]) -> None : \"\"\"Create a `MergeNamed` instance. Args: **kwargs: sequence of channel receivers. \"\"\" self . _receivers = kwargs self . _pending : Set [ asyncio . Task [ Any ]] = { asyncio . create_task ( recv . __anext__ (), name = name ) for name , recv in self . _receivers . items () } self . _results : Deque [ Tuple [ str , T ]] = deque ( maxlen = len ( self . _receivers ))","title":"__init__()"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util._merge_named.MergeNamed.consume","text":"Return the latest value once ready is complete. RETURNS DESCRIPTION Tuple [ str , T ] The next key, value that was received. RAISES DESCRIPTION ReceiverStoppedError if the receiver stopped producing messages. ReceiverError if there is some problem with the receiver. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_merge_named.py 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 def consume ( self ) -> Tuple [ str , T ]: \"\"\"Return the latest value once `ready` is complete. Returns: The next key, value that was received. Raises: ReceiverStoppedError: if the receiver stopped producing messages. ReceiverError: if there is some problem with the receiver. \"\"\" if not self . _results and not self . _pending : raise ReceiverStoppedError ( self ) assert self . _results , \"`consume()` must be preceeded by a call to `ready()`\" return self . _results . popleft ()","title":"consume()"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util._merge_named.MergeNamed.ready","text":"Wait until the receiver is ready with a value or an error. Once a call to ready() has finished, the value should be read with a call to consume() ( receive() or iterated over). The receiver will remain ready (this method will return immediately) until it is consumed. RETURNS DESCRIPTION bool Whether the receiver is still active. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_merge_named.py 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 async def ready ( self ) -> bool : \"\"\"Wait until the receiver is ready with a value or an error. Once a call to `ready()` has finished, the value should be read with a call to `consume()` (`receive()` or iterated over). The receiver will remain ready (this method will return immediately) until it is consumed. Returns: Whether the receiver is still active. \"\"\" # we use a while loop to continue to wait for new data, in case the # previous `wait` completed because a channel was closed. while True : # if there are messages waiting to be consumed, return immediately. if len ( self . _results ) > 0 : return True # if there are no more pending receivers, we return immediately. if len ( self . _pending ) == 0 : return False done , self . _pending = await asyncio . wait ( self . _pending , return_when = asyncio . FIRST_COMPLETED ) for item in done : name = item . get_name () # if channel is closed, don't add a task for it again. if isinstance ( item . exception (), StopAsyncIteration ): continue result = item . result () self . _results . append (( name , result )) self . _pending . add ( # pylint: disable=unnecessary-dunder-call asyncio . create_task ( self . _receivers [ name ] . __anext__ (), name = name ) )","title":"ready()"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util._merge_named.MergeNamed.stop","text":"Stop the MergeNamed instance and cleanup any pending tasks. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_merge_named.py 40 41 42 43 44 45 async def stop ( self ) -> None : \"\"\"Stop the `MergeNamed` instance and cleanup any pending tasks.\"\"\" for task in self . _pending : task . cancel () await asyncio . gather ( * self . _pending , return_exceptions = True ) self . _pending = set ()","title":"stop()"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util.MissedTickPolicy","text":"Bases: abc . ABC A policy to handle timer missed ticks. This is only relevant if the timer is not ready to trigger when it should (an interval passed) which can happen if the event loop is busy processing other tasks. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_timer.py 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 class MissedTickPolicy ( abc . ABC ): \"\"\"A policy to handle timer missed ticks. This is only relevant if the timer is not ready to trigger when it should (an interval passed) which can happen if the event loop is busy processing other tasks. \"\"\" @abc . abstractmethod def calculate_next_tick_time ( self , * , interval : int , scheduled_tick_time : int , now : int ) -> int : \"\"\"Calculate the next tick time according to `missed_tick_policy`. This method is called by `ready()` after it has determined that the timer has triggered. It will check if the timer has missed any ticks and handle them according to `missed_tick_policy`. Args: interval: The interval between ticks (in microseconds). scheduled_tick_time: The time the current tick was scheduled to trigger (in microseconds). now: The current loop time (in microseconds). Returns: The next tick time (in microseconds) according to `missed_tick_policy`. \"\"\" return 0 # dummy value to avoid darglint warnings","title":"MissedTickPolicy"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util.MissedTickPolicy-functions","text":"","title":"Functions"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util._timer.MissedTickPolicy.calculate_next_tick_time","text":"Calculate the next tick time according to missed_tick_policy . This method is called by ready() after it has determined that the timer has triggered. It will check if the timer has missed any ticks and handle them according to missed_tick_policy . PARAMETER DESCRIPTION interval The interval between ticks (in microseconds). TYPE: int scheduled_tick_time The time the current tick was scheduled to trigger (in microseconds). TYPE: int now The current loop time (in microseconds). TYPE: int RETURNS DESCRIPTION int The next tick time (in microseconds) according to missed_tick_policy . Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_timer.py 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 @abc . abstractmethod def calculate_next_tick_time ( self , * , interval : int , scheduled_tick_time : int , now : int ) -> int : \"\"\"Calculate the next tick time according to `missed_tick_policy`. This method is called by `ready()` after it has determined that the timer has triggered. It will check if the timer has missed any ticks and handle them according to `missed_tick_policy`. Args: interval: The interval between ticks (in microseconds). scheduled_tick_time: The time the current tick was scheduled to trigger (in microseconds). now: The current loop time (in microseconds). Returns: The next tick time (in microseconds) according to `missed_tick_policy`. \"\"\" return 0 # dummy value to avoid darglint warnings","title":"calculate_next_tick_time()"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util.Select","text":"Select the next available message from a group of Receivers. If Select was created with more Receiver than what are read in the if-chain after each call to ready() , messages coming in the additional receivers are dropped, and a warning message is logged. Receiver s also function as Receiver . When Select is no longer needed, then it should be stopped using self.stop() method. This would cleanup any internal pending async tasks. Example For example, if there are two receivers that you want to simultaneously wait on, this can be done with: select = Select ( name1 = receiver1 , name2 = receiver2 ) while await select . ready (): if msg := select . name1 : if val := msg . inner : # do something with `val` pass else : # handle closure of receiver. pass elif msg := select . name2 : # do something with `msg.inner` pass Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_select.py 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 class Select : \"\"\"Select the next available message from a group of Receivers. If `Select` was created with more `Receiver` than what are read in the if-chain after each call to [ready()][frequenz.channels.util.Select.ready], messages coming in the additional receivers are dropped, and a warning message is logged. [Receiver][frequenz.channels.Receiver]s also function as `Receiver`. When Select is no longer needed, then it should be stopped using `self.stop()` method. This would cleanup any internal pending async tasks. Example: For example, if there are two receivers that you want to simultaneously wait on, this can be done with: ```python select = Select(name1 = receiver1, name2 = receiver2) while await select.ready(): if msg := select.name1: if val := msg.inner: # do something with `val` pass else: # handle closure of receiver. pass elif msg := select.name2: # do something with `msg.inner` pass ``` \"\"\" def __init__ ( self , ** kwargs : Receiver [ Any ]) -> None : \"\"\"Create a `Select` instance. Args: **kwargs: sequence of receivers \"\"\" self . _receivers = kwargs self . _pending : Set [ asyncio . Task [ bool ]] = set () for name , recv in self . _receivers . items (): self . _pending . add ( asyncio . create_task ( recv . ready (), name = name )) self . _ready_count = 0 self . _prev_ready_count = 0 self . _result : Dict [ str , Optional [ _ReadyReceiver ]] = { name : None for name in self . _receivers } def __del__ ( self ) -> None : \"\"\"Cleanup any pending tasks.\"\"\" for task in self . _pending : if not task . done () and task . get_loop () . is_running (): task . cancel () async def stop ( self ) -> None : \"\"\"Stop the `Select` instance and cleanup any pending tasks.\"\"\" for task in self . _pending : task . cancel () await asyncio . gather ( * self . _pending , return_exceptions = True ) self . _pending = set () async def ready ( self ) -> bool : \"\"\"Wait until there is a message in any of the receivers. Returns `True` if there is a message available, and `False` if all receivers have closed. Returns: Whether there are further messages or not. \"\"\" # This function will change radically soon # pylint: disable=too-many-nested-blocks if self . _ready_count > 0 : if self . _ready_count == self . _prev_ready_count : dropped_names : List [ str ] = [] for name , value in self . _result . items (): if value is not None : dropped_names . append ( name ) if value . recv is not None : try : value . recv . consume () except ReceiverStoppedError : pass self . _result [ name ] = None self . _ready_count = 0 self . _prev_ready_count = 0 logger . warning ( \"Select.ready() dropped data from receiver(s): %s , \" \"because no messages have been fetched since the last call to ready().\" , dropped_names , ) else : self . _prev_ready_count = self . _ready_count return True if len ( self . _pending ) == 0 : return False # once all the pending messages have been consumed, reset the # `_prev_ready_count` as well, and wait for new messages. self . _prev_ready_count = 0 done , self . _pending = await asyncio . wait ( self . _pending , return_when = asyncio . FIRST_COMPLETED ) for task in done : name = task . get_name () recv = self . _receivers [ name ] receiver_active = task . result () if receiver_active : ready_recv = recv else : ready_recv = None self . _ready_count += 1 self . _result [ name ] = _ReadyReceiver ( ready_recv ) # if channel or Receiver is closed # don't add a task for it again. if not receiver_active : continue self . _pending . add ( asyncio . create_task ( recv . ready (), name = name )) return True def __getattr__ ( self , name : str ) -> Optional [ Any ]: \"\"\"Return the latest unread message from a `Receiver`, if available. Args: name: Name of the channel. Returns: Latest unread message for the specified `Receiver`, or `None`. Raises: KeyError: when the name was not specified when creating the `Select` instance. \"\"\" result = self . _result [ name ] if result is None : return result self . _result [ name ] = None self . _ready_count -= 1 return result . get ()","title":"Select"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util.Select-functions","text":"","title":"Functions"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util._select.Select.__del__","text":"Cleanup any pending tasks. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_select.py 108 109 110 111 112 def __del__ ( self ) -> None : \"\"\"Cleanup any pending tasks.\"\"\" for task in self . _pending : if not task . done () and task . get_loop () . is_running (): task . cancel ()","title":"__del__()"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util._select.Select.__getattr__","text":"Return the latest unread message from a Receiver , if available. PARAMETER DESCRIPTION name Name of the channel. TYPE: str RETURNS DESCRIPTION Optional [ Any ] Latest unread message for the specified Receiver , or None . RAISES DESCRIPTION KeyError when the name was not specified when creating the Select instance. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_select.py 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 def __getattr__ ( self , name : str ) -> Optional [ Any ]: \"\"\"Return the latest unread message from a `Receiver`, if available. Args: name: Name of the channel. Returns: Latest unread message for the specified `Receiver`, or `None`. Raises: KeyError: when the name was not specified when creating the `Select` instance. \"\"\" result = self . _result [ name ] if result is None : return result self . _result [ name ] = None self . _ready_count -= 1 return result . get ()","title":"__getattr__()"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util._select.Select.__init__","text":"Create a Select instance. PARAMETER DESCRIPTION **kwargs sequence of receivers TYPE: Receiver [ Any ] DEFAULT: {} Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_select.py 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 def __init__ ( self , ** kwargs : Receiver [ Any ]) -> None : \"\"\"Create a `Select` instance. Args: **kwargs: sequence of receivers \"\"\" self . _receivers = kwargs self . _pending : Set [ asyncio . Task [ bool ]] = set () for name , recv in self . _receivers . items (): self . _pending . add ( asyncio . create_task ( recv . ready (), name = name )) self . _ready_count = 0 self . _prev_ready_count = 0 self . _result : Dict [ str , Optional [ _ReadyReceiver ]] = { name : None for name in self . _receivers }","title":"__init__()"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util._select.Select.ready","text":"Wait until there is a message in any of the receivers. Returns True if there is a message available, and False if all receivers have closed. RETURNS DESCRIPTION bool Whether there are further messages or not. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_select.py 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 async def ready ( self ) -> bool : \"\"\"Wait until there is a message in any of the receivers. Returns `True` if there is a message available, and `False` if all receivers have closed. Returns: Whether there are further messages or not. \"\"\" # This function will change radically soon # pylint: disable=too-many-nested-blocks if self . _ready_count > 0 : if self . _ready_count == self . _prev_ready_count : dropped_names : List [ str ] = [] for name , value in self . _result . items (): if value is not None : dropped_names . append ( name ) if value . recv is not None : try : value . recv . consume () except ReceiverStoppedError : pass self . _result [ name ] = None self . _ready_count = 0 self . _prev_ready_count = 0 logger . warning ( \"Select.ready() dropped data from receiver(s): %s , \" \"because no messages have been fetched since the last call to ready().\" , dropped_names , ) else : self . _prev_ready_count = self . _ready_count return True if len ( self . _pending ) == 0 : return False # once all the pending messages have been consumed, reset the # `_prev_ready_count` as well, and wait for new messages. self . _prev_ready_count = 0 done , self . _pending = await asyncio . wait ( self . _pending , return_when = asyncio . FIRST_COMPLETED ) for task in done : name = task . get_name () recv = self . _receivers [ name ] receiver_active = task . result () if receiver_active : ready_recv = recv else : ready_recv = None self . _ready_count += 1 self . _result [ name ] = _ReadyReceiver ( ready_recv ) # if channel or Receiver is closed # don't add a task for it again. if not receiver_active : continue self . _pending . add ( asyncio . create_task ( recv . ready (), name = name )) return True","title":"ready()"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util._select.Select.stop","text":"Stop the Select instance and cleanup any pending tasks. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_select.py 114 115 116 117 118 119 async def stop ( self ) -> None : \"\"\"Stop the `Select` instance and cleanup any pending tasks.\"\"\" for task in self . _pending : task . cancel () await asyncio . gather ( * self . _pending , return_exceptions = True ) self . _pending = set ()","title":"stop()"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util.SkipMissedAndDrift","text":"Bases: MissedTickPolicy A policy that drops all the missed ticks, triggers immediately and resets. This will behave effectively as if the timer was reset() at the time it had triggered last, so the start time will change (and the drift will be accumulated each time a tick is delayed, but only the relative drift will be returned on each tick). The reset happens only if the delay is larger than delay_tolerance , so it is possible to ignore small delays and not drift in those cases. Example Assume a timer with interval 1 second and delay_tolerance=0.1 , the first tick, T0 , happens exactly at time 0, the second tick, T1 , happens at time 1.2 (0.2 seconds late), so the timer triggers immmediately but drifts a bit. The next tick, T2.2 , happens at 2.3 seconds (0.1 seconds late), so it also triggers immediately but it doesn't drift because the delay is under the delay_tolerance . The next tick, T3.2 , triggers at 4.3 seconds (1.1 seconds late), so it also triggers immediately but the timer drifts by 1.1 seconds and the tick T4.2 is skipped (not triggered). The next tick, T5.3 , triggers at 5.3 seconds so is right on time (no drift) and the same happens for tick T6.3 , which triggers at 6.3 seconds. 0 1 2 3 4 5 6 o---------|-o-------|--o------|---------|--o------|--o------|--o--> time T0 T1 T2.2 T3.2 T5.3 T6.3 Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_timer.py 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 class SkipMissedAndDrift ( MissedTickPolicy ): \"\"\"A policy that drops all the missed ticks, triggers immediately and resets. This will behave effectively as if the timer was `reset()` at the time it had triggered last, so the start time will change (and the drift will be accumulated each time a tick is delayed, but only the relative drift will be returned on each tick). The reset happens only if the delay is larger than `delay_tolerance`, so it is possible to ignore small delays and not drift in those cases. Example: Assume a timer with interval 1 second and `delay_tolerance=0.1`, the first tick, `T0`, happens exactly at time 0, the second tick, `T1`, happens at time 1.2 (0.2 seconds late), so the timer triggers immmediately but drifts a bit. The next tick, `T2.2`, happens at 2.3 seconds (0.1 seconds late), so it also triggers immediately but it doesn't drift because the delay is under the `delay_tolerance`. The next tick, `T3.2`, triggers at 4.3 seconds (1.1 seconds late), so it also triggers immediately but the timer drifts by 1.1 seconds and the tick `T4.2` is skipped (not triggered). The next tick, `T5.3`, triggers at 5.3 seconds so is right on time (no drift) and the same happens for tick `T6.3`, which triggers at 6.3 seconds. ``` 0 1 2 3 4 5 6 o---------|-o-------|--o------|---------|--o------|--o------|--o--> time T0 T1 T2.2 T3.2 T5.3 T6.3 ``` \"\"\" def __init__ ( self , * , delay_tolerance : timedelta = timedelta ( 0 )): \"\"\" Create an instance. See the class documenation for more details. Args: delay_tolerance: The maximum delay that is tolerated before starting to drift. If a tick is delayed less than this, then it is not considered a missed tick and the timer doesn't accumulate this drift. Raises: ValueError: If `delay_tolerance` is negative. \"\"\" self . _tolerance : int = _to_microseconds ( delay_tolerance ) \"\"\"The maximum allowed delay before starting to drift.\"\"\" if self . _tolerance < 0 : raise ValueError ( \"delay_tolerance must be positive\" ) @property def delay_tolerance ( self ) -> timedelta : \"\"\"Return the maximum delay that is tolerated before starting to drift. Returns: The maximum delay that is tolerated before starting to drift. \"\"\" return timedelta ( microseconds = self . _tolerance ) def calculate_next_tick_time ( self , * , now : int , scheduled_tick_time : int , interval : int ) -> int : \"\"\"Calculate the next tick time. If the drift is larger than `delay_tolerance`, then it returns `now + interval` (so the timer drifts), otherwise it returns `scheduled_tick_time + interval` (we consider the delay too small and avoid small drifts). Args: now: The current loop time (in microseconds). scheduled_tick_time: The time the current tick was scheduled to trigger (in microseconds). interval: The interval between ticks (in microseconds). Returns: The next tick time (in microseconds). \"\"\" drift = now - scheduled_tick_time if drift > self . _tolerance : return now + interval return scheduled_tick_time + interval","title":"SkipMissedAndDrift"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util.SkipMissedAndDrift-attributes","text":"","title":"Attributes"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util._timer.SkipMissedAndDrift.delay_tolerance","text":"Return the maximum delay that is tolerated before starting to drift. RETURNS DESCRIPTION timedelta The maximum delay that is tolerated before starting to drift.","title":"delay_tolerance"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util.SkipMissedAndDrift-functions","text":"","title":"Functions"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util._timer.SkipMissedAndDrift.__init__","text":"Create an instance. See the class documenation for more details. PARAMETER DESCRIPTION delay_tolerance The maximum delay that is tolerated before starting to drift. If a tick is delayed less than this, then it is not considered a missed tick and the timer doesn't accumulate this drift. TYPE: timedelta DEFAULT: timedelta(0) RAISES DESCRIPTION ValueError If delay_tolerance is negative. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_timer.py 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 def __init__ ( self , * , delay_tolerance : timedelta = timedelta ( 0 )): \"\"\" Create an instance. See the class documenation for more details. Args: delay_tolerance: The maximum delay that is tolerated before starting to drift. If a tick is delayed less than this, then it is not considered a missed tick and the timer doesn't accumulate this drift. Raises: ValueError: If `delay_tolerance` is negative. \"\"\" self . _tolerance : int = _to_microseconds ( delay_tolerance ) \"\"\"The maximum allowed delay before starting to drift.\"\"\" if self . _tolerance < 0 : raise ValueError ( \"delay_tolerance must be positive\" )","title":"__init__()"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util._timer.SkipMissedAndDrift.calculate_next_tick_time","text":"Calculate the next tick time. If the drift is larger than delay_tolerance , then it returns now + interval (so the timer drifts), otherwise it returns scheduled_tick_time + interval (we consider the delay too small and avoid small drifts). PARAMETER DESCRIPTION now The current loop time (in microseconds). TYPE: int scheduled_tick_time The time the current tick was scheduled to trigger (in microseconds). TYPE: int interval The interval between ticks (in microseconds). TYPE: int RETURNS DESCRIPTION int The next tick time (in microseconds). Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_timer.py 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 def calculate_next_tick_time ( self , * , now : int , scheduled_tick_time : int , interval : int ) -> int : \"\"\"Calculate the next tick time. If the drift is larger than `delay_tolerance`, then it returns `now + interval` (so the timer drifts), otherwise it returns `scheduled_tick_time + interval` (we consider the delay too small and avoid small drifts). Args: now: The current loop time (in microseconds). scheduled_tick_time: The time the current tick was scheduled to trigger (in microseconds). interval: The interval between ticks (in microseconds). Returns: The next tick time (in microseconds). \"\"\" drift = now - scheduled_tick_time if drift > self . _tolerance : return now + interval return scheduled_tick_time + interval","title":"calculate_next_tick_time()"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util.SkipMissedAndResync","text":"Bases: MissedTickPolicy A policy that drops all the missed ticks, triggers immediately and resyncs. If ticks are missed, the timer will trigger immediately returing the drift and it will schedule to trigger again on the next multiple of interval , effectively skipping any missed ticks, but resyncing with the original start time. Example Assume a timer with interval 1 second, the tick T0 happens exactly at time 0, the second tick, T1 , happens at time 1.2 (0.2 seconds late), so it trigges immediately. The third tick, T2 , happens at time 2.3 (0.3 seconds late), so it also triggers immediately. The fourth tick, T3 , happens at time 4.3 (1.3 seconds late), so it also triggers immediately but the fifth tick, T4 , which was also already delayed (by 0.3 seconds) is skipped. The sixth tick, T5 , happens at 5.1 (0.1 seconds late), so it triggers immediately again. The seventh tick, T6 , happens at 6.0, right on time. 0 1 2 3 4 o 5 6 o---------|-o-------|--o------|---------|--o------|o--------o-----> time T0 T1 T2 T3 T5 T6 Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_timer.py 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 class SkipMissedAndResync ( MissedTickPolicy ): \"\"\"A policy that drops all the missed ticks, triggers immediately and resyncs. If ticks are missed, the timer will trigger immediately returing the drift and it will schedule to trigger again on the next multiple of `interval`, effectively skipping any missed ticks, but resyncing with the original start time. Example: Assume a timer with interval 1 second, the tick `T0` happens exactly at time 0, the second tick, `T1`, happens at time 1.2 (0.2 seconds late), so it trigges immediately. The third tick, `T2`, happens at time 2.3 (0.3 seconds late), so it also triggers immediately. The fourth tick, `T3`, happens at time 4.3 (1.3 seconds late), so it also triggers immediately but the fifth tick, `T4`, which was also already delayed (by 0.3 seconds) is skipped. The sixth tick, `T5`, happens at 5.1 (0.1 seconds late), so it triggers immediately again. The seventh tick, `T6`, happens at 6.0, right on time. ``` 0 1 2 3 4 o 5 6 o---------|-o-------|--o------|---------|--o------|o--------o-----> time T0 T1 T2 T3 T5 T6 ``` \"\"\" def calculate_next_tick_time ( self , * , now : int , scheduled_tick_time : int , interval : int ) -> int : \"\"\"Calculate the next tick time. Calculate the next multiple of `interval` after `scheduled_tick_time`. Args: now: The current loop time (in microseconds). scheduled_tick_time: The time the current tick was scheduled to trigger (in microseconds). interval: The interval between ticks (in microseconds). Returns: The next tick time (in microseconds). \"\"\" # We need to resync (align) the next tick time to the current time drift = now - scheduled_tick_time delta_to_next_tick = interval - ( drift % interval ) return now + delta_to_next_tick","title":"SkipMissedAndResync"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util.SkipMissedAndResync-functions","text":"","title":"Functions"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util._timer.SkipMissedAndResync.calculate_next_tick_time","text":"Calculate the next tick time. Calculate the next multiple of interval after scheduled_tick_time . PARAMETER DESCRIPTION now The current loop time (in microseconds). TYPE: int scheduled_tick_time The time the current tick was scheduled to trigger (in microseconds). TYPE: int interval The interval between ticks (in microseconds). TYPE: int RETURNS DESCRIPTION int The next tick time (in microseconds). Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_timer.py 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 def calculate_next_tick_time ( self , * , now : int , scheduled_tick_time : int , interval : int ) -> int : \"\"\"Calculate the next tick time. Calculate the next multiple of `interval` after `scheduled_tick_time`. Args: now: The current loop time (in microseconds). scheduled_tick_time: The time the current tick was scheduled to trigger (in microseconds). interval: The interval between ticks (in microseconds). Returns: The next tick time (in microseconds). \"\"\" # We need to resync (align) the next tick time to the current time drift = now - scheduled_tick_time delta_to_next_tick = interval - ( drift % interval ) return now + delta_to_next_tick","title":"calculate_next_tick_time()"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util.Timer","text":"Bases: Receiver [ timedelta ] A timer receiver that triggers every interval time. The timer as microseconds resolution, so the interval must be at least 1 microsecond. The message it produces is a timedelta containing the drift of the timer, i.e. the difference between when the timer should have triggered and the time when it actually triggered. This drift will likely never be 0 , because if there is a task that is running when it should trigger, the timer will be delayed. In this case the drift will be positive. A negative drift should be technically impossible, as the timer uses asyncio s loop monotonic clock. If the timer is delayed too much, then the timer will behave according to the missed_tick_policy . Missing ticks might or might not trigger a message and the drift could be accumulated or not depending on the chosen policy. The timer accepts an optional loop , which will be used to track the time. If loop is None , then the running loop will be used (if there is no running loop most calls will raise a RuntimeError ). Starting the timer can be delayed if necessary by using auto_start=False (for example until we have a running loop). A call to reset() , ready() , receive() or the async iterator interface to await for a new message will start the timer. For the most common cases, a specialized constructor is provided: periodic() timeout() Periodic timer example async for drift in Timer . periodic ( timedelta ( seconds = 1.0 )): print ( f \"The timer has triggered { drift =} \" ) But you can also use Select to combine it with other receivers, and even start it (semi) manually: timer = Timer . timeout ( timedelta ( seconds = 1.0 ), auto_start = False ) # Do some other initialization, the timer will start automatically if # a message is awaited (or manually via `reset()`). select = Select ( bat_1 = receiver1 , timer = timer ) while await select . ready (): if msg := select . bat_1 : if val := msg . inner : process_data ( val ) else : logging . warn ( \"battery channel closed\" ) elif drift := select . timer : # Print some regular battery data print ( f \"Battery is charged at { battery . soc } %\" ) if stop_logging : timer . stop () elif start_logging : timer . reset () Timeout example timer = Timer . timeout ( timedelta ( seconds = 1.0 ), auto_start = False ) select = Select ( bat_1 = receiver1 , heavy_process = receiver2 , timeout = timer ) while await select . ready (): if msg := select . bat_1 : if val := msg . inner : process_data ( val ) timer . reset () else : logging . warn ( \"battery channel closed\" ) if msg := select . heavy_process : if val := msg . inner : do_heavy_processing ( val ) else : logging . warn ( \"processing channel closed\" ) elif drift := select . timeout : logging . warn ( \"No data received in time\" ) In this case do_heavy_processing might take 2 seconds, and we don't want our timeout timer to trigger for the missed ticks, and want the next tick to be relative to the time timer was last triggered. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_timer.py 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 class Timer ( Receiver [ timedelta ]): \"\"\"A timer receiver that triggers every `interval` time. The timer as microseconds resolution, so the `interval` must be at least 1 microsecond. The message it produces is a `timedelta` containing the drift of the timer, i.e. the difference between when the timer should have triggered and the time when it actually triggered. This drift will likely never be `0`, because if there is a task that is running when it should trigger, the timer will be delayed. In this case the drift will be positive. A negative drift should be technically impossible, as the timer uses `asyncio`s loop monotonic clock. If the timer is delayed too much, then the timer will behave according to the `missed_tick_policy`. Missing ticks might or might not trigger a message and the drift could be accumulated or not depending on the chosen policy. The timer accepts an optional `loop`, which will be used to track the time. If `loop` is `None`, then the running loop will be used (if there is no running loop most calls will raise a `RuntimeError`). Starting the timer can be delayed if necessary by using `auto_start=False` (for example until we have a running loop). A call to `reset()`, `ready()`, `receive()` or the async iterator interface to await for a new message will start the timer. For the most common cases, a specialized constructor is provided: * [`periodic()`][frequenz.channels.util.Timer.periodic] * [`timeout()`][frequenz.channels.util.Timer.timeout] Example: Periodic timer example ```python async for drift in Timer.periodic(timedelta(seconds=1.0)): print(f\"The timer has triggered {drift=}\") ``` But you can also use [`Select`][frequenz.channels.util.Select] to combine it with other receivers, and even start it (semi) manually: ```python timer = Timer.timeout(timedelta(seconds=1.0), auto_start=False) # Do some other initialization, the timer will start automatically if # a message is awaited (or manually via `reset()`). select = Select(bat_1=receiver1, timer=timer) while await select.ready(): if msg := select.bat_1: if val := msg.inner: process_data(val) else: logging.warn(\"battery channel closed\") elif drift := select.timer: # Print some regular battery data print(f\"Battery is charged at {battery.soc}%\") if stop_logging: timer.stop() elif start_logging: timer.reset() ``` Example: Timeout example ```python timer = Timer.timeout(timedelta(seconds=1.0), auto_start=False) select = Select(bat_1=receiver1, heavy_process=receiver2, timeout=timer) while await select.ready(): if msg := select.bat_1: if val := msg.inner: process_data(val) timer.reset() else: logging.warn(\"battery channel closed\") if msg := select.heavy_process: if val := msg.inner: do_heavy_processing(val) else: logging.warn(\"processing channel closed\") elif drift := select.timeout: logging.warn(\"No data received in time\") ``` In this case `do_heavy_processing` might take 2 seconds, and we don't want our timeout timer to trigger for the missed ticks, and want the next tick to be relative to the time timer was last triggered. \"\"\" def __init__ ( self , interval : timedelta , missed_tick_policy : MissedTickPolicy , / , * , auto_start : bool = True , loop : asyncio . AbstractEventLoop | None = None , ) -> None : \"\"\"Create an instance. See the class documentation for details. Args: interval: The time between timer ticks. Must be at least 1 microsecond. missed_tick_policy: The policy of the timer when it misses a tick. See the documentation of `MissedTickPolicy` for details. auto_start: Whether the timer should be started when the instance is created. This can only be `True` if there is already a running loop or an explicit `loop` that is running was passed. loop: The event loop to use to track time. If `None`, `asyncio.get_running_loop()` will be used. Raises: RuntimeError: if it was called without a loop and there is no running loop. ValueError: if `interval` is not positive or is smaller than 1 microsecond. \"\"\" self . _interval : int = _to_microseconds ( interval ) \"\"\"The time to between timer ticks.\"\"\" self . _missed_tick_policy : MissedTickPolicy = missed_tick_policy \"\"\"The policy of the timer when it misses a tick. See the documentation of `MissedTickPolicy` for details. \"\"\" self . _loop : asyncio . AbstractEventLoop = ( loop if loop is not None else asyncio . get_running_loop () ) \"\"\"The event loop to use to track time.\"\"\" self . _stopped : bool = True \"\"\"Whether the timer was requested to stop. If this is `False`, then the timer is running. If this is `True`, then it is stopped or there is a request to stop it or it was not started yet: * If `_next_msg_time` is `None`, it means it wasn't started yet (it was created with `auto_start=False`). Any receiving method will start it by calling `reset()` in this case. * If `_next_msg_time` is not `None`, it means there was a request to stop it. In this case receiving methods will raise a `ReceiverClosedError`. \"\"\" self . _next_tick_time : int | None = None \"\"\"The absolute (monotonic) time when the timer should trigger. If this is `None`, it means the timer didn't start yet, but it should be started as soon as it is used. \"\"\" self . _current_drift : timedelta | None = None \"\"\"The difference between `_next_msg_time` and the triggered time. This is calculated by `ready()` but is returned by `consume()`. If `None` it means `ready()` wasn't called and `consume()` will assert. `consume()` will set it back to `None` to tell `ready()` that it needs to wait again. \"\"\" if self . _interval <= 0 : raise ValueError ( \"The `interval` must be positive and at least 1 microsecond, \" f \"not { interval } ( { self . _interval } microseconds)\" ) if auto_start : self . reset () @classmethod def timeout ( cls , delay : timedelta , / , * , auto_start : bool = True , loop : asyncio . AbstractEventLoop | None = None , ) -> Timer : \"\"\"Create a timer useful for tracking timeouts. This is basically a shortcut to create a timer with `SkipMissedAndDrift(delay_tolerance=timedelta(0))` as the missed tick policy. See the class documentation for details. Args: delay: The time until the timer ticks. Must be at least 1 microsecond. auto_start: Whether the timer should be started when the instance is created. This can only be `True` if there is already a running loop or an explicit `loop` that is running was passed. loop: The event loop to use to track time. If `None`, `asyncio.get_running_loop()` will be used. Returns: The timer instance. Raises: RuntimeError: if it was called without a loop and there is no running loop. ValueError: if `interval` is not positive or is smaller than 1 microsecond. \"\"\" return Timer ( delay , SkipMissedAndDrift ( delay_tolerance = timedelta ( 0 )), auto_start = auto_start , loop = loop , ) @classmethod def periodic ( cls , period : timedelta , / , * , skip_missed_ticks : bool = False , auto_start : bool = True , loop : asyncio . AbstractEventLoop | None = None , ) -> Timer : \"\"\"Create a periodic timer. This is basically a shortcut to create a timer with either `TriggerAllMissed()` or `SkipMissedAndResync()` as the missed tick policy (depending on `skip_missed_ticks`). See the class documentation for details. Args: period: The time between timer ticks. Must be at least 1 microsecond. skip_missed_ticks: Whether to skip missed ticks or trigger them all until it catches up. auto_start: Whether the timer should be started when the instance is created. This can only be `True` if there is already a running loop or an explicit `loop` that is running was passed. loop: The event loop to use to track time. If `None`, `asyncio.get_running_loop()` will be used. Returns: The timer instance. Raises: RuntimeError: if it was called without a loop and there is no running loop. ValueError: if `interval` is not positive or is smaller than 1 microsecond. \"\"\" missed_tick_policy = ( SkipMissedAndResync () if skip_missed_ticks else TriggerAllMissed () ) return Timer ( period , missed_tick_policy , auto_start = auto_start , loop = loop , ) @property def interval ( self ) -> timedelta : \"\"\"The interval between timer ticks. Returns: The interval between timer ticks. \"\"\" return timedelta ( microseconds = self . _interval ) @property def missed_tick_policy ( self ) -> MissedTickPolicy : \"\"\"The policy of the timer when it misses a tick. Returns: The policy of the timer when it misses a tick. \"\"\" return self . _missed_tick_policy @property def loop ( self ) -> asyncio . AbstractEventLoop : \"\"\"The event loop used by the timer to track time. Returns: The event loop used by the timer to track time. \"\"\" return self . _loop @property def is_running ( self ) -> bool : \"\"\"Whether the timer is running. This will be `False` if the timer was stopped, or not started yet. Returns: Whether the timer is running. \"\"\" return not self . _stopped def reset ( self ) -> None : \"\"\"Reset the timer to start timing from now. If the timer was stopped, or not started yet, it will be started. This can only be called with a running loop, see the class documentation for more details. Raises: RuntimeError: if it was called without a running loop. \"\"\" self . _stopped = False self . _next_tick_time = self . _now () + self . _interval self . _current_drift = None def stop ( self ) -> None : \"\"\"Stop the timer. Once `stop` has been called, all subsequent calls to `ready()` will immediately return False and calls to `consume()` / `receive()` or any use of the async iterator interface will raise a `ReceiverStoppedError`. You can restart the timer with `reset()`. \"\"\" self . _stopped = True # We need to make sure it's not None, otherwise `ready()` will start it self . _next_tick_time = self . _now () async def ready ( self ) -> bool : \"\"\"Wait until the timer `interval` passed. Once a call to `ready()` has finished, the resulting tick information must be read with a call to `consume()` (`receive()` or iterated over) to tell the timer it should wait for the next interval. The timer will remain ready (this method will return immediately) until it is consumed. Returns: Whether the timer was started and it is still running. Raises: RuntimeError: if it was called without a running loop. \"\"\" # If there are messages waiting to be consumed, return immediately. if self . _current_drift is not None : return True # If `_next_tick_time` is `None`, it means it was created with # `auto_start=False` and should be started. if self . _next_tick_time is None : self . reset () assert ( self . _next_tick_time is not None ), \"This should be assigned by reset()\" # If a stop was explicitly requested, we bail out. if self . _stopped : return False now = self . _now () time_to_next_tick = self . _next_tick_time - now # If we didn't reach the tick yet, sleep until we do. if time_to_next_tick > 0 : await asyncio . sleep ( time_to_next_tick / 1_000_000 ) now = self . _now () # If a stop was explicitly requested during the sleep, we bail out. if self . _stopped : return False self . _current_drift = timedelta ( microseconds = now - self . _next_tick_time ) self . _next_tick_time = self . _missed_tick_policy . calculate_next_tick_time ( now = now , scheduled_tick_time = self . _next_tick_time , interval = self . _interval , ) return True def consume ( self ) -> timedelta : \"\"\"Return the latest drift once `ready()` is complete. Once the timer has triggered (`ready()` is done), this method returns the difference between when the timer should have triggered and the time when it actually triggered. See the class documentation for more details. Returns: The difference between when the timer should have triggered and the time when it actually did. Raises: ReceiverStoppedError: if the timer was stopped via `stop()`. \"\"\" # If it was stopped and there it no pending result, we raise # (if there is a pending result, then we still want to return it first) if self . _stopped and self . _current_drift is None : raise ReceiverStoppedError ( self ) assert ( self . _current_drift is not None ), \"calls to `consume()` must be follow a call to `ready()`\" drift = self . _current_drift self . _current_drift = None return drift def _now ( self ) -> int : \"\"\"Return the current monotonic clock time in microseconds. Returns: The current monotonic clock time in microseconds. \"\"\" return _to_microseconds ( self . _loop . time ())","title":"Timer"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util.Timer-attributes","text":"","title":"Attributes"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util._timer.Timer.interval","text":"The interval between timer ticks. RETURNS DESCRIPTION timedelta The interval between timer ticks.","title":"interval"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util._timer.Timer.is_running","text":"Whether the timer is running. This will be False if the timer was stopped, or not started yet. RETURNS DESCRIPTION bool Whether the timer is running.","title":"is_running"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util._timer.Timer.loop","text":"The event loop used by the timer to track time. RETURNS DESCRIPTION asyncio . AbstractEventLoop The event loop used by the timer to track time.","title":"loop"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util._timer.Timer.missed_tick_policy","text":"The policy of the timer when it misses a tick. RETURNS DESCRIPTION MissedTickPolicy The policy of the timer when it misses a tick.","title":"missed_tick_policy"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util.Timer-functions","text":"","title":"Functions"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util._timer.Timer.__init__","text":"Create an instance. See the class documentation for details. PARAMETER DESCRIPTION interval The time between timer ticks. Must be at least 1 microsecond. TYPE: timedelta missed_tick_policy The policy of the timer when it misses a tick. See the documentation of MissedTickPolicy for details. TYPE: MissedTickPolicy auto_start Whether the timer should be started when the instance is created. This can only be True if there is already a running loop or an explicit loop that is running was passed. TYPE: bool DEFAULT: True loop The event loop to use to track time. If None , asyncio.get_running_loop() will be used. TYPE: asyncio . AbstractEventLoop | None DEFAULT: None RAISES DESCRIPTION RuntimeError if it was called without a loop and there is no running loop. ValueError if interval is not positive or is smaller than 1 microsecond. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_timer.py 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 def __init__ ( self , interval : timedelta , missed_tick_policy : MissedTickPolicy , / , * , auto_start : bool = True , loop : asyncio . AbstractEventLoop | None = None , ) -> None : \"\"\"Create an instance. See the class documentation for details. Args: interval: The time between timer ticks. Must be at least 1 microsecond. missed_tick_policy: The policy of the timer when it misses a tick. See the documentation of `MissedTickPolicy` for details. auto_start: Whether the timer should be started when the instance is created. This can only be `True` if there is already a running loop or an explicit `loop` that is running was passed. loop: The event loop to use to track time. If `None`, `asyncio.get_running_loop()` will be used. Raises: RuntimeError: if it was called without a loop and there is no running loop. ValueError: if `interval` is not positive or is smaller than 1 microsecond. \"\"\" self . _interval : int = _to_microseconds ( interval ) \"\"\"The time to between timer ticks.\"\"\" self . _missed_tick_policy : MissedTickPolicy = missed_tick_policy \"\"\"The policy of the timer when it misses a tick. See the documentation of `MissedTickPolicy` for details. \"\"\" self . _loop : asyncio . AbstractEventLoop = ( loop if loop is not None else asyncio . get_running_loop () ) \"\"\"The event loop to use to track time.\"\"\" self . _stopped : bool = True \"\"\"Whether the timer was requested to stop. If this is `False`, then the timer is running. If this is `True`, then it is stopped or there is a request to stop it or it was not started yet: * If `_next_msg_time` is `None`, it means it wasn't started yet (it was created with `auto_start=False`). Any receiving method will start it by calling `reset()` in this case. * If `_next_msg_time` is not `None`, it means there was a request to stop it. In this case receiving methods will raise a `ReceiverClosedError`. \"\"\" self . _next_tick_time : int | None = None \"\"\"The absolute (monotonic) time when the timer should trigger. If this is `None`, it means the timer didn't start yet, but it should be started as soon as it is used. \"\"\" self . _current_drift : timedelta | None = None \"\"\"The difference between `_next_msg_time` and the triggered time. This is calculated by `ready()` but is returned by `consume()`. If `None` it means `ready()` wasn't called and `consume()` will assert. `consume()` will set it back to `None` to tell `ready()` that it needs to wait again. \"\"\" if self . _interval <= 0 : raise ValueError ( \"The `interval` must be positive and at least 1 microsecond, \" f \"not { interval } ( { self . _interval } microseconds)\" ) if auto_start : self . reset ()","title":"__init__()"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util._timer.Timer.consume","text":"Return the latest drift once ready() is complete. Once the timer has triggered ( ready() is done), this method returns the difference between when the timer should have triggered and the time when it actually triggered. See the class documentation for more details. RETURNS DESCRIPTION timedelta The difference between when the timer should have triggered and the time when it actually did. RAISES DESCRIPTION ReceiverStoppedError if the timer was stopped via stop() . Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_timer.py 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 def consume ( self ) -> timedelta : \"\"\"Return the latest drift once `ready()` is complete. Once the timer has triggered (`ready()` is done), this method returns the difference between when the timer should have triggered and the time when it actually triggered. See the class documentation for more details. Returns: The difference between when the timer should have triggered and the time when it actually did. Raises: ReceiverStoppedError: if the timer was stopped via `stop()`. \"\"\" # If it was stopped and there it no pending result, we raise # (if there is a pending result, then we still want to return it first) if self . _stopped and self . _current_drift is None : raise ReceiverStoppedError ( self ) assert ( self . _current_drift is not None ), \"calls to `consume()` must be follow a call to `ready()`\" drift = self . _current_drift self . _current_drift = None return drift","title":"consume()"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util._timer.Timer.periodic","text":"Create a periodic timer. This is basically a shortcut to create a timer with either TriggerAllMissed() or SkipMissedAndResync() as the missed tick policy (depending on skip_missed_ticks ). See the class documentation for details. PARAMETER DESCRIPTION period The time between timer ticks. Must be at least 1 microsecond. TYPE: timedelta skip_missed_ticks Whether to skip missed ticks or trigger them all until it catches up. TYPE: bool DEFAULT: False auto_start Whether the timer should be started when the instance is created. This can only be True if there is already a running loop or an explicit loop that is running was passed. TYPE: bool DEFAULT: True loop The event loop to use to track time. If None , asyncio.get_running_loop() will be used. TYPE: asyncio . AbstractEventLoop | None DEFAULT: None RETURNS DESCRIPTION Timer The timer instance. RAISES DESCRIPTION RuntimeError if it was called without a loop and there is no running loop. ValueError if interval is not positive or is smaller than 1 microsecond. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_timer.py 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 @classmethod def periodic ( cls , period : timedelta , / , * , skip_missed_ticks : bool = False , auto_start : bool = True , loop : asyncio . AbstractEventLoop | None = None , ) -> Timer : \"\"\"Create a periodic timer. This is basically a shortcut to create a timer with either `TriggerAllMissed()` or `SkipMissedAndResync()` as the missed tick policy (depending on `skip_missed_ticks`). See the class documentation for details. Args: period: The time between timer ticks. Must be at least 1 microsecond. skip_missed_ticks: Whether to skip missed ticks or trigger them all until it catches up. auto_start: Whether the timer should be started when the instance is created. This can only be `True` if there is already a running loop or an explicit `loop` that is running was passed. loop: The event loop to use to track time. If `None`, `asyncio.get_running_loop()` will be used. Returns: The timer instance. Raises: RuntimeError: if it was called without a loop and there is no running loop. ValueError: if `interval` is not positive or is smaller than 1 microsecond. \"\"\" missed_tick_policy = ( SkipMissedAndResync () if skip_missed_ticks else TriggerAllMissed () ) return Timer ( period , missed_tick_policy , auto_start = auto_start , loop = loop , )","title":"periodic()"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util._timer.Timer.ready","text":"Wait until the timer interval passed. Once a call to ready() has finished, the resulting tick information must be read with a call to consume() ( receive() or iterated over) to tell the timer it should wait for the next interval. The timer will remain ready (this method will return immediately) until it is consumed. RETURNS DESCRIPTION bool Whether the timer was started and it is still running. RAISES DESCRIPTION RuntimeError if it was called without a running loop. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_timer.py 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 async def ready ( self ) -> bool : \"\"\"Wait until the timer `interval` passed. Once a call to `ready()` has finished, the resulting tick information must be read with a call to `consume()` (`receive()` or iterated over) to tell the timer it should wait for the next interval. The timer will remain ready (this method will return immediately) until it is consumed. Returns: Whether the timer was started and it is still running. Raises: RuntimeError: if it was called without a running loop. \"\"\" # If there are messages waiting to be consumed, return immediately. if self . _current_drift is not None : return True # If `_next_tick_time` is `None`, it means it was created with # `auto_start=False` and should be started. if self . _next_tick_time is None : self . reset () assert ( self . _next_tick_time is not None ), \"This should be assigned by reset()\" # If a stop was explicitly requested, we bail out. if self . _stopped : return False now = self . _now () time_to_next_tick = self . _next_tick_time - now # If we didn't reach the tick yet, sleep until we do. if time_to_next_tick > 0 : await asyncio . sleep ( time_to_next_tick / 1_000_000 ) now = self . _now () # If a stop was explicitly requested during the sleep, we bail out. if self . _stopped : return False self . _current_drift = timedelta ( microseconds = now - self . _next_tick_time ) self . _next_tick_time = self . _missed_tick_policy . calculate_next_tick_time ( now = now , scheduled_tick_time = self . _next_tick_time , interval = self . _interval , ) return True","title":"ready()"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util._timer.Timer.reset","text":"Reset the timer to start timing from now. If the timer was stopped, or not started yet, it will be started. This can only be called with a running loop, see the class documentation for more details. RAISES DESCRIPTION RuntimeError if it was called without a running loop. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_timer.py 551 552 553 554 555 556 557 558 559 560 561 562 563 564 def reset ( self ) -> None : \"\"\"Reset the timer to start timing from now. If the timer was stopped, or not started yet, it will be started. This can only be called with a running loop, see the class documentation for more details. Raises: RuntimeError: if it was called without a running loop. \"\"\" self . _stopped = False self . _next_tick_time = self . _now () + self . _interval self . _current_drift = None","title":"reset()"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util._timer.Timer.stop","text":"Stop the timer. Once stop has been called, all subsequent calls to ready() will immediately return False and calls to consume() / receive() or any use of the async iterator interface will raise a ReceiverStoppedError . You can restart the timer with reset() . Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_timer.py 566 567 568 569 570 571 572 573 574 575 576 577 578 def stop ( self ) -> None : \"\"\"Stop the timer. Once `stop` has been called, all subsequent calls to `ready()` will immediately return False and calls to `consume()` / `receive()` or any use of the async iterator interface will raise a `ReceiverStoppedError`. You can restart the timer with `reset()`. \"\"\" self . _stopped = True # We need to make sure it's not None, otherwise `ready()` will start it self . _next_tick_time = self . _now ()","title":"stop()"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util._timer.Timer.timeout","text":"Create a timer useful for tracking timeouts. This is basically a shortcut to create a timer with SkipMissedAndDrift(delay_tolerance=timedelta(0)) as the missed tick policy. See the class documentation for details. PARAMETER DESCRIPTION delay The time until the timer ticks. Must be at least 1 microsecond. TYPE: timedelta auto_start Whether the timer should be started when the instance is created. This can only be True if there is already a running loop or an explicit loop that is running was passed. TYPE: bool DEFAULT: True loop The event loop to use to track time. If None , asyncio.get_running_loop() will be used. TYPE: asyncio . AbstractEventLoop | None DEFAULT: None RETURNS DESCRIPTION Timer The timer instance. RAISES DESCRIPTION RuntimeError if it was called without a loop and there is no running loop. ValueError if interval is not positive or is smaller than 1 microsecond. Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_timer.py 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 @classmethod def timeout ( cls , delay : timedelta , / , * , auto_start : bool = True , loop : asyncio . AbstractEventLoop | None = None , ) -> Timer : \"\"\"Create a timer useful for tracking timeouts. This is basically a shortcut to create a timer with `SkipMissedAndDrift(delay_tolerance=timedelta(0))` as the missed tick policy. See the class documentation for details. Args: delay: The time until the timer ticks. Must be at least 1 microsecond. auto_start: Whether the timer should be started when the instance is created. This can only be `True` if there is already a running loop or an explicit `loop` that is running was passed. loop: The event loop to use to track time. If `None`, `asyncio.get_running_loop()` will be used. Returns: The timer instance. Raises: RuntimeError: if it was called without a loop and there is no running loop. ValueError: if `interval` is not positive or is smaller than 1 microsecond. \"\"\" return Timer ( delay , SkipMissedAndDrift ( delay_tolerance = timedelta ( 0 )), auto_start = auto_start , loop = loop , )","title":"timeout()"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util.TriggerAllMissed","text":"Bases: MissedTickPolicy A policy that triggers all the missed ticks immediately until it catches up. Example Assume a timer with interval 1 second, the tick T0 happens exactly at time 0, the second tick, T1 , happens at time 1.2 (0.2 seconds late), so it trigges immediately. The third tick, T2 , happens at time 2.3 (0.3 seconds late), so it also triggers immediately. The fourth tick, T3 , happens at time 4.3 (1.3 seconds late), so it also triggers immediately as well as the fifth tick, T4 , which was also already delayed (by 0.3 seconds), so it catches up. The sixth tick, T5 , happens at 5.1 (0.1 seconds late), so it triggers immediately again. The seventh tick, T6 , happens at 6.0, right on time. 0 1 2 3 4 o 5 6 o---------|-o-------|--o------|---------|--o------|o--------o-----> time T0 T1 T2 T3 T5 T6 T4 Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_timer.py 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 class TriggerAllMissed ( MissedTickPolicy ): \"\"\"A policy that triggers all the missed ticks immediately until it catches up. Example: Assume a timer with interval 1 second, the tick `T0` happens exactly at time 0, the second tick, `T1`, happens at time 1.2 (0.2 seconds late), so it trigges immediately. The third tick, `T2`, happens at time 2.3 (0.3 seconds late), so it also triggers immediately. The fourth tick, `T3`, happens at time 4.3 (1.3 seconds late), so it also triggers immediately as well as the fifth tick, `T4`, which was also already delayed (by 0.3 seconds), so it catches up. The sixth tick, `T5`, happens at 5.1 (0.1 seconds late), so it triggers immediately again. The seventh tick, `T6`, happens at 6.0, right on time. ``` 0 1 2 3 4 o 5 6 o---------|-o-------|--o------|---------|--o------|o--------o-----> time T0 T1 T2 T3 T5 T6 T4 ``` \"\"\" def calculate_next_tick_time ( self , * , now : int , scheduled_tick_time : int , interval : int ) -> int : \"\"\"Calculate the next tick time. This method always returns `scheduled_tick_time + interval`, as all ticks need to produce a trigger event. Args: now: The current loop time (in microseconds). scheduled_tick_time: The time the current tick was scheduled to trigger (in microseconds). interval: The interval between ticks (in microseconds). Returns: The next tick time (in microseconds). \"\"\" return scheduled_tick_time + interval","title":"TriggerAllMissed"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util.TriggerAllMissed-functions","text":"","title":"Functions"},{"location":"reference/frequenz/channels/util/#frequenz.channels.util._timer.TriggerAllMissed.calculate_next_tick_time","text":"Calculate the next tick time. This method always returns scheduled_tick_time + interval , as all ticks need to produce a trigger event. PARAMETER DESCRIPTION now The current loop time (in microseconds). TYPE: int scheduled_tick_time The time the current tick was scheduled to trigger (in microseconds). TYPE: int interval The interval between ticks (in microseconds). TYPE: int RETURNS DESCRIPTION int The next tick time (in microseconds). Source code in /opt/hostedtoolcache/Python/3.11.3/x64/lib/python3.11/site-packages/frequenz/channels/util/_timer.py 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 def calculate_next_tick_time ( self , * , now : int , scheduled_tick_time : int , interval : int ) -> int : \"\"\"Calculate the next tick time. This method always returns `scheduled_tick_time + interval`, as all ticks need to produce a trigger event. Args: now: The current loop time (in microseconds). scheduled_tick_time: The time the current tick was scheduled to trigger (in microseconds). interval: The interval between ticks (in microseconds). Returns: The next tick time (in microseconds). \"\"\" return scheduled_tick_time + interval","title":"calculate_next_tick_time()"}]}